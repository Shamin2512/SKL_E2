{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fcba82d",
   "metadata": {},
   "source": [
    "## Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5737f62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2 is inbalanced data set; ~2200 in PD and ~1100 in SNP\n",
    "# Goal is to predict if protein is a SNP or PD\n",
    "#ImprovedBalancing branch\n",
    "\n",
    "#Imports the required libraries and packages\n",
    "import pandas as pd  #Import for data manipulation in dataframes\n",
    "import numpy as np  #Array manipulation and calculates mean\n",
    "import matplotlib.pyplot as plt  #Graphing and plotting\n",
    "# show figures in jupyter instead of prompt window\n",
    "%matplotlib inline \n",
    "\n",
    "import random as rd\n",
    "import time\n",
    "import sys\n",
    "\n",
    "from sklearn import tree\n",
    "\n",
    "from sklearn.metrics import(\n",
    "    matthews_corrcoef,  # CC for evaluation\n",
    "    f1_score,  #F1 score for evaluation\n",
    "    balanced_accuracy_score, roc_auc_score, make_scorer,  #Scoring metrics\n",
    "    confusion_matrix,  #Creates the confusion matrix - stats on how accurate the test set output is\n",
    "    classification_report #Returns the F1 socre, precision, and recall of a prediction using a given model\n",
    "    )\n",
    "from sklearn.model_selection import(\n",
    "    train_test_split,  # Splits data frame into the training set and testing set\n",
    "    GridSearchCV,  # Cross validation to improve hyperparameters\n",
    "    StratifiedKFold\n",
    "        )\n",
    "from sklearn.ensemble import RandomForestClassifier #SK learn API for classificastion random forests\n",
    "from sklearn.tree import DecisionTreeClassifier #Single tree decisions \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.utils import shuffle #shuffles rows\n",
    "from sklearn.neighbors import KNeighborsClassifier #allows for confidence scores to be predicted for each\n",
    "\n",
    "np.set_printoptions(threshold=np.inf) #full array printing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2ffd97",
   "metadata": {},
   "source": [
    "## Random Seed function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6be2ee9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "167043"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Random_Seed(): #Generates a random seed\n",
    "    random1 = rd.randrange(1,100) #Random integet between 1 and 100\n",
    "    random2 =  time.time() #Time since UTC epoch\n",
    "    Seed = int(random2//random1//1000)\n",
    "    return Seed\n",
    "Random_Seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddcc865",
   "metadata": {},
   "source": [
    "## Read the whole dataset - revis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62413d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 3368\n",
      "2254 PD samples\n",
      "1111 PD samples\n"
     ]
    }
   ],
   "source": [
    "#Create, clean and convert dataset E2.csv to PD dataframe**\n",
    "df = pd.read_csv('E2.csv')  #Create PD data frame from .csv\n",
    "df.drop(['pdbcode:chain:resnum:mutation'], axis=1, inplace=True)  #Removes unrequired columns. PDBcode may be needed for manual validation \n",
    "df.columns = df.columns.str.replace(' ', '_')  # Removes any blank attributes\n",
    "df.replace(' ', '_', regex=True, inplace=True)  # Replace all blank spaces with underscore (none were present)\n",
    "df.reset_index(drop=True, inplace = True) #Resets index numbering from 0 and drops column\n",
    "Input = df.drop('dataset', axis =1).fillna('0') #DF of input instances for classification training. Unknown attributes assigned 0\n",
    "Output_encoded = pd.get_dummies(df, columns=['dataset']) #One hot encoding dataset column so \"PD\" and \"SNP\" attributes are numerical 0 or 1\n",
    "Output = Output_encoded['dataset_pd'].copy().astype('int32') #Dataframe with 1 column where 1 = PD, 0 = SNP, integer\n",
    "\n",
    "print(\"Total samples:\", len(df))\n",
    "Majority = len(df.loc[df['dataset'] == 'pd'])\n",
    "print(f\"{Majority} PD samples\")\n",
    "Minority = len(df.loc[df['dataset'] == 'snp'])\n",
    "print(f\"{Minority} PD samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb451c9e",
   "metadata": {},
   "source": [
    "## Split into training and testing, generate RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbfacd1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    4.3s finished\n"
     ]
    }
   ],
   "source": [
    "Input_train, Input_test, Classes_train, Classes_test = train_test_split(Input, Output, train_size = 0.8, random_state=42, stratify=Output) #80% training and 20% testing split. Strartify ensures fixed poportion of output labels is in both sets. Input attributes and class labels, training attributes and class label etc\n",
    "start=time.time() #Start timer for inital training model building\n",
    "RFC = RandomForestClassifier(random_state = 42, n_estimators = 1000, verbose = 1) #Defines the Random Forest. 42 seeds, 1000 trees\n",
    "RFC.fit(Input_train, Classes_train) #Generates a random forest from the training data\n",
    "\n",
    "with open('Training Data.txt', 'w') as file: #Writes class labels for all instances to text file\n",
    "    file.write(Input_train.to_string())\n",
    "    \n",
    "with open('Class labels.txt', 'w') as file: #Writes class labels for all instances to text file\n",
    "    file.write(Output.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2cdf65",
   "metadata": {},
   "source": [
    "### Plotting a tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f86678f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(nrows = 1,ncols = 1,figsize = (10,10), dpi=130)\n",
    "# tree.plot_tree(RFC.estimators_[45],\n",
    "#                feature_names = None, \n",
    "#                class_names= None,\n",
    "#                filled = True)\n",
    "# plt.show()\n",
    "# plt.savefig('clf_individualtree.png', bbox_inches = 'tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e8b7f5",
   "metadata": {},
   "source": [
    "## Training (revisit params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf8d9857",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[145  78]\n",
      " [ 27 424]]\n",
      "MCC:\n",
      " 0.6371468255225344\n",
      "F1:\n",
      " 0.8898216159496328\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.65      0.73       223\n",
      "           1       0.84      0.94      0.89       451\n",
      "\n",
      "    accuracy                           0.84       674\n",
      "   macro avg       0.84      0.80      0.81       674\n",
      "weighted avg       0.84      0.84      0.84       674\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "# StandardScaler().fit(X_train).transform(X_train) #Scales data \n",
    "# pipeline = make_pipeline( #Sets the random forest parameters\n",
    "#     StandardScaler(),\n",
    "#     LogisticRegression(solver='saga', max_iter=2000),\n",
    "#     verbose=2\n",
    "#  )\n",
    "RFC.get_params()\n",
    "# Evaluation of training before weighted vote\n",
    "\n",
    "Output_pred = RFC.predict(Input_test) #Always perdict on the unseen test data, as train has been used by the estimastor\n",
    "print(f\"Confusion Matrix:\\n {confusion_matrix(Classes_test, Output_pred)}\")\n",
    "print(f\"MCC:\\n {matthews_corrcoef(Classes_test, Output_pred)}\")\n",
    "print(\"F1:\\n\", f1_score(Classes_test, Output_pred))\n",
    "print(classification_report(Classes_test, Output_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5ae3dc",
   "metadata": {},
   "source": [
    "# Weighted Voting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a43542",
   "metadata": {},
   "source": [
    "### Input training sets for each class (PD and SNP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24405e5f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PD:1803\n",
      "SNP:891\n"
     ]
    }
   ],
   "source": [
    "Training_Outputs = pd.DataFrame([Output]).reset_index(drop=True).transpose() #Converts Output series to dataframe\n",
    "Training_Outputs.columns = ['Class'] #Names column 'Class'\n",
    "Majority_Class= Training_Outputs.drop(Training_Outputs[Training_Outputs['Class'] == 0].index) #Removes all SNP classes; only PD majority class remains\n",
    "Minority_Class = Training_Outputs.drop(Training_Outputs[Training_Outputs['Class'] == 1].index) #Removes all PD classes; only SNP minority class remains\n",
    "#print(\"PD:\",len(Majority_Class),\"SNP:\", len(Minority_Class))\n",
    "\n",
    "# Only the rows in input training set that are PD\n",
    "Input_PD_train = Input_train.loc[Input_train.index.isin(Majority_Class.index.values)]\n",
    "Classes_PD_train = Classes_train.loc[Classes_train.index.isin(Majority_Class.index.values)] #Labels training data of only PD. 1803\n",
    "\n",
    "# Only the rows in X (input training set) that are SNP\n",
    "Input_SNP_train = Input_train.loc[Input_train.index.isin(Minority_Class.index.values)]\n",
    "Classes_SNP_train = Classes_train.loc[Classes_train.index.isin(Minority_Class.index.values)] #Labels training data of only SNP. 891\n",
    "\n",
    "print(f\"PD:{len(Input_PD_train)}\\nSNP:{len(Input_SNP_train)}\") #Returns the number of only PD or SNP instances in respective training data sets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118067a2",
   "metadata": {},
   "source": [
    "### Find majority:minority ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6746be83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imbalance ratio:\n",
      "2.0235690235690234:1\n",
      "5 balancing folds needed.\n"
     ]
    }
   ],
   "source": [
    "def Ratio_divide(): #Finds ratio between the 2 classes (i.e the imbalance) and the number of folds required\n",
    "    a = len(Input_PD_train)\n",
    "    b = len(Input_SNP_train)\n",
    "    Divide = a/b\n",
    "    if Divide <= 1:\n",
    "        Ratio = 1/Divide\n",
    "    else:\n",
    "        Ratio = Divide\n",
    "        \n",
    "    if round(Ratio) % 2 == 0:\n",
    "        BF = 2 * round(Ratio) + 1\n",
    "    else:\n",
    "        BF = round(Ratio)\n",
    "    return Ratio, BF;\n",
    "Ratio, BF = Ratio_divide()\n",
    "print(f\"Imbalance ratio:\\n{Ratio}:1\\n{BF} balancing folds needed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b501a8",
   "metadata": {},
   "source": [
    "## Balancing via array index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5d1241bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Balancing_Fold():\n",
    "    Output_reset = Output.reset_index() #resets index and drops an un-needed \"index\" column\n",
    "    Output_Array = np.array(Output_reset) #Array of class labels. 1 = PD = majority, 0 = SNP = minority\n",
    "    Array = np.squeeze(Output_Array) #Makes array 1D\n",
    "\n",
    "    count_0 = 0\n",
    "    count_1 = 0\n",
    "    list_index = []\n",
    "    Array_loop = shuffle(Array)\n",
    "\n",
    "    for i in Array_loop:\n",
    "        index = int(i[0:1])\n",
    "        values = i[1:]\n",
    "\n",
    "        if values == 0 and count_0 < Minority:\n",
    "            count_0 += 1\n",
    "            list_index.append(index)\n",
    "        elif values == 1 and count_1 < Minority:\n",
    "            count_1 += 1\n",
    "            list_index.append(index)\n",
    "#     print(f\"PD:{count_1}\\nSNP:{count_0}\\nTotal:{count_1+count_0}\")\n",
    "\n",
    "    Balanced_Input = df.filter(list_index, axis = 0)\n",
    "    \n",
    "    BF_List = []\n",
    "    for i in range(BF):\n",
    "        BF_List.append(Balanced_Input)\n",
    "        \n",
    "    return BF_List\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "59873d9f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Binding', 'SProtFT0', 'SProtFT1', 'SProtFT2', 'SProtFT3', 'SProtFT4', 'SProtFT5', 'SProtFT6', 'SProtFT7', 'SProtFT8', 'SProtFT9', 'SProtFT10', 'SProtFT11', 'SProtFT12', 'Interface', 'Relaccess', 'Impact', 'HBonds', 'SPhobic', 'CPhilic', 'BCharge', 'SSGeom', 'Voids', 'MLargest1', 'MLargest2', 'MLargest3', 'MLargest4', 'MLargest5', 'MLargest6', 'MLargest7', 'MLargest8', 'MLargest9', 'MLargest10', 'NLargest1', 'NLargest2', 'NLargest3', 'NLargest4', 'NLargest5', 'NLargest6', 'NLargest7', 'NLargest8', 'NLargest9', 'NLargest10', 'Clash', 'Glycine', 'Proline', 'CisPro'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [98], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m         BF_List[i]\u001b[38;5;241m.\u001b[39mdrop(labels\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBinding\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSProtFT0\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSProtFT1\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSProtFT2\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSProtFT3\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSProtFT4\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSProtFT5\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSProtFT6\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSProtFT7\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSProtFT8\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSProtFT9\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSProtFT10\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSProtFT11\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSProtFT12\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInterface\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRelaccess\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImpact\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHBonds\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSPhobic\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCPhilic\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBCharge\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSSGeom\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVoids\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMLargest1\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMLargest2\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMLargest3\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMLargest4\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMLargest5\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMLargest6\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMLargest7\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMLargest8\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMLargest9\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMLargest10\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNLargest1\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNLargest2\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNLargest3\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNLargest4\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNLargest5\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNLargest6\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNLargest7\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNLargest8\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNLargest9\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNLargest10\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClash\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGlycine\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProline\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCisPro\u001b[39m\u001b[38;5;124m'\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m BF_List\n\u001b[1;32m----> 6\u001b[0m \u001b[43mClean_Balance_Fold\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn [98], line 4\u001b[0m, in \u001b[0;36mClean_Balance_Fold\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mClean_Balance_Fold\u001b[39m():\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(BF):\n\u001b[1;32m----> 4\u001b[0m         \u001b[43mBF_List\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBinding\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSProtFT0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSProtFT1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSProtFT2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSProtFT3\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSProtFT4\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSProtFT5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSProtFT6\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSProtFT7\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSProtFT8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSProtFT9\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSProtFT10\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSProtFT11\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSProtFT12\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mInterface\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRelaccess\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mImpact\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mHBonds\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSPhobic\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCPhilic\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBCharge\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSSGeom\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mVoids\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMLargest1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMLargest2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMLargest3\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMLargest4\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMLargest5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMLargest6\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMLargest7\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMLargest8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMLargest9\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMLargest10\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNLargest1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNLargest2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNLargest3\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNLargest4\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNLargest5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNLargest6\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNLargest7\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNLargest8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNLargest9\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNLargest10\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mClash\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGlycine\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mProline\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCisPro\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m BF_List\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\util\\_decorators.py:317\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    312\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    313\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    314\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    315\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(inspect\u001b[38;5;241m.\u001b[39mcurrentframe()),\n\u001b[0;32m    316\u001b[0m     )\n\u001b[1;32m--> 317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:5391\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5243\u001b[0m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, allowed_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m   5244\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[0;32m   5245\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5252\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5253\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5254\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5255\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5256\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5389\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5390\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5391\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5392\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5393\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5394\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5395\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5396\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5397\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5398\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5399\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\util\\_decorators.py:317\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    312\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    313\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    314\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    315\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(inspect\u001b[38;5;241m.\u001b[39mcurrentframe()),\n\u001b[0;32m    316\u001b[0m     )\n\u001b[1;32m--> 317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\generic.py:4510\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4508\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4509\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4510\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4513\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\generic.py:4551\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4549\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4550\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4551\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4552\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4554\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4555\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6972\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6970\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   6971\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 6972\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(labels[mask])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6973\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   6974\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Binding', 'SProtFT0', 'SProtFT1', 'SProtFT2', 'SProtFT3', 'SProtFT4', 'SProtFT5', 'SProtFT6', 'SProtFT7', 'SProtFT8', 'SProtFT9', 'SProtFT10', 'SProtFT11', 'SProtFT12', 'Interface', 'Relaccess', 'Impact', 'HBonds', 'SPhobic', 'CPhilic', 'BCharge', 'SSGeom', 'Voids', 'MLargest1', 'MLargest2', 'MLargest3', 'MLargest4', 'MLargest5', 'MLargest6', 'MLargest7', 'MLargest8', 'MLargest9', 'MLargest10', 'NLargest1', 'NLargest2', 'NLargest3', 'NLargest4', 'NLargest5', 'NLargest6', 'NLargest7', 'NLargest8', 'NLargest9', 'NLargest10', 'Clash', 'Glycine', 'Proline', 'CisPro'] not found in axis\""
     ]
    }
   ],
   "source": [
    "Balancing_Fold()\n",
    "def Clean_Balance_Fold():\n",
    "    for i in range(BF):\n",
    "        BF_List[i].drop(labels=['Binding','SProtFT0','SProtFT1','SProtFT2','SProtFT3','SProtFT4','SProtFT5','SProtFT6','SProtFT7','SProtFT8','SProtFT9','SProtFT10','SProtFT11','SProtFT12','Interface','Relaccess','Impact','HBonds','SPhobic','CPhilic','BCharge','SSGeom','Voids','MLargest1','MLargest2','MLargest3','MLargest4','MLargest5','MLargest6','MLargest7','MLargest8','MLargest9','MLargest10','NLargest1','NLargest2','NLargest3','NLargest4','NLargest5','NLargest6','NLargest7','NLargest8','NLargest9','NLargest10','Clash','Glycine','Proline','CisPro'], axis=1, inplace=True)\n",
    "    return BF_List\n",
    "Clean_Balance_Fold()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4b8fdd",
   "metadata": {},
   "source": [
    "### Weighted voting for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "dead8029",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2       0.0\n",
       "5       0.0\n",
       "2054    0.0\n",
       "2055    0.0\n",
       "8       0.0\n",
       "       ... \n",
       "2025    0.0\n",
       "2027    0.0\n",
       "2034    0.0\n",
       "2036    0.0\n",
       "2039    0.0\n",
       "Length: 1171, dtype: float64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Apply weighted vote scheme for a predictor that outputs confidence value between 0 and 1 for each class. \n",
    "def Weighted_Proba(BF_Prob, BF_list):\n",
    "\n",
    "    # Identify which instance appear in all folds, uding the nth fold (random number)\n",
    "    intersect_index = set(BF_Prob[0].index.values) #index of all 1782 instances in first fold\n",
    "    \n",
    "    for i in BF_list: #for all 5 folds\n",
    "        intersect_index = intersect_index.intersection(set(BF_Prob[i].index.values)) #intersection checks if instances are in all folds\n",
    "    intersect_index_list = list(intersect_index) #converts set to list, 945 items\n",
    "\n",
    "    with open('All Instances.txt', 'w') as f:\n",
    "        for line in intersect_index_list:\n",
    "            f.write(f\"{line}\\n\")\n",
    "            \n",
    "    BF_prob_list_PD =[]\n",
    "    BF_prob_list_SNP =[]\n",
    "    for i in BF_list: #for all 5 folds\n",
    "        BF_Prob_instance = BF_Prob[i].loc[intersect_index_list,:] #Returns each dataframe with the common instances\n",
    "        BF_prob_list_PD.append(BF_Prob_instance.iloc[:,1] - BF_Prob_instance.iloc[:,0]) #PD - SNP prob\n",
    "        BF_prob_list_SNP.append(BF_Prob_instance.iloc[:,0] - BF_Prob_instance.iloc[:,1]) #SNP - PD prob   \n",
    "    \n",
    "    SNP_Sum = 0\n",
    "    for i in BF_list:\n",
    "        SNP_Sum += BF_prob_list_SNP[i]\n",
    "    PD_Sum = 0\n",
    "    for i in BF_list:\n",
    "        PD_Sum += BF_prob_list_PD[i]\n",
    "        \n",
    "    S_out = abs((PD_Sum - SNP_Sum)/(len(BF_list) * 2))\n",
    "    return(S_out)\n",
    "\n",
    "Weighted_Proba(BF_Prob = BF_List, BF_list=range(BF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee46ca48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Prob_PD = RFC.predict_proba(Input_PD_train) #Probability prediction, as a mean of all trees in RF, for the PD instances\n",
    "Prob_SNP = RFC.predict_proba(Input_SNP_train) #Probability prediction, as a mean of all trees in RF, for the SNP instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170a68d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build a model for each balancing fold, predict the confidence scores and find average for each, which gives final vote\n",
    " \n",
    "BF_RFC = RandomForestClassifier(random_state = 42, n_estimators = 100) #Defines the Random Forest. 42 seeds, 100 trees (increase)\n",
    "BF_Prob = []\n",
    "BF_Probtxt = []\n",
    "BF_data = []\n",
    "\n",
    "#Randomly samples the majority class PD, to the same size of minority class SNP, and scores confidence for each instance\n",
    "for i in range (BF):\n",
    "    a = Random_Seed()\n",
    "    BF_Input_PD_train = Input_PD_train.sample(frac = (1/Ratio), random_state = a//100) #Balanced PD input training data \n",
    "    BF_Classes_PD_train = Classes_PD_train.sample(frac = (1/Ratio), random_state = a//100) #Balanced PD output training data\n",
    "    \n",
    "    #Concatanates the input and output balancing fold training data, so a new RFC can be generated. Function\n",
    "    BF_Input_all = shuffle(pd.concat([BF_Input_PD_train, Input_SNP_train]), random_state = a//50)\n",
    "    BF_Output_all = shuffle(pd.concat([BF_Classes_PD_train, Classes_SNP_train]), random_state = a//50)\n",
    "    Full_set = pd.concat([BF_Input_all, BF_Output_all], axis = 1)\n",
    "\n",
    "\n",
    "    #Generates RF and calculates probabilities for each fold\n",
    "    BF_RFC.fit(BF_Input_all, BF_Output_all)\n",
    "    BF_data.append(Full_set) #Builds random forest from training data for each fold\n",
    "    \n",
    "    Prob_index = BF_RFC.predict_proba(BF_Input_all) #Predicts confidence score for each instance\n",
    "    Full_set[['SNP', 'PD']] = Prob_index\n",
    "    Prob_index = Full_set.drop(labels=['Binding','SProtFT0','SProtFT1','SProtFT2','SProtFT3','SProtFT4','SProtFT5','SProtFT6','SProtFT7','SProtFT8','SProtFT9','SProtFT10','SProtFT11','SProtFT12','Interface','Relaccess','Impact','HBonds','SPhobic','CPhilic','BCharge','SSGeom','Voids','MLargest1','MLargest2','MLargest3','MLargest4','MLargest5','MLargest6','MLargest7','MLargest8','MLargest9','MLargest10','NLargest1','NLargest2','NLargest3','NLargest4','NLargest5','NLargest6','NLargest7','NLargest8','NLargest9','NLargest10','Clash','Glycine','Proline','CisPro','dataset_pd'], axis=1, inplace=False)\n",
    "    #Becomes a list\n",
    "    BF_Prob.append(Prob_index) #List with probabilites for all instances\n",
    "    BF_Probtxt.append(Prob_index.to_string())\n",
    "    \n",
    "with open('Balanced probabilities.txt', 'w') as f:\n",
    "    for number, line in zip(range(BF), BF_Probtxt):\n",
    "        f.write(f\"Fold: {number}\\n\\n{line}\\n\\n\\n\")\n",
    "        \n",
    "with open('Balanced training data.txt', 'w') as f:\n",
    "    for number, fold in zip(range(BF), BF_data):\n",
    "        f.write(f\"Fold: {number}\\n\\n{fold}\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fe70fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "S_out_string = Weighted_Proba(BF_Prob, BF_list=range(BF)).to_string() #Write S_out to text file\n",
    "with open('S_out.txt', 'w') as f:\n",
    "    f.write(S_out_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05628e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BF_Prob[0].iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a322d7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final vote\n",
    "\n",
    "PD = BF_Prob[0].iloc[:,1].to_numpy()\n",
    "SNP = BF_Prob[0].iloc[:,0].to_numpy()\n",
    "# if np.greater(PD,SNP):\n",
    "\n",
    "# PD_Count = 0\n",
    "# SNP_Count = 0\n",
    "# for i in range(len(BF_Prob)):\n",
    "#     if np.greater(PD,SNP):\n",
    "#         PD_Count += 1\n",
    "#     elif BF_Prob[i].iloc[:,0] > BF_Prob[i].iloc[:,1]:\n",
    "#         SNP_Count += 1\n",
    "#     else:\n",
    "#         pass\n",
    "\n",
    "        \n",
    "\n",
    "# PD_Count = 0\n",
    "# for i in Weighted_Proba(BF_Prob, BF_list=range(BF)):\n",
    "#     if i > 0.5:\n",
    "#         PD_Count += 1\n",
    "#     else:\n",
    "#         pass\n",
    "# print(PD_Count,\"samples predicted to be PD\")\n",
    "\n",
    "# SNP_Count = 0\n",
    "# for i in Weighted_Proba(BF_Prob, BF_list=range(BF)):\n",
    "#     if i < 0.5:\n",
    "#         SNP_Count += 1\n",
    "#     else:\n",
    "#         pass\n",
    "# print(SNP_Count,\"samples predicted to be SNP\")\n",
    "\n",
    "\n",
    "# #Evaluation of training after weighted vote\n",
    "# Classes_pred = RFC.predict(Input_test)\n",
    "# print(f\"Confusion Matrix:\\n {confusion_matrix(Classes_test, Classes_pred)}\")\n",
    "# print(f\"MCC:\\n {matthews_corrcoef(Classes_test, Classes_pred)}\")\n",
    "# print(\"F1:\\n\", f1_score(Classes_test, Classes_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4af5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: retrive the probability from each tree for a single sample  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965f8777",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c426f23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # **Split data into training and test**\n",
    "# with open('SNPorPD.txt', 'w+') as f:\n",
    "#         data=f.read()\n",
    "#         f.write(str(y_test.to_string()))\n",
    "\n",
    "# # pipeline.fit(X, y) #applies list if transformers to give a fitted model\n",
    "\n",
    "plt.scatter(Classes_test, Output_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f620e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch = GridSearchCV( #validation\n",
    "    estimator = LogisticRegression(solver='saga'),\n",
    "    param_grid = {}, #dictionary of parameters to search through\n",
    "    cv = StratifiedKFold(),\n",
    "    n_jobs = 1, #how many processors to run in parallel\n",
    "    scoring = 'f1',\n",
    "    verbose = 3 \n",
    "    ).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15af356d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = clf.predict(X_test)\n",
    "# print(\"Training time:\", stop-start)\n",
    "# print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "# print(\"MCC:\\n\", matthews_corrcoef(y_test, y_pred))\n",
    "# print(\"F1:\\n\", f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1de8521",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 337.844,
   "position": {
    "height": "359.844px",
    "left": "1536px",
    "right": "20px",
    "top": "112px",
    "width": "354px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
