{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fcba82d",
   "metadata": {},
   "source": [
    "## Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5737f62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2 is inbalanced data set; ~2200 in PD and ~1100 in SNP\n",
    "# Goal is to predict if protein is a SNP or PD\n",
    "#ImprovedBalancing branch\n",
    "\n",
    "#Imports the required libraries and packages\n",
    "import pandas as pd  #Import for data manipulation in dataframes\n",
    "import numpy as np  #Array manipulation and calculates mean\n",
    "import matplotlib.pyplot as plt  #Graphing and plotting\n",
    "# show figures in jupyter instead of prompt window\n",
    "%matplotlib inline \n",
    "\n",
    "import random as rd\n",
    "import time\n",
    "import sys\n",
    "\n",
    "from sklearn import tree\n",
    "\n",
    "from sklearn.metrics import(\n",
    "    matthews_corrcoef,  # CC for evaluation\n",
    "    f1_score,  #F1 score for evaluation\n",
    "    balanced_accuracy_score, roc_auc_score, make_scorer,  #Scoring metrics\n",
    "    confusion_matrix,  #Creates the confusion matrix - stats on how accurate the test set output is\n",
    "    classification_report #Returns the F1 socre, precision, and recall of a prediction using a given model\n",
    "    )\n",
    "from sklearn.model_selection import(\n",
    "    train_test_split,  # Splits data frame into the training set and testing set\n",
    "    GridSearchCV,  # Cross validation to improve hyperparameters\n",
    "    StratifiedKFold\n",
    "        )\n",
    "from sklearn.ensemble import RandomForestClassifier #SK learn API for classificastion random forests\n",
    "from sklearn.tree import DecisionTreeClassifier #Single tree decisions \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.utils import shuffle #shuffles rows\n",
    "from sklearn.neighbors import KNeighborsClassifier #allows for confidence scores to be predicted for each\n",
    "\n",
    "np.set_printoptions(threshold=np.inf) #full array printing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2ffd97",
   "metadata": {},
   "source": [
    "## Random Seed function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6be2ee9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59676"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Random_Seed(): #Generates a random seed\n",
    "    random1 = rd.randrange(1,100) #Random integet between 1 and 100\n",
    "    random2 =  time.time() #Time since UTC epoch\n",
    "    Seed = int(random2//random1//1000)\n",
    "    return Seed\n",
    "Random_Seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddcc865",
   "metadata": {},
   "source": [
    "## Read the whole dataset - revis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62413d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 3368\n",
      "2254 PD samples\n",
      "1111 SNP samples\n"
     ]
    }
   ],
   "source": [
    "#Create, clean and convert dataset E2.csv to PD dataframe**\n",
    "df = pd.read_csv('E2.csv')  #Create PD data frame from .csv\n",
    "df.drop(['pdbcode:chain:resnum:mutation'], axis=1, inplace=True)  #Removes unrequired columns. PDBcode may be needed for manual validation \n",
    "df.columns = df.columns.str.replace(' ', '_')  # Removes any blank attributes\n",
    "df.replace(' ', '_', regex=True, inplace=True)  # Replace all blank spaces with underscore (none were present)\n",
    "df.reset_index(drop=True, inplace = True) #Resets index numbering from 0 and drops column\n",
    "Input = df.drop('dataset', axis =1).fillna('0') #DF of input instances for classification training. Unknown attributes assigned 0\n",
    "Output_encoded = pd.get_dummies(df, columns=['dataset']) #One hot encoding dataset column so \"PD\" and \"SNP\" attributes are numerical 0 or 1\n",
    "Output = Output_encoded['dataset_pd'].copy().astype('int32') #Dataframe with 1 column where 1 = PD, 0 = SNP, integer\n",
    "\n",
    "print(\"Total samples:\", len(df))\n",
    "Majority = len(df.loc[df['dataset'] == 'pd'])\n",
    "print(f\"{Majority} PD samples\")\n",
    "Minority = len(df.loc[df['dataset'] == 'snp'])\n",
    "print(f\"{Minority} SNP samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb451c9e",
   "metadata": {},
   "source": [
    "## Split into training and testing, generate RF (whole dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbfacd1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    4.2s finished\n"
     ]
    }
   ],
   "source": [
    "Input_train, Input_test, Classes_train, Classes_test = train_test_split(Input, Output, train_size = 0.8, random_state=42, stratify=Output) #80% training and 20% testing split. Strartify ensures fixed poportion of output labels is in both sets. Input attributes and class labels, training attributes and class label etc\n",
    "start=time.time() #Start timer for inital training model building\n",
    "RFC = RandomForestClassifier(random_state = 42, n_estimators = 1000, verbose = 1) #Defines the Random Forest. 42 seeds, 1000 trees\n",
    "RFC.fit(Input_train, Classes_train) #Generates a random forest from the training data\n",
    "with open('Training Data.txt', 'w') as file: #Writes class labels for all instances to text file\n",
    "    file.write(Input_train.to_string())\n",
    "    \n",
    "with open('Class labels.txt', 'w') as file: #Writes class labels for all instances to text file\n",
    "    file.write(Classes_train.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e8b7f5",
   "metadata": {},
   "source": [
    "### Training (revisit params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cf8d9857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[145  78]\n",
      " [ 27 424]]\n",
      "MCC:\n",
      " 0.6371468255225344\n",
      "F1:\n",
      " 0.8898216159496328\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.65      0.73       223\n",
      "           1       0.84      0.94      0.89       451\n",
      "\n",
      "    accuracy                           0.84       674\n",
      "   macro avg       0.84      0.80      0.81       674\n",
      "weighted avg       0.84      0.84      0.84       674\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "# StandardScaler().fit(X_train).transform(X_train) #Scales data \n",
    "# pipeline = make_pipeline( #Sets the random forest parameters\n",
    "#     StandardScaler(),\n",
    "#     LogisticRegression(solver='saga', max_iter=2000),\n",
    "#     verbose=2\n",
    "# )\n",
    "RFC.get_params()\n",
    "# Evaluation of training before weighted vote\n",
    "\n",
    "Output_pred = RFC.predict(Input_test) #Always perdict on the unseen test data, as train has been used by the estimastor\n",
    "print(f\"Confusion Matrix:\\n {confusion_matrix(Classes_test, Output_pred)}\")\n",
    "print(f\"MCC:\\n {matthews_corrcoef(Classes_test, Output_pred)}\")\n",
    "print(\"F1:\\n\", f1_score(Classes_test, Output_pred))\n",
    "print(classification_report(Classes_test, Output_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118067a2",
   "metadata": {},
   "source": [
    "### Find majority:minority ratio and number of balancing folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6746be83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Balance_ratio(Major, Minor): #Finds ratio between the 2 classes (i.e the imbalance) and the number of folds required\n",
    "    Divide = Majority/Minority\n",
    "    if Divide <= 1:\n",
    "        Ratio = 1/Divide\n",
    "    else:\n",
    "        Ratio = Divide\n",
    "        \n",
    "    if round(Ratio) % 2 == 0:\n",
    "        BF = 2 * round(Ratio) + 1\n",
    "    else:\n",
    "        BF = round(Ratio)\n",
    "        \n",
    "    print(f\"Imbalance ratio:\\n{Ratio}:1\\n{BF} balancing folds needed.\")\n",
    "    return BF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b501a8",
   "metadata": {},
   "source": [
    "### Balancing via array index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "76a89536",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Minority_length(labels): #Finds the minority class size\n",
    "    SNP = 0\n",
    "    PD = 0\n",
    "    for i in labels:\n",
    "        if i == 0:\n",
    "            SNP +=1\n",
    "        if i == 1:\n",
    "            PD +=1\n",
    "    return SNP #returns the minority class length. [891]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5d1241bf",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2799,\n",
       " 2888,\n",
       " 1379,\n",
       " 1053,\n",
       " 1797,\n",
       " 1674,\n",
       " 1595,\n",
       " 1124,\n",
       " 3134,\n",
       " 610,\n",
       " 1937,\n",
       " 3011,\n",
       " 590,\n",
       " 394,\n",
       " 3341,\n",
       " 2170,\n",
       " 2012,\n",
       " 1873,\n",
       " 1483,\n",
       " 1825,\n",
       " 3038,\n",
       " 2702,\n",
       " 975,\n",
       " 2388,\n",
       " 1540,\n",
       " 3133,\n",
       " 2089,\n",
       " 2117,\n",
       " 1158,\n",
       " 3271,\n",
       " 889,\n",
       " 1134,\n",
       " 2820,\n",
       " 1630,\n",
       " 3118,\n",
       " 3292,\n",
       " 1269,\n",
       " 661,\n",
       " 810,\n",
       " 455,\n",
       " 2390,\n",
       " 1702,\n",
       " 1677,\n",
       " 952,\n",
       " 1218,\n",
       " 229,\n",
       " 2199,\n",
       " 698,\n",
       " 2101,\n",
       " 606,\n",
       " 857,\n",
       " 1236,\n",
       " 510,\n",
       " 879,\n",
       " 20,\n",
       " 2317,\n",
       " 1004,\n",
       " 1509,\n",
       " 2336,\n",
       " 3061,\n",
       " 2795,\n",
       " 3276,\n",
       " 1394,\n",
       " 2164,\n",
       " 2209,\n",
       " 3128,\n",
       " 411,\n",
       " 2614,\n",
       " 2151,\n",
       " 1360,\n",
       " 499,\n",
       " 2310,\n",
       " 1473,\n",
       " 1738,\n",
       " 3055,\n",
       " 348,\n",
       " 3037,\n",
       " 1974,\n",
       " 3225,\n",
       " 2018,\n",
       " 2746,\n",
       " 3148,\n",
       " 191,\n",
       " 1288,\n",
       " 273,\n",
       " 308,\n",
       " 3230,\n",
       " 309,\n",
       " 1163,\n",
       " 1979,\n",
       " 1876,\n",
       " 403,\n",
       " 2990,\n",
       " 685,\n",
       " 2017,\n",
       " 594,\n",
       " 324,\n",
       " 3245,\n",
       " 1518,\n",
       " 298,\n",
       " 2175,\n",
       " 179,\n",
       " 911,\n",
       " 1167,\n",
       " 2010,\n",
       " 90,\n",
       " 1259,\n",
       " 3032,\n",
       " 2915,\n",
       " 776,\n",
       " 404,\n",
       " 1670,\n",
       " 1282,\n",
       " 1014,\n",
       " 1844,\n",
       " 2783,\n",
       " 2245,\n",
       " 2433,\n",
       " 2540,\n",
       " 2454,\n",
       " 3342,\n",
       " 2413,\n",
       " 996,\n",
       " 819,\n",
       " 2826,\n",
       " 3029,\n",
       " 3103,\n",
       " 1468,\n",
       " 1933,\n",
       " 2137,\n",
       " 2462,\n",
       " 2695,\n",
       " 299,\n",
       " 1535,\n",
       " 2313,\n",
       " 2350,\n",
       " 2214,\n",
       " 1975,\n",
       " 2941,\n",
       " 3301,\n",
       " 508,\n",
       " 1040,\n",
       " 1231,\n",
       " 2212,\n",
       " 2094,\n",
       " 1261,\n",
       " 1576,\n",
       " 1392,\n",
       " 3136,\n",
       " 2309,\n",
       " 1548,\n",
       " 450,\n",
       " 2548,\n",
       " 2461,\n",
       " 247,\n",
       " 1587,\n",
       " 3195,\n",
       " 784,\n",
       " 2788,\n",
       " 2849,\n",
       " 2469,\n",
       " 1221,\n",
       " 565,\n",
       " 2176,\n",
       " 1545,\n",
       " 681,\n",
       " 3291,\n",
       " 2447,\n",
       " 1078,\n",
       " 347,\n",
       " 3166,\n",
       " 906,\n",
       " 2405,\n",
       " 2281,\n",
       " 1487,\n",
       " 1662,\n",
       " 1816,\n",
       " 2542,\n",
       " 2683,\n",
       " 1544,\n",
       " 2545,\n",
       " 1771,\n",
       " 1925,\n",
       " 1826,\n",
       " 2893,\n",
       " 493,\n",
       " 2124,\n",
       " 755,\n",
       " 901,\n",
       " 2326,\n",
       " 1592,\n",
       " 126,\n",
       " 2827,\n",
       " 1719,\n",
       " 863,\n",
       " 854,\n",
       " 783,\n",
       " 2931,\n",
       " 1756,\n",
       " 1881,\n",
       " 1494,\n",
       " 3165,\n",
       " 1804,\n",
       " 2338,\n",
       " 2760,\n",
       " 2183,\n",
       " 82,\n",
       " 668,\n",
       " 2752,\n",
       " 1126,\n",
       " 1515,\n",
       " 1824,\n",
       " 2361,\n",
       " 1887,\n",
       " 1147,\n",
       " 2256,\n",
       " 2686,\n",
       " 363,\n",
       " 1399,\n",
       " 2211,\n",
       " 1071,\n",
       " 1888,\n",
       " 838,\n",
       " 2514,\n",
       " 1530,\n",
       " 1883,\n",
       " 145,\n",
       " 735,\n",
       " 2412,\n",
       " 440,\n",
       " 1409,\n",
       " 1681,\n",
       " 441,\n",
       " 2671,\n",
       " 2396,\n",
       " 1132,\n",
       " 2732,\n",
       " 1391,\n",
       " 3078,\n",
       " 2292,\n",
       " 743,\n",
       " 2341,\n",
       " 2806,\n",
       " 1790,\n",
       " 1711,\n",
       " 1757,\n",
       " 605,\n",
       " 272,\n",
       " 2366,\n",
       " 1836,\n",
       " 593,\n",
       " 430,\n",
       " 543,\n",
       " 1355,\n",
       " 2547,\n",
       " 664,\n",
       " 1082,\n",
       " 2791,\n",
       " 121,\n",
       " 2072,\n",
       " 2944,\n",
       " 134,\n",
       " 818,\n",
       " 462,\n",
       " 3283,\n",
       " 3150,\n",
       " 1008,\n",
       " 390,\n",
       " 1099,\n",
       " 354,\n",
       " 2354,\n",
       " 1760,\n",
       " 999,\n",
       " 2060,\n",
       " 2174,\n",
       " 1267,\n",
       " 2796,\n",
       " 2356,\n",
       " 2869,\n",
       " 425,\n",
       " 1638,\n",
       " 2692,\n",
       " 271,\n",
       " 1130,\n",
       " 1546,\n",
       " 1350,\n",
       " 3351,\n",
       " 640,\n",
       " 3010,\n",
       " 1362,\n",
       " 1027,\n",
       " 1170,\n",
       " 1947,\n",
       " 1445,\n",
       " 131,\n",
       " 1119,\n",
       " 264,\n",
       " 2069,\n",
       " 306,\n",
       " 3250,\n",
       " 2643,\n",
       " 284,\n",
       " 2115,\n",
       " 3095,\n",
       " 759,\n",
       " 750,\n",
       " 2132,\n",
       " 1818,\n",
       " 2700,\n",
       " 1989,\n",
       " 2235,\n",
       " 327,\n",
       " 1862,\n",
       " 1731,\n",
       " 2234,\n",
       " 1278,\n",
       " 2979,\n",
       " 3121,\n",
       " 940,\n",
       " 408,\n",
       " 1870,\n",
       " 2625,\n",
       " 577,\n",
       " 2739,\n",
       " 2725,\n",
       " 259,\n",
       " 2054,\n",
       " 1758,\n",
       " 2605,\n",
       " 2744,\n",
       " 501,\n",
       " 1388,\n",
       " 1922,\n",
       " 2843,\n",
       " 1044,\n",
       " 3040,\n",
       " 858,\n",
       " 1512,\n",
       " 1850,\n",
       " 718,\n",
       " 228,\n",
       " 1295,\n",
       " 95,\n",
       " 3026,\n",
       " 1012,\n",
       " 1987,\n",
       " 2270,\n",
       " 1187,\n",
       " 2032,\n",
       " 992,\n",
       " 1849,\n",
       " 1179,\n",
       " 1686,\n",
       " 142,\n",
       " 2205,\n",
       " 1331,\n",
       " 1755,\n",
       " 426,\n",
       " 2606,\n",
       " 2261,\n",
       " 773,\n",
       " 2801,\n",
       " 263,\n",
       " 2840,\n",
       " 2580,\n",
       " 489,\n",
       " 2830,\n",
       " 412,\n",
       " 704,\n",
       " 22,\n",
       " 370,\n",
       " 2042,\n",
       " 566,\n",
       " 1890,\n",
       " 310,\n",
       " 1820,\n",
       " 1449,\n",
       " 825,\n",
       " 2897,\n",
       " 2975,\n",
       " 152,\n",
       " 295,\n",
       " 2299,\n",
       " 517,\n",
       " 337,\n",
       " 2383,\n",
       " 1871,\n",
       " 2709,\n",
       " 3221,\n",
       " 99,\n",
       " 1403,\n",
       " 2191,\n",
       " 3237,\n",
       " 1594,\n",
       " 1532,\n",
       " 1716,\n",
       " 1833,\n",
       " 2634,\n",
       " 1931,\n",
       " 2903,\n",
       " 2226,\n",
       " 2113,\n",
       " 2129,\n",
       " 2631,\n",
       " 1478,\n",
       " 1440,\n",
       " 10,\n",
       " 232,\n",
       " 2141,\n",
       " 2567,\n",
       " 1329,\n",
       " 133,\n",
       " 2364,\n",
       " 325,\n",
       " 2496,\n",
       " 2718,\n",
       " 2468,\n",
       " 993,\n",
       " 1387,\n",
       " 1614,\n",
       " 2041,\n",
       " 2090,\n",
       " 1588,\n",
       " 542,\n",
       " 1657,\n",
       " 588,\n",
       " 410,\n",
       " 2669,\n",
       " 736,\n",
       " 289,\n",
       " 1672,\n",
       " 2110,\n",
       " 2395,\n",
       " 1198,\n",
       " 153,\n",
       " 172,\n",
       " 788,\n",
       " 2005,\n",
       " 1085,\n",
       " 989,\n",
       " 1032,\n",
       " 64,\n",
       " 1063,\n",
       " 1213,\n",
       " 3249,\n",
       " 1112,\n",
       " 2437,\n",
       " 1127,\n",
       " 687,\n",
       " 473,\n",
       " 1108,\n",
       " 693,\n",
       " 1484,\n",
       " 2729,\n",
       " 3215,\n",
       " 883,\n",
       " 957,\n",
       " 872,\n",
       " 1024,\n",
       " 545,\n",
       " 2632,\n",
       " 1117,\n",
       " 1562,\n",
       " 2856,\n",
       " 892,\n",
       " 2039,\n",
       " 2530,\n",
       " 1000,\n",
       " 3357,\n",
       " 2865,\n",
       " 2301,\n",
       " 1829,\n",
       " 2184,\n",
       " 557,\n",
       " 2173,\n",
       " 345,\n",
       " 873,\n",
       " 1608,\n",
       " 3243,\n",
       " 1316,\n",
       " 2476,\n",
       " 614,\n",
       " 2714,\n",
       " 1406,\n",
       " 316,\n",
       " 150,\n",
       " 2513,\n",
       " 177,\n",
       " 2290,\n",
       " 3196,\n",
       " 457,\n",
       " 1336,\n",
       " 176,\n",
       " 2431,\n",
       " 2511,\n",
       " 2946,\n",
       " 2750,\n",
       " 1626,\n",
       " 1610,\n",
       " 392,\n",
       " 2368,\n",
       " 1920,\n",
       " 624,\n",
       " 2011,\n",
       " 1572,\n",
       " 3275,\n",
       " 2273,\n",
       " 683,\n",
       " 3204,\n",
       " 544,\n",
       " 774,\n",
       " 1632,\n",
       " 1568,\n",
       " 933,\n",
       " 3094,\n",
       " 361,\n",
       " 1156,\n",
       " 2581,\n",
       " 1323,\n",
       " 74,\n",
       " 1111,\n",
       " 212,\n",
       " 3160,\n",
       " 96,\n",
       " 1271,\n",
       " 764,\n",
       " 1940,\n",
       " 3156,\n",
       " 896,\n",
       " 128,\n",
       " 2627,\n",
       " 2441,\n",
       " 875,\n",
       " 31,\n",
       " 2773,\n",
       " 659,\n",
       " 3096,\n",
       " 677,\n",
       " 1923,\n",
       " 1076,\n",
       " 850,\n",
       " 2436,\n",
       " 422,\n",
       " 1917,\n",
       " 871,\n",
       " 2203,\n",
       " 369,\n",
       " 2681,\n",
       " 955,\n",
       " 421,\n",
       " 645,\n",
       " 1651,\n",
       " 1959,\n",
       " 1928,\n",
       " 3141,\n",
       " 1704,\n",
       " 612,\n",
       " 81,\n",
       " 1730,\n",
       " 1405,\n",
       " 1182,\n",
       " 988,\n",
       " 2167,\n",
       " 723,\n",
       " 3265,\n",
       " 912,\n",
       " 1086,\n",
       " 2302,\n",
       " 3229,\n",
       " 3322,\n",
       " 1284,\n",
       " 1469,\n",
       " 793,\n",
       " 2958,\n",
       " 328,\n",
       " 860,\n",
       " 1482,\n",
       " 1434,\n",
       " 2859,\n",
       " 2430,\n",
       " 109,\n",
       " 3021,\n",
       " 2393,\n",
       " 2833,\n",
       " 1286,\n",
       " 2178,\n",
       " 844,\n",
       " 779,\n",
       " 437,\n",
       " 1098,\n",
       " 155,\n",
       " 1673,\n",
       " 1305,\n",
       " 2327,\n",
       " 836,\n",
       " 769,\n",
       " 2213,\n",
       " 1383,\n",
       " 2251,\n",
       " 19,\n",
       " 2486,\n",
       " 1057,\n",
       " 1123,\n",
       " 3030,\n",
       " 148,\n",
       " 3262,\n",
       " 762,\n",
       " 1590,\n",
       " 2427,\n",
       " 3219,\n",
       " 1813,\n",
       " 2004,\n",
       " 2677,\n",
       " 811,\n",
       " 926,\n",
       " 2335,\n",
       " 695,\n",
       " 2838,\n",
       " 3331,\n",
       " 1789,\n",
       " 533,\n",
       " 2857,\n",
       " 2220,\n",
       " 2640,\n",
       " 1696,\n",
       " 2250,\n",
       " 2344,\n",
       " 944,\n",
       " 969,\n",
       " 2472,\n",
       " 3257,\n",
       " 1963,\n",
       " 569,\n",
       " 1395,\n",
       " 2996,\n",
       " 1706,\n",
       " 137,\n",
       " 568,\n",
       " 132,\n",
       " 1114,\n",
       " 1732,\n",
       " 3263,\n",
       " 692,\n",
       " 1528,\n",
       " 1986,\n",
       " 1698,\n",
       " 2591,\n",
       " 1426,\n",
       " 2228,\n",
       " 2215,\n",
       " 502,\n",
       " 1191,\n",
       " 3114,\n",
       " 799,\n",
       " 1620,\n",
       " 1874,\n",
       " 1188,\n",
       " 2854,\n",
       " 1655,\n",
       " 1160,\n",
       " 529,\n",
       " 2342,\n",
       " 2225,\n",
       " 2535,\n",
       " 2378,\n",
       " 2498,\n",
       " 3151,\n",
       " 1956,\n",
       " 2999,\n",
       " 326,\n",
       " 1131,\n",
       " 482,\n",
       " 3333,\n",
       " 1661,\n",
       " 166,\n",
       " 3200,\n",
       " 2778,\n",
       " 1581,\n",
       " 2229,\n",
       " 2721,\n",
       " 86,\n",
       " 382,\n",
       " 1748,\n",
       " 719,\n",
       " 1361,\n",
       " 467,\n",
       " 1840,\n",
       " 92,\n",
       " 3081,\n",
       " 2400,\n",
       " 1555,\n",
       " 608,\n",
       " 531,\n",
       " 895,\n",
       " 1462,\n",
       " 2818,\n",
       " 599,\n",
       " 2332,\n",
       " 2510,\n",
       " 1831,\n",
       " 1328,\n",
       " 1351,\n",
       " 362,\n",
       " 2221,\n",
       " 2092,\n",
       " 1900,\n",
       " 2589,\n",
       " 2370,\n",
       " 2223,\n",
       " 987,\n",
       " 891,\n",
       " 2917,\n",
       " 1802,\n",
       " 791,\n",
       " 3009,\n",
       " 1495,\n",
       " 1778,\n",
       " 1235,\n",
       " 497,\n",
       " 2276,\n",
       " 539,\n",
       " 2570,\n",
       " 2775,\n",
       " 790,\n",
       " 168,\n",
       " 598,\n",
       " 650,\n",
       " 756,\n",
       " 1536,\n",
       " 114,\n",
       " 639,\n",
       " 2534,\n",
       " 2684,\n",
       " 2119,\n",
       " 1435,\n",
       " 1308,\n",
       " 170,\n",
       " 2894,\n",
       " 1523,\n",
       " 1759,\n",
       " 1407,\n",
       " 1196,\n",
       " 2450,\n",
       " 2373,\n",
       " 3020,\n",
       " 2505,\n",
       " 851,\n",
       " 119,\n",
       " 1270,\n",
       " 2083,\n",
       " 1074,\n",
       " 884,\n",
       " 1806,\n",
       " 2983,\n",
       " 1370,\n",
       " 1671,\n",
       " 2497,\n",
       " 492,\n",
       " 2526,\n",
       " 3182,\n",
       " 520,\n",
       " 256,\n",
       " 626,\n",
       " 814,\n",
       " 2194,\n",
       " 2381,\n",
       " 1125,\n",
       " 1823,\n",
       " 794,\n",
       " 1860,\n",
       " 7,\n",
       " 709,\n",
       " 3330,\n",
       " 1181,\n",
       " 1839,\n",
       " 1926,\n",
       " 745,\n",
       " 204,\n",
       " 3120,\n",
       " 2339,\n",
       " 2938,\n",
       " 2308,\n",
       " 2253,\n",
       " 357,\n",
       " 3060,\n",
       " 2582,\n",
       " 3057,\n",
       " 1968,\n",
       " 2448,\n",
       " 1531,\n",
       " 466,\n",
       " 3317,\n",
       " 601,\n",
       " 2409,\n",
       " 1764,\n",
       " 302,\n",
       " 2841,\n",
       " 1601,\n",
       " 3168,\n",
       " 2904,\n",
       " 2369,\n",
       " 1094,\n",
       " 2902,\n",
       " 49,\n",
       " 1858,\n",
       " 238,\n",
       " 3139,\n",
       " 2063,\n",
       " 333,\n",
       " 3125,\n",
       " 2293,\n",
       " 1324,\n",
       " 1754,\n",
       " 1842,\n",
       " 1682,\n",
       " 591,\n",
       " 79,\n",
       " 3007,\n",
       " 671,\n",
       " 117,\n",
       " 2330,\n",
       " 1281,\n",
       " 1148,\n",
       " 2724,\n",
       " 1791,\n",
       " 1773,\n",
       " 414,\n",
       " 338,\n",
       " 91,\n",
       " 2968,\n",
       " 551,\n",
       " 2048,\n",
       " 2568,\n",
       " 488,\n",
       " 1643,\n",
       " 372,\n",
       " 2147,\n",
       " 293,\n",
       " 243,\n",
       " 2573,\n",
       " 2945,\n",
       " 275,\n",
       " 3273,\n",
       " 1550,\n",
       " 1902,\n",
       " 766,\n",
       " 908,\n",
       " 1970,\n",
       " 3017,\n",
       " 998,\n",
       " 2116,\n",
       " 1538,\n",
       " 396,\n",
       " 1408,\n",
       " 2717,\n",
       " 1799,\n",
       " 1877,\n",
       " 2111,\n",
       " 1223,\n",
       " 2555,\n",
       " 3036,\n",
       " 159,\n",
       " 1041,\n",
       " 1577,\n",
       " 2751,\n",
       " 2780,\n",
       " 1203,\n",
       " 2936,\n",
       " 876,\n",
       " 3224,\n",
       " 3234,\n",
       " 2029,\n",
       " 375,\n",
       " 57,\n",
       " 669,\n",
       " 1088,\n",
       " 638,\n",
       " 200,\n",
       " 2886,\n",
       " 2851,\n",
       " 966,\n",
       " 2549,\n",
       " 2507,\n",
       " 1784,\n",
       " 2224,\n",
       " 2673,\n",
       " 1244,\n",
       " 1364,\n",
       " 2541,\n",
       " 2189,\n",
       " 2523,\n",
       " 1935,\n",
       " 3022,\n",
       " 1205,\n",
       " 2939,\n",
       " 46,\n",
       " 239,\n",
       " 1423,\n",
       " 61,\n",
       " 1022,\n",
       " 2095,\n",
       " 2733,\n",
       " 1018,\n",
       " 994,\n",
       " 705,\n",
       " 1571,\n",
       " 1997,\n",
       " 334,\n",
       " 1910,\n",
       " 1851,\n",
       " 391,\n",
       " 351,\n",
       " 2130,\n",
       " 329,\n",
       " 1376,\n",
       " 1238,\n",
       " 464,\n",
       " 1559,\n",
       " 2394,\n",
       " 3074,\n",
       " 14,\n",
       " 2500,\n",
       " 330,\n",
       " 3321,\n",
       " 2333,\n",
       " 3244,\n",
       " 36,\n",
       " 1787,\n",
       " 3140,\n",
       " 2103,\n",
       " 3353,\n",
       " 3014,\n",
       " 3047,\n",
       " 516,\n",
       " 1129,\n",
       " 3348,\n",
       " 3012,\n",
       " 2907,\n",
       " 1980,\n",
       " 2774,\n",
       " 1298,\n",
       " 2036,\n",
       " 2020,\n",
       " 1810,\n",
       " 2575,\n",
       " 803,\n",
       " 2898,\n",
       " 2612,\n",
       " 935,\n",
       " 2661,\n",
       " 2073,\n",
       " 3217,\n",
       " 8,\n",
       " 2074,\n",
       " 3066,\n",
       " 2901,\n",
       " 907,\n",
       " 2421,\n",
       " 2056,\n",
       " 3184,\n",
       " 1279,\n",
       " 3352,\n",
       " 9,\n",
       " 2086,\n",
       " 732,\n",
       " 312,\n",
       " 1659,\n",
       " 458,\n",
       " 2807,\n",
       " 3191,\n",
       " 3279,\n",
       " 1741,\n",
       " 385,\n",
       " 1189,\n",
       " 2866,\n",
       " 60,\n",
       " 2790,\n",
       " 1465,\n",
       " 1306,\n",
       " 1633,\n",
       " 1430,\n",
       " 3187,\n",
       " 405,\n",
       " 2478,\n",
       " 2997,\n",
       " 1801,\n",
       " 2196,\n",
       " 2279,\n",
       " 1498,\n",
       " 443,\n",
       " 574,\n",
       " 3170,\n",
       " 2177,\n",
       " 1095,\n",
       " 3013,\n",
       " 2703,\n",
       " 2810,\n",
       " 1964,\n",
       " 1918,\n",
       " 2059,\n",
       " ...]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Balance(length, labels): #Balances the dataset \n",
    "    Array = np.column_stack((labels.index, labels)) #Array of class labels. 1 = PD = majority, 0 = SNP = minority\n",
    "    \n",
    "    count_0 = 0\n",
    "    count_1 = 0\n",
    "    list_index = []\n",
    "    Array_loop = shuffle(Array)\n",
    "    \n",
    "    for i in Array_loop:\n",
    "        index = int(i[0:1]) #element index\n",
    "        values = i[1:] #element values\n",
    "\n",
    "        if values == 0 and count_0 < length:\n",
    "            count_0 += 1\n",
    "            list_index.append(index)\n",
    "        elif values == 1 and count_1 < length:\n",
    "            count_1 += 1\n",
    "            list_index.append(index)\n",
    "            \n",
    "#     print(f\"PD:{count_1}\\nSNP:{count_0}\\nTotal:{count_1+count_0}\")\n",
    "\n",
    "    return list_index #Returns a list of indicies with random, equal SNPs and PDs. [891]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "59873d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def Balancing_Fold(Fold, BF): #Output n number of balance folds instances as a list\n",
    "#     list_index_BF = []\n",
    "#     for i in range(BF):\n",
    "#         Fold #Call balanced data, different for each loop  \n",
    "#         list_index_BF.append(Fold)\n",
    "#     return list_index_BF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea8505e",
   "metadata": {},
   "source": [
    "### Train balanced data on random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1decd7a3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def BF_training(BF): #Creates a model then returns probability predictions for each fold, using the list of indicies as input\n",
    "    BF_RFC = RandomForestClassifier(random_state = 42, n_estimators = 1000, verbose = 1) #Defines the Random Forest. 42 seeds, 1000 trees\n",
    "    Prob_list = []\n",
    "    Prob_liststr = [] #for file\n",
    "    BF_data = []\n",
    "    \n",
    "    for i in range(BF):\n",
    "        Folds = Balance(length = Minority_length(labels = Classes_train), labels = Classes_train)\n",
    "        Input = Input_train.filter(Folds, axis = 0)\n",
    "        Output = Classes_train.filter(Folds, axis = 0)\n",
    "        \n",
    "        combined = pd.concat([Input, Output], axis =1) #Combines input and output data so can be displayed easily\n",
    "        BF_data.append(combined)\n",
    "        \n",
    "        BF_RFC.fit(Input, Output) #Generates a random forest for each fold's training data\n",
    "        Prob = BF_RFC.predict_proba(Input) #Predicted class label from input training data\n",
    "        \n",
    "        combined[['SNP', 'PD']] = Prob\n",
    "        Prob = combined.drop(labels=['Binding','SProtFT0','SProtFT1','SProtFT2','SProtFT3','SProtFT4','SProtFT5','SProtFT6','SProtFT7','SProtFT8','SProtFT9','SProtFT10','SProtFT11','SProtFT12','Interface','Relaccess','Impact','HBonds','SPhobic','CPhilic','BCharge','SSGeom','Voids','MLargest1','MLargest2','MLargest3','MLargest4','MLargest5','MLargest6','MLargest7','MLargest8','MLargest9','MLargest10','NLargest1','NLargest2','NLargest3','NLargest4','NLargest5','NLargest6','NLargest7','NLargest8','NLargest9','NLargest10','Clash','Glycine','Proline','CisPro','dataset_pd'], axis=1, inplace=False)\n",
    "        #Becomes a list\n",
    "        Prob_list.append(Prob) #List with probabilites for all instances, with indicies\n",
    "        Prob_liststr.append(Prob.to_string()) #List with probabilites for all instances as string\n",
    "\n",
    "    with open('Balanced probabilities.txt', 'w') as f:\n",
    "        for number, line in zip(range(BF), Prob_liststr):\n",
    "            f.write(f\"Fold: {number}\\n\\n{line}\\n\\n\\n\")\n",
    "        \n",
    "    with open('Balanced training data.txt', 'w') as f:\n",
    "        for number, fold in zip(range(BF), BF_data):\n",
    "            f.write(f\"Fold: {number}\\n\\n{fold}\\n\\n\\n\")\n",
    "                \n",
    "    return Prob_list #Returns n number of randomly balanced dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4b8fdd",
   "metadata": {},
   "source": [
    "### Weighted voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "dead8029",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply weighted vote scheme for a predictor that outputs confidence value between 0 and 1 for each class. \n",
    "def Weighted_Proba(BF_Prob, BF):\n",
    "\n",
    "    # Identify which instance appear in all folds, using the nth fold (random number)(change for all values)\n",
    "    intersect_index = set(BF_Prob[0].index.values) #index of all 1782 instances in first fold\n",
    "    \n",
    "    for i in range(BF): #for all 5 folds\n",
    "        intersect_index = intersect_index.intersection(set(BF_Prob[i].index.values)) #intersection checks if instances are in all folds\n",
    "    intersect_index_list = list(intersect_index) #converts set to list, 936 items\n",
    "    \n",
    "    BF_common = []\n",
    "    for i in range(BF): #for all 5 folds\n",
    "        BF_Prob_instance = BF_Prob[i].loc[intersect_index_list,:] #Returns each df with the common instances\n",
    "        BF_common.append(BF_Prob_instance)\n",
    "        \n",
    "  \n",
    "    return BF_common #Returns the common instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "71033215",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Score(Instance, BF):\n",
    "    BF_prob_PD =[]\n",
    "    BF_prob_SNP =[]\n",
    "    for i in range(BF):\n",
    "        BF_prob_PD.append(Instance.iloc[:,1] - Instance.iloc[:,0]) #PD - SNP prob\n",
    "        BF_prob_SNP.append(Instance.iloc[:,0] - Instance.iloc[:,1]) #SNP - PD prob     \n",
    "    \n",
    "    PD_Sum = 0\n",
    "    for i in range(BF):\n",
    "        PD_Sum += BF_prob_PD[i]\n",
    "        \n",
    "    SNP_Sum = 0\n",
    "    for i in range(BF):\n",
    "        SNP_Sum += BF_prob_SNP[i]\n",
    "        \n",
    "    S_out = abs((PD_Sum - SNP_Sum)/(len(range(BF) * 2)))\n",
    "    \n",
    "    string = S_out.to_string\n",
    "    with open('S_out.txt', 'w') as f:\n",
    "        f.write(string)\n",
    "    \n",
    "    return(S_out) #Returns the final confidence scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a322d7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final vote\n",
    "def Final_vote(Instance, BF):\n",
    "    PD = Instance.iloc[:,1].to_numpy()\n",
    "    SNP = Instance.iloc[:,0].to_numpy()\n",
    "    # if np.greater(PD,SNP):\n",
    "\n",
    "    # PD_Count = 0\n",
    "    # SNP_Count = 0\n",
    "    # for i in range(len(BF_Prob)):\n",
    "    #     if np.greater(PD,SNP):\n",
    "    #         PD_Count += 1\n",
    "    #     elif BF_Prob[i].iloc[:,0] > BF_Prob[i].iloc[:,1]:\n",
    "    #         SNP_Count += 1\n",
    "    #     else:\n",
    "    #         pass\n",
    "\n",
    "\n",
    "\n",
    "    # PD_Count = 0\n",
    "    # for i in Weighted_Proba(BF_Prob, BF_list=range(BF)):\n",
    "    #     if i > 0.5:\n",
    "    #         PD_Count += 1\n",
    "    #     else:\n",
    "    #         pass\n",
    "    # print(PD_Count,\"samples predicted to be PD\")\n",
    "\n",
    "    # SNP_Count = 0\n",
    "    # for i in Weighted_Proba(BF_Prob, BF_list=range(BF)):\n",
    "    #     if i < 0.5:\n",
    "    #         SNP_Count += 1\n",
    "    #     else:\n",
    "    #         pass\n",
    "    # print(SNP_Count,\"samples predicted to be SNP\")\n",
    "\n",
    "\n",
    "    # #Evaluation of training after weighted vote\n",
    "    # Classes_pred = RFC.predict(Input_test)\n",
    "    # print(f\"Confusion Matrix:\\n {confusion_matrix(Classes_test, Classes_pred)}\")\n",
    "    # print(f\"MCC:\\n {matthews_corrcoef(Classes_test, Classes_pred)}\")\n",
    "    # print(\"F1:\\n\", f1_score(Classes_test, Classes_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4af5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: retrive the probability from each tree for a single sample  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9ce6740d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imbalance ratio:\n",
      "2.028802880288029:1\n",
      "5 balancing folds needed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    3.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    3.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    3.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    3.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    3.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'iloc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [93], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m BF \u001b[38;5;241m=\u001b[39m Balance_ratio(Major \u001b[38;5;241m=\u001b[39m Majority, Minor \u001b[38;5;241m=\u001b[39m Minority)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mFinal_vote\u001b[49m\u001b[43m(\u001b[49m\u001b[43mInstance\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mWeighted_Proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBF_Prob\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mBF_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBF\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBF\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mBF\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBF\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mBF\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn [85], line 3\u001b[0m, in \u001b[0;36mFinal_vote\u001b[1;34m(Instance, BF)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mFinal_vote\u001b[39m(Instance, BF):\n\u001b[1;32m----> 3\u001b[0m     PD \u001b[38;5;241m=\u001b[39m \u001b[43mInstance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m[:,\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mto_numpy()\n\u001b[0;32m      4\u001b[0m     SNP \u001b[38;5;241m=\u001b[39m Instance\u001b[38;5;241m.\u001b[39miloc[:,\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto_numpy()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'iloc'"
     ]
    }
   ],
   "source": [
    "BF = Balance_ratio(Major = Majority, Minor = Minority)\n",
    "Final_vote(Instance = Weighted_Proba(BF_Prob = BF_training(BF), BF = BF), BF = BF)\n",
    "Score = Instance = Weighted_Proba(BF_Prob = BF_training(BF), BF = BF), BF = BF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10b27af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "965f8777",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c426f23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # **Split data into training and test**\n",
    "# with open('SNPorPD.txt', 'w+') as f:\n",
    "#         data=f.read()\n",
    "#         f.write(str(y_test.to_string()))\n",
    "\n",
    "# # pipeline.fit(X, y) #applies list if transformers to give a fitted model\n",
    "\n",
    "plt.scatter(Classes_test, Output_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f620e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch = GridSearchCV( #validation\n",
    "    estimator = LogisticRegression(solver='saga'),\n",
    "    param_grid = {}, #dictionary of parameters to search through\n",
    "    cv = StratifiedKFold(),\n",
    "    n_jobs = 1, #how many processors to run in parallel\n",
    "    scoring = 'f1',\n",
    "    verbose = 3 \n",
    "    ).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15af356d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = clf.predict(X_test)\n",
    "# print(\"Training time:\", stop-start)\n",
    "# print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "# print(\"MCC:\\n\", matthews_corrcoef(y_test, y_pred))\n",
    "# print(\"F1:\\n\", f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1de8521",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 337.844,
   "position": {
    "height": "359.844px",
    "left": "1536px",
    "right": "20px",
    "top": "112px",
    "width": "354px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
