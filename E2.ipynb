{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fcba82d",
   "metadata": {},
   "source": [
    "## Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5737f62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2 is inbalanced data set; ~2200 in PD and ~1100 in SNP\n",
    "# Goal is to predict if protein is a SNP or PD\n",
    "#ImprovedBalancing branch\n",
    "\n",
    "#Imports the required libraries and packages\n",
    "import pandas as pd  #Import for data manipulation in dataframes\n",
    "import numpy as np  #Array manipulation and calculates mean\n",
    "import matplotlib.pyplot as plt  #Graphing and plotting\n",
    "# show figures in jupyter instead of prompt window\n",
    "%matplotlib inline \n",
    "\n",
    "import random as rd\n",
    "import time\n",
    "import sys\n",
    "\n",
    "from sklearn import tree\n",
    "\n",
    "from sklearn.metrics import(\n",
    "    matthews_corrcoef,  # CC for evaluation\n",
    "    f1_score,  #F1 score for evaluation\n",
    "    balanced_accuracy_score, roc_auc_score, make_scorer,  #Scoring metrics\n",
    "    confusion_matrix,  #Creates the confusion matrix - stats on how accurate the test set output is\n",
    "    classification_report #Returns the F1 socre, precision, and recall of a prediction using a given model\n",
    "    )\n",
    "from sklearn.model_selection import(\n",
    "    train_test_split,  # Splits data frame into the training set and testing set\n",
    "    GridSearchCV,  # Cross validation to improve hyperparameters\n",
    "    StratifiedKFold\n",
    "        )\n",
    "from sklearn.ensemble import RandomForestClassifier #SK learn API for classificastion random forests\n",
    "from sklearn.tree import DecisionTreeClassifier #Single tree decisions \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.utils import shuffle #shuffles rows\n",
    "from sklearn.neighbors import KNeighborsClassifier #allows for confidence scores to be predicted for each\n",
    "\n",
    "np.set_printoptions(threshold=np.inf) #full array printing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2ffd97",
   "metadata": {},
   "source": [
    "## Random Seed function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6be2ee9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79544"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Random_Seed(): #Generates a random seed\n",
    "    random1 = rd.randrange(1,100) #Random integet between 1 and 100\n",
    "    random2 =  time.time() #Time since UTC epoch\n",
    "    Seed = int(random2//random1//1000)\n",
    "    return Seed\n",
    "Random_Seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddcc865",
   "metadata": {},
   "source": [
    "## Read the whole dataset - revis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "62413d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 3368\n",
      "2254 PD samples\n",
      "1111 PD samples\n"
     ]
    }
   ],
   "source": [
    "#Create, clean and convert dataset E2.csv to PD dataframe**\n",
    "df = pd.read_csv('E2.csv')  #Create PD data frame from .csv\n",
    "df.drop(['pdbcode:chain:resnum:mutation'], axis=1, inplace=True)  #Removes unrequired columns. PDBcode may be needed for manual validation \n",
    "df.columns = df.columns.str.replace(' ', '_')  # Removes any blank attributes\n",
    "df.replace(' ', '_', regex=True, inplace=True)  # Replace all blank spaces with underscore (none were present)\n",
    "df.reset_index(drop=True, inplace = True) #Resets index numbering from 0 and drops column\n",
    "Input = df.drop('dataset', axis =1).fillna('0') #DF of input instances for classification training. Unknown attributes assigned 0\n",
    "Output_encoded = pd.get_dummies(df, columns=['dataset']) #One hot encoding dataset column so \"PD\" and \"SNP\" attributes are numerical 0 or 1\n",
    "Output = Output_encoded['dataset_pd'].copy().astype('int32') #Dataframe with 1 column where 1 = PD, 0 = SNP, integer\n",
    "\n",
    "print(\"Total samples:\", len(df))\n",
    "Majority = len(df.loc[df['dataset'] == 'pd'])\n",
    "print(f\"{Majority} PD samples\")\n",
    "Minority = len(df.loc[df['dataset'] == 'snp'])\n",
    "print(f\"{Minority} PD samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb451c9e",
   "metadata": {},
   "source": [
    "## Split into training and testing, generate RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbfacd1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    4.7s finished\n"
     ]
    }
   ],
   "source": [
    "Input_train, Input_test, Classes_train, Classes_test = train_test_split(Input, Output, train_size = 0.8, random_state=42, stratify=Output) #80% training and 20% testing split. Strartify ensures fixed poportion of output labels is in both sets. Input attributes and class labels, training attributes and class label etc\n",
    "start=time.time() #Start timer for inital training model building\n",
    "RFC = RandomForestClassifier(random_state = 42, n_estimators = 1000, verbose = 1) #Defines the Random Forest. 42 seeds, 1000 trees\n",
    "RFC.fit(Input_train, Classes_train) #Generates a random forest from the training data\n",
    "\n",
    "with open('Training Data.txt', 'w') as file: #Writes class labels for all instances to text file\n",
    "    file.write(Input_train.to_string())\n",
    "    \n",
    "with open('Class labels.txt', 'w') as file: #Writes class labels for all instances to text file\n",
    "    file.write(Output.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2cdf65",
   "metadata": {},
   "source": [
    "### Plotting a tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f86678f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(nrows = 1,ncols = 1,figsize = (10,10), dpi=130)\n",
    "# tree.plot_tree(RFC.estimators_[45],\n",
    "#                feature_names = None, \n",
    "#                class_names= None,\n",
    "#                filled = True)\n",
    "# plt.show()\n",
    "# plt.savefig('clf_individualtree.png', bbox_inches = 'tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e8b7f5",
   "metadata": {},
   "source": [
    "## Training (revisit params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf8d9857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[145  78]\n",
      " [ 27 424]]\n",
      "MCC:\n",
      " 0.6371468255225344\n",
      "F1:\n",
      " 0.8898216159496328\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.65      0.73       223\n",
      "           1       0.84      0.94      0.89       451\n",
      "\n",
      "    accuracy                           0.84       674\n",
      "   macro avg       0.84      0.80      0.81       674\n",
      "weighted avg       0.84      0.84      0.84       674\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "# StandardScaler().fit(X_train).transform(X_train) #Scales data \n",
    "# pipeline = make_pipeline( #Sets the random forest parameters\n",
    "#     StandardScaler(),\n",
    "#     LogisticRegression(solver='saga', max_iter=2000),\n",
    "#     verbose=2\n",
    "#  )\n",
    "RFC.get_params()\n",
    "# Evaluation of training before weighted vote\n",
    "\n",
    "Output_pred = RFC.predict(Input_test) #Always perdict on the unseen test data, as train has been used by the estimastor\n",
    "print(f\"Confusion Matrix:\\n {confusion_matrix(Classes_test, Output_pred)}\")\n",
    "print(f\"MCC:\\n {matthews_corrcoef(Classes_test, Output_pred)}\")\n",
    "print(\"F1:\\n\", f1_score(Classes_test, Output_pred))\n",
    "print(classification_report(Classes_test, Output_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5ae3dc",
   "metadata": {},
   "source": [
    "# Weighted Voting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b501a8",
   "metadata": {},
   "source": [
    "## Balancing via array index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5d1241bf",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1080,\n",
       " 1791,\n",
       " 108,\n",
       " 3105,\n",
       " 409,\n",
       " 2292,\n",
       " 567,\n",
       " 2158,\n",
       " 2454,\n",
       " 1526,\n",
       " 360,\n",
       " 388,\n",
       " 1005,\n",
       " 1762,\n",
       " 1752,\n",
       " 649,\n",
       " 536,\n",
       " 1862,\n",
       " 2647,\n",
       " 1536,\n",
       " 2636,\n",
       " 1749,\n",
       " 1235,\n",
       " 2252,\n",
       " 2582,\n",
       " 1358,\n",
       " 2738,\n",
       " 2671,\n",
       " 1477,\n",
       " 1201,\n",
       " 1782,\n",
       " 2180,\n",
       " 782,\n",
       " 958,\n",
       " 694,\n",
       " 565,\n",
       " 761,\n",
       " 1614,\n",
       " 1386,\n",
       " 1655,\n",
       " 2429,\n",
       " 2660,\n",
       " 1676,\n",
       " 2515,\n",
       " 3199,\n",
       " 2745,\n",
       " 714,\n",
       " 3226,\n",
       " 1687,\n",
       " 1560,\n",
       " 2433,\n",
       " 1143,\n",
       " 1545,\n",
       " 2782,\n",
       " 1633,\n",
       " 2612,\n",
       " 265,\n",
       " 1171,\n",
       " 1750,\n",
       " 2912,\n",
       " 2337,\n",
       " 2792,\n",
       " 518,\n",
       " 624,\n",
       " 1553,\n",
       " 2973,\n",
       " 286,\n",
       " 1730,\n",
       " 1570,\n",
       " 2205,\n",
       " 3118,\n",
       " 3142,\n",
       " 2831,\n",
       " 1278,\n",
       " 1704,\n",
       " 484,\n",
       " 1508,\n",
       " 165,\n",
       " 151,\n",
       " 1404,\n",
       " 1901,\n",
       " 2567,\n",
       " 3320,\n",
       " 390,\n",
       " 720,\n",
       " 2899,\n",
       " 223,\n",
       " 446,\n",
       " 3184,\n",
       " 1967,\n",
       " 40,\n",
       " 425,\n",
       " 1720,\n",
       " 2294,\n",
       " 479,\n",
       " 2986,\n",
       " 1783,\n",
       " 2530,\n",
       " 1567,\n",
       " 3294,\n",
       " 3010,\n",
       " 2021,\n",
       " 73,\n",
       " 951,\n",
       " 1950,\n",
       " 718,\n",
       " 2066,\n",
       " 368,\n",
       " 2881,\n",
       " 1590,\n",
       " 1778,\n",
       " 2144,\n",
       " 1515,\n",
       " 1635,\n",
       " 2670,\n",
       " 2488,\n",
       " 2688,\n",
       " 665,\n",
       " 663,\n",
       " 2860,\n",
       " 2876,\n",
       " 2518,\n",
       " 1354,\n",
       " 2751,\n",
       " 2552,\n",
       " 417,\n",
       " 1206,\n",
       " 2189,\n",
       " 1454,\n",
       " 858,\n",
       " 1509,\n",
       " 2730,\n",
       " 2796,\n",
       " 2607,\n",
       " 1701,\n",
       " 2815,\n",
       " 1607,\n",
       " 577,\n",
       " 1158,\n",
       " 3277,\n",
       " 890,\n",
       " 3237,\n",
       " 1465,\n",
       " 1930,\n",
       " 1126,\n",
       " 856,\n",
       " 177,\n",
       " 3044,\n",
       " 1817,\n",
       " 1192,\n",
       " 1339,\n",
       " 2503,\n",
       " 3339,\n",
       " 27,\n",
       " 848,\n",
       " 1094,\n",
       " 1241,\n",
       " 812,\n",
       " 3001,\n",
       " 3308,\n",
       " 997,\n",
       " 3179,\n",
       " 3136,\n",
       " 2908,\n",
       " 2956,\n",
       " 2600,\n",
       " 2342,\n",
       " 3241,\n",
       " 622,\n",
       " 2312,\n",
       " 2789,\n",
       " 21,\n",
       " 1744,\n",
       " 3156,\n",
       " 3231,\n",
       " 1836,\n",
       " 1283,\n",
       " 1923,\n",
       " 1236,\n",
       " 320,\n",
       " 1651,\n",
       " 1359,\n",
       " 50,\n",
       " 3083,\n",
       " 2672,\n",
       " 2446,\n",
       " 2248,\n",
       " 2516,\n",
       " 384,\n",
       " 2963,\n",
       " 415,\n",
       " 406,\n",
       " 2000,\n",
       " 3092,\n",
       " 2185,\n",
       " 1702,\n",
       " 3029,\n",
       " 2367,\n",
       " 2393,\n",
       " 35,\n",
       " 1890,\n",
       " 2213,\n",
       " 2186,\n",
       " 1401,\n",
       " 3137,\n",
       " 471,\n",
       " 1332,\n",
       " 3183,\n",
       " 922,\n",
       " 3266,\n",
       " 3261,\n",
       " 2027,\n",
       " 2940,\n",
       " 159,\n",
       " 1295,\n",
       " 820,\n",
       " 1144,\n",
       " 2226,\n",
       " 3311,\n",
       " 1569,\n",
       " 937,\n",
       " 3007,\n",
       " 2265,\n",
       " 2625,\n",
       " 1745,\n",
       " 340,\n",
       " 2409,\n",
       " 702,\n",
       " 1909,\n",
       " 2121,\n",
       " 2592,\n",
       " 361,\n",
       " 1652,\n",
       " 1618,\n",
       " 2954,\n",
       " 2184,\n",
       " 488,\n",
       " 2704,\n",
       " 914,\n",
       " 1592,\n",
       " 3324,\n",
       " 1044,\n",
       " 168,\n",
       " 1751,\n",
       " 3177,\n",
       " 3281,\n",
       " 269,\n",
       " 3303,\n",
       " 666,\n",
       " 1407,\n",
       " 2802,\n",
       " 2300,\n",
       " 373,\n",
       " 2148,\n",
       " 2816,\n",
       " 1870,\n",
       " 1102,\n",
       " 2767,\n",
       " 1535,\n",
       " 2936,\n",
       " 810,\n",
       " 661,\n",
       " 751,\n",
       " 1133,\n",
       " 2559,\n",
       " 2059,\n",
       " 1246,\n",
       " 211,\n",
       " 2674,\n",
       " 3220,\n",
       " 693,\n",
       " 980,\n",
       " 2301,\n",
       " 3325,\n",
       " 1251,\n",
       " 2755,\n",
       " 1928,\n",
       " 1469,\n",
       " 1057,\n",
       " 976,\n",
       " 29,\n",
       " 572,\n",
       " 3085,\n",
       " 1285,\n",
       " 988,\n",
       " 747,\n",
       " 1662,\n",
       " 351,\n",
       " 2302,\n",
       " 1628,\n",
       " 1478,\n",
       " 1413,\n",
       " 221,\n",
       " 38,\n",
       " 967,\n",
       " 1753,\n",
       " 1368,\n",
       " 1874,\n",
       " 1629,\n",
       " 1136,\n",
       " 675,\n",
       " 2391,\n",
       " 3304,\n",
       " 318,\n",
       " 1142,\n",
       " 12,\n",
       " 827,\n",
       " 570,\n",
       " 1048,\n",
       " 2341,\n",
       " 2548,\n",
       " 2384,\n",
       " 2196,\n",
       " 150,\n",
       " 2251,\n",
       " 1424,\n",
       " 1801,\n",
       " 3301,\n",
       " 2222,\n",
       " 1620,\n",
       " 2116,\n",
       " 2644,\n",
       " 362,\n",
       " 79,\n",
       " 2162,\n",
       " 1748,\n",
       " 1549,\n",
       " 1462,\n",
       " 3011,\n",
       " 2286,\n",
       " 1342,\n",
       " 2227,\n",
       " 421,\n",
       " 443,\n",
       " 645,\n",
       " 243,\n",
       " 1680,\n",
       " 629,\n",
       " 867,\n",
       " 1580,\n",
       " 386,\n",
       " 1517,\n",
       " 2768,\n",
       " 1076,\n",
       " 834,\n",
       " 14,\n",
       " 2988,\n",
       " 701,\n",
       " 1880,\n",
       " 1022,\n",
       " 2468,\n",
       " 2110,\n",
       " 1557,\n",
       " 1340,\n",
       " 1448,\n",
       " 2812,\n",
       " 2167,\n",
       " 1001,\n",
       " 2999,\n",
       " 2176,\n",
       " 435,\n",
       " 42,\n",
       " 1062,\n",
       " 2534,\n",
       " 2221,\n",
       " 1661,\n",
       " 3279,\n",
       " 170,\n",
       " 3149,\n",
       " 2396,\n",
       " 852,\n",
       " 1394,\n",
       " 2895,\n",
       " 2403,\n",
       " 1501,\n",
       " 592,\n",
       " 841,\n",
       " 2818,\n",
       " 532,\n",
       " 3107,\n",
       " 711,\n",
       " 249,\n",
       " 3167,\n",
       " 3270,\n",
       " 2445,\n",
       " 257,\n",
       " 2499,\n",
       " 2440,\n",
       " 2425,\n",
       " 2564,\n",
       " 1566,\n",
       " 145,\n",
       " 2036,\n",
       " 1320,\n",
       " 1196,\n",
       " 209,\n",
       " 932,\n",
       " 1114,\n",
       " 965,\n",
       " 356,\n",
       " 3115,\n",
       " 3048,\n",
       " 3052,\n",
       " 2457,\n",
       " 2604,\n",
       " 1238,\n",
       " 3353,\n",
       " 1146,\n",
       " 589,\n",
       " 2324,\n",
       " 482,\n",
       " 2962,\n",
       " 1,\n",
       " 1439,\n",
       " 854,\n",
       " 2633,\n",
       " 2255,\n",
       " 431,\n",
       " 3217,\n",
       " 1830,\n",
       " 2944,\n",
       " 2451,\n",
       " 750,\n",
       " 3317,\n",
       " 3307,\n",
       " 1200,\n",
       " 3072,\n",
       " 1066,\n",
       " 2906,\n",
       " 2052,\n",
       " 1725,\n",
       " 3147,\n",
       " 2093,\n",
       " 2082,\n",
       " 681,\n",
       " 1047,\n",
       " 2805,\n",
       " 1792,\n",
       " 1330,\n",
       " 1922,\n",
       " 2234,\n",
       " 2057,\n",
       " 1819,\n",
       " 1262,\n",
       " 2118,\n",
       " 2849,\n",
       " 2344,\n",
       " 1488,\n",
       " 188,\n",
       " 1460,\n",
       " 2134,\n",
       " 850,\n",
       " 2879,\n",
       " 2597,\n",
       " 183,\n",
       " 445,\n",
       " 926,\n",
       " 1263,\n",
       " 2733,\n",
       " 3326,\n",
       " 2761,\n",
       " 2120,\n",
       " 790,\n",
       " 786,\n",
       " 3035,\n",
       " 526,\n",
       " 458,\n",
       " 811,\n",
       " 2231,\n",
       " 3109,\n",
       " 1037,\n",
       " 2299,\n",
       " 61,\n",
       " 1650,\n",
       " 2474,\n",
       " 698,\n",
       " 1631,\n",
       " 441,\n",
       " 2629,\n",
       " 1638,\n",
       " 2659,\n",
       " 26,\n",
       " 1376,\n",
       " 594,\n",
       " 1706,\n",
       " 2238,\n",
       " 964,\n",
       " 2223,\n",
       " 1391,\n",
       " 1563,\n",
       " 1709,\n",
       " 127,\n",
       " 190,\n",
       " 5,\n",
       " 1852,\n",
       " 1532,\n",
       " 2519,\n",
       " 3230,\n",
       " 2757,\n",
       " 2780,\n",
       " 2762,\n",
       " 3152,\n",
       " 1458,\n",
       " 1514,\n",
       " 1275,\n",
       " 1551,\n",
       " 1385,\n",
       " 359,\n",
       " 895,\n",
       " 2587,\n",
       " 498,\n",
       " 726,\n",
       " 1397,\n",
       " 242,\n",
       " 248,\n",
       " 2064,\n",
       " 1318,\n",
       " 2102,\n",
       " 1911,\n",
       " 1846,\n",
       " 833,\n",
       " 1999,\n",
       " 107,\n",
       " 367,\n",
       " 338,\n",
       " 1499,\n",
       " 502,\n",
       " 1711,\n",
       " 1789,\n",
       " 1277,\n",
       " 587,\n",
       " 1799,\n",
       " 738,\n",
       " 1937,\n",
       " 436,\n",
       " 1559,\n",
       " 3275,\n",
       " 1763,\n",
       " 2624,\n",
       " 2266,\n",
       " 2091,\n",
       " 1698,\n",
       " 2368,\n",
       " 2586,\n",
       " 2830,\n",
       " 3310,\n",
       " 866,\n",
       " 1337,\n",
       " 1000,\n",
       " 1972,\n",
       " 382,\n",
       " 2544,\n",
       " 1209,\n",
       " 1415,\n",
       " 2531,\n",
       " 1696,\n",
       " 3245,\n",
       " 434,\n",
       " 1400,\n",
       " 444,\n",
       " 276,\n",
       " 1422,\n",
       " 124,\n",
       " 3139,\n",
       " 3341,\n",
       " 104,\n",
       " 2783,\n",
       " 1824,\n",
       " 2991,\n",
       " 1244,\n",
       " 2278,\n",
       " 3169,\n",
       " 3119,\n",
       " 3262,\n",
       " 1849,\n",
       " 1034,\n",
       " 322,\n",
       " 383,\n",
       " 1103,\n",
       " 2140,\n",
       " 395,\n",
       " 1828,\n",
       " 3195,\n",
       " 2030,\n",
       " 912,\n",
       " 1452,\n",
       " 2992,\n",
       " 2510,\n",
       " 1644,\n",
       " 1145,\n",
       " 173,\n",
       " 1584,\n",
       " 2804,\n",
       " 3274,\n",
       " 1023,\n",
       " 685,\n",
       " 37,\n",
       " 538,\n",
       " 400,\n",
       " 3159,\n",
       " 2570,\n",
       " 2690,\n",
       " 300,\n",
       " 2453,\n",
       " 1437,\n",
       " 2734,\n",
       " 1070,\n",
       " 3182,\n",
       " 2763,\n",
       " 56,\n",
       " 2089,\n",
       " 2041,\n",
       " 835,\n",
       " 3228,\n",
       " 2578,\n",
       " 1483,\n",
       " 2437,\n",
       " 224,\n",
       " 2560,\n",
       " 3040,\n",
       " 1598,\n",
       " 2851,\n",
       " 1484,\n",
       " 772,\n",
       " 762,\n",
       " 619,\n",
       " 19,\n",
       " 2075,\n",
       " 3131,\n",
       " 853,\n",
       " 2729,\n",
       " 788,\n",
       " 2959,\n",
       " 731,\n",
       " 235,\n",
       " 2968,\n",
       " 1867,\n",
       " 1869,\n",
       " 2068,\n",
       " 1310,\n",
       " 1380,\n",
       " 673,\n",
       " 1279,\n",
       " 2862,\n",
       " 1981,\n",
       " 2675,\n",
       " 1379,\n",
       " 2832,\n",
       " 1673,\n",
       " 819,\n",
       " 897,\n",
       " 490,\n",
       " 2527,\n",
       " 3323,\n",
       " 1132,\n",
       " 2475,\n",
       " 3175,\n",
       " 92,\n",
       " 1976,\n",
       " 1435,\n",
       " 2883,\n",
       " 2004,\n",
       " 1153,\n",
       " 1298,\n",
       " 1197,\n",
       " 2256,\n",
       " 2536,\n",
       " 3366,\n",
       " 3273,\n",
       " 3132,\n",
       " 229,\n",
       " 3321,\n",
       " 2930,\n",
       " 956,\n",
       " 1897,\n",
       " 1604,\n",
       " 768,\n",
       " 3093,\n",
       " 2970,\n",
       " 1441,\n",
       " 598,\n",
       " 584,\n",
       " 1581,\n",
       " 246,\n",
       " 2129,\n",
       " 2890,\n",
       " 815,\n",
       " 1997,\n",
       " 1417,\n",
       " 688,\n",
       " 2017,\n",
       " 53,\n",
       " 1294,\n",
       " 1705,\n",
       " 1471,\n",
       " 2224,\n",
       " 1764,\n",
       " 1572,\n",
       " 316,\n",
       " 2044,\n",
       " 3125,\n",
       " 1866,\n",
       " 2114,\n",
       " 799,\n",
       " 58,\n",
       " 233,\n",
       " 807,\n",
       " 860,\n",
       " 2316,\n",
       " 1061,\n",
       " 467,\n",
       " 3315,\n",
       " 2101,\n",
       " 3154,\n",
       " 2340,\n",
       " 3017,\n",
       " 311,\n",
       " 3269,\n",
       " 2173,\n",
       " 729,\n",
       " 330,\n",
       " 3165,\n",
       " 3117,\n",
       " 2907,\n",
       " 1777,\n",
       " 156,\n",
       " 2373,\n",
       " 737,\n",
       " 3286,\n",
       " 2602,\n",
       " 595,\n",
       " 1925,\n",
       " 2795,\n",
       " 2811,\n",
       " 1814,\n",
       " 1758,\n",
       " 611,\n",
       " 2631,\n",
       " 3030,\n",
       " 1953,\n",
       " 1939,\n",
       " 1735,\n",
       " 650,\n",
       " 1808,\n",
       " 2773,\n",
       " 2654,\n",
       " 2937,\n",
       " 523,\n",
       " 1812,\n",
       " 1663,\n",
       " 3213,\n",
       " 3272,\n",
       " 2348,\n",
       " 1886,\n",
       " 455,\n",
       " 231,\n",
       " 2993,\n",
       " 1326,\n",
       " 2438,\n",
       " 2829,\n",
       " 706,\n",
       " 993,\n",
       " 2685,\n",
       " 3009,\n",
       " 1032,\n",
       " 2209,\n",
       " 1594,\n",
       " 1858,\n",
       " 93,\n",
       " 1155,\n",
       " 743,\n",
       " 2983,\n",
       " 154,\n",
       " 547,\n",
       " 1729,\n",
       " 2753,\n",
       " 1760,\n",
       " 1688,\n",
       " 194,\n",
       " 696,\n",
       " 1420,\n",
       " 1974,\n",
       " 1296,\n",
       " 708,\n",
       " 3127,\n",
       " 2083,\n",
       " 2897,\n",
       " 3080,\n",
       " 2010,\n",
       " 2279,\n",
       " 1850,\n",
       " 2472,\n",
       " 809,\n",
       " 2400,\n",
       " 2980,\n",
       " 1585,\n",
       " 861,\n",
       " 117,\n",
       " 2786,\n",
       " 1139,\n",
       " 888,\n",
       " 2105,\n",
       " 3252,\n",
       " 2452,\n",
       " 3201,\n",
       " 1768,\n",
       " 326,\n",
       " 2950,\n",
       " 3227,\n",
       " 575,\n",
       " 837,\n",
       " 935,\n",
       " 2727,\n",
       " 2270,\n",
       " 1820,\n",
       " 3055,\n",
       " 1755,\n",
       " 1461,\n",
       " 1098,\n",
       " 1574,\n",
       " 1226,\n",
       " 2824,\n",
       " 511,\n",
       " 2572,\n",
       " 1691,\n",
       " 372,\n",
       " 1878,\n",
       " 2084,\n",
       " 3211,\n",
       " 1239,\n",
       " 842,\n",
       " 2545,\n",
       " 440,\n",
       " 2333,\n",
       " 1378,\n",
       " 1403,\n",
       " 2504,\n",
       " 2953,\n",
       " 1345,\n",
       " 1234,\n",
       " 503,\n",
       " 408,\n",
       " 1467,\n",
       " 3012,\n",
       " 3197,\n",
       " 568,\n",
       " 191,\n",
       " 468,\n",
       " 1230,\n",
       " 1491,\n",
       " 2235,\n",
       " 627,\n",
       " 321,\n",
       " 2542,\n",
       " 1059,\n",
       " 825,\n",
       " 2979,\n",
       " 1101,\n",
       " 2581,\n",
       " 2957,\n",
       " 1160,\n",
       " 15,\n",
       " 1054,\n",
       " 709,\n",
       " 2282,\n",
       " 2788,\n",
       " 2501,\n",
       " 2346,\n",
       " 2193,\n",
       " 232,\n",
       " 874,\n",
       " 2058,\n",
       " 2922,\n",
       " 703,\n",
       " 806,\n",
       " 2350,\n",
       " 2485,\n",
       " 357,\n",
       " 3248,\n",
       " 1881,\n",
       " 2652,\n",
       " 1864,\n",
       " 1221,\n",
       " 1156,\n",
       " 623,\n",
       " 2175,\n",
       " 2981,\n",
       " 791,\n",
       " 537,\n",
       " 2119,\n",
       " 1933,\n",
       " 2743,\n",
       " 3026,\n",
       " 2448,\n",
       " 1067,\n",
       " 193,\n",
       " 2649,\n",
       " 540,\n",
       " 2695,\n",
       " 1016,\n",
       " 2386,\n",
       " 354,\n",
       " 514,\n",
       " 674,\n",
       " 1818,\n",
       " 2274,\n",
       " 680,\n",
       " 892,\n",
       " 1463,\n",
       " 3151,\n",
       " 3278,\n",
       " 2138,\n",
       " 2874,\n",
       " 1276,\n",
       " 2878,\n",
       " 1681,\n",
       " 3358,\n",
       " 1134,\n",
       " 1601,\n",
       " 2610,\n",
       " 2347,\n",
       " 1991,\n",
       " 1742,\n",
       " 508,\n",
       " 970,\n",
       " 1659,\n",
       " 59,\n",
       " 1355,\n",
       " 2382,\n",
       " 957,\n",
       " 365,\n",
       " 2422,\n",
       " 281,\n",
       " 710,\n",
       " 2304,\n",
       " 1956,\n",
       " 2056,\n",
       " 684,\n",
       " 453,\n",
       " 1943,\n",
       " 2284,\n",
       " 2939,\n",
       " 3116,\n",
       " 2465,\n",
       " 2754,\n",
       " 3088,\n",
       " 1728,\n",
       " 2656,\n",
       " 2820,\n",
       " 1140,\n",
       " 1222,\n",
       " 2662,\n",
       " 1172,\n",
       " 3157,\n",
       " 197,\n",
       " 1231,\n",
       " 4,\n",
       " 1079,\n",
       " 2614,\n",
       " 773,\n",
       " 1512,\n",
       " 3354,\n",
       " 2902,\n",
       " 2813,\n",
       " 2427,\n",
       " 2467,\n",
       " 2202,\n",
       " 2837,\n",
       " 908,\n",
       " 1853,\n",
       " 3335,\n",
       " 2242,\n",
       " 692,\n",
       " 2253,\n",
       " 679,\n",
       " 2642,\n",
       " 1369,\n",
       " 466,\n",
       " 396,\n",
       " 2045,\n",
       " 1875,\n",
       " 1573,\n",
       " 1724,\n",
       " 3328,\n",
       " 1195,\n",
       " 2554,\n",
       " 3355,\n",
       " 1218,\n",
       " 829,\n",
       " 2571,\n",
       " 49,\n",
       " 2401,\n",
       " 1071,\n",
       " 876,\n",
       " 1888,\n",
       " 2276,\n",
       " 2609,\n",
       " 652,\n",
       " 648,\n",
       " 2543,\n",
       " ...]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Balancing_Fold():\n",
    "    Output_reset = Output.reset_index() #resets index and drops an un-needed \"index\" column\n",
    "    Output_Array = np.array(Output_reset) #Array of class labels. 1 = PD = majority, 0 = SNP = minority\n",
    "    Array = np.squeeze(Output_Array) #Makes array 1D\n",
    "\n",
    "    count_0 = 0\n",
    "    count_1 = 0\n",
    "    list_index = []\n",
    "    Array_loop = shuffle(Array)\n",
    "\n",
    "    for i in Array_loop:\n",
    "        index = int(i[0:1])\n",
    "        values = i[1:]\n",
    "\n",
    "        if values == 0 and count_0 < Minority:\n",
    "            count_0 += 1\n",
    "            list_index.append(index)\n",
    "        elif values == 1 and count_1 < Minority:\n",
    "            count_1 += 1\n",
    "            list_index.append(index)\n",
    "    return list_index\n",
    "    print(f\"PD:{count_1}\\nSNP:{count_0}\\nTotal:{count_1+count_0}\")\n",
    "Balancing_Fold()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a43542",
   "metadata": {},
   "source": [
    "### Input training sets for each class (PD and SNP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24405e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PD:1803\n",
      "SNP:891\n"
     ]
    }
   ],
   "source": [
    "Training_Outputs = pd.DataFrame([Output]).reset_index(drop=True).transpose() #Converts Output series to dataframe\n",
    "Training_Outputs.columns = ['Class'] #Names column 'Class'\n",
    "Majority_Class= Training_Outputs.drop(Training_Outputs[Training_Outputs['Class'] == 0].index) #Removes all SNP classes; only PD majority class remains\n",
    "Minority_Class = Training_Outputs.drop(Training_Outputs[Training_Outputs['Class'] == 1].index) #Removes all PD classes; only SNP minority class remains\n",
    "#print(\"PD:\",len(Majority_Class),\"SNP:\", len(Minority_Class))\n",
    "\n",
    "# Only the rows in input training set that are PD\n",
    "Input_PD_train = Input_train.loc[Input_train.index.isin(Majority_Class.index.values)]\n",
    "Classes_PD_train = Classes_train.loc[Classes_train.index.isin(Majority_Class.index.values)] #Labels training data of only PD. 1803\n",
    "\n",
    "# Only the rows in X (input training set) that are SNP\n",
    "Input_SNP_train = Input_train.loc[Input_train.index.isin(Minority_Class.index.values)]\n",
    "Classes_SNP_train = Classes_train.loc[Classes_train.index.isin(Minority_Class.index.values)] #Labels training data of only SNP. 891\n",
    "\n",
    "print(f\"PD:{len(Input_PD_train)}\\nSNP:{len(Input_SNP_train)}\") #Returns the number of only PD or SNP instances in respective training data sets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4b8fdd",
   "metadata": {},
   "source": [
    "### Weighted voting for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee46ca48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "Prob_PD = RFC.predict_proba(Input_PD_train) #Probability prediction, as a mean of all trees in RF, for the PD instances\n",
    "Prob_SNP = RFC.predict_proba(Input_SNP_train) #Probability prediction, as a mean of all trees in RF, for the SNP instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6746be83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imbalance ratio:\n",
      "2.0235690235690234:1\n",
      "5 balancing folds needed.\n"
     ]
    }
   ],
   "source": [
    "def Ratio_divide(): #Finds ratio between the 2 classes (i.e the imbalance) and the number of folds required\n",
    "    a = len(Input_PD_train)\n",
    "    b = len(Input_SNP_train)\n",
    "    Divide = a/b\n",
    "    if Divide <= 1:\n",
    "        Ratio = 1/Divide\n",
    "    else:\n",
    "        Ratio = Divide\n",
    "        \n",
    "    if round(Ratio) % 2 == 0:\n",
    "        BF = 2 * round(Ratio) + 1\n",
    "    else:\n",
    "        BF = round(Ratio)\n",
    "    return Ratio, BF;\n",
    "Ratio, BF = Ratio_divide()\n",
    "\n",
    "print(f\"Imbalance ratio:\\n{Ratio}:1\\n{BF} balancing folds needed.\")\n",
    "\n",
    "#Build a model for each balancing fold, predict the confidence scores and find average for each, which gives final vote\n",
    " \n",
    "BF_RFC = RandomForestClassifier(random_state = 42, n_estimators = 100) #Defines the Random Forest. 42 seeds, 100 trees (increase)\n",
    "BF_Prob = []\n",
    "BF_Probtxt = []\n",
    "BF_data = []\n",
    "\n",
    "#Randomly samples the majority class PD, to the same size of minority class SNP, and scores confidence for each instance\n",
    "for i in range (BF):\n",
    "    a = Random_Seed()\n",
    "    BF_Input_PD_train = Input_PD_train.sample(frac = (1/Ratio), random_state = a//100) #Balanced PD input training data \n",
    "    BF_Classes_PD_train = Classes_PD_train.sample(frac = (1/Ratio), random_state = a//100) #Balanced PD output training data\n",
    "    \n",
    "    #Concatanates the input and output balancing fold training data, so a new RFC can be generated. Function\n",
    "    BF_Input_all = shuffle(pd.concat([BF_Input_PD_train, Input_SNP_train]), random_state = a//50)\n",
    "    BF_Output_all = shuffle(pd.concat([BF_Classes_PD_train, Classes_SNP_train]), random_state = a//50)\n",
    "    Full_set = pd.concat([BF_Input_all, BF_Output_all], axis = 1)\n",
    "\n",
    "\n",
    "    #Generates RF and calculates probabilities for each fold\n",
    "    BF_RFC.fit(BF_Input_all, BF_Output_all)\n",
    "    BF_data.append(Full_set) #Builds random forest from training data for each fold\n",
    "    \n",
    "    Prob_index = BF_RFC.predict_proba(BF_Input_all) #Predicts confidence score for each instance\n",
    "    Full_set[['SNP', 'PD']] = Prob_index\n",
    "    Prob_index = Full_set.drop(labels=['Binding','SProtFT0','SProtFT1','SProtFT2','SProtFT3','SProtFT4','SProtFT5','SProtFT6','SProtFT7','SProtFT8','SProtFT9','SProtFT10','SProtFT11','SProtFT12','Interface','Relaccess','Impact','HBonds','SPhobic','CPhilic','BCharge','SSGeom','Voids','MLargest1','MLargest2','MLargest3','MLargest4','MLargest5','MLargest6','MLargest7','MLargest8','MLargest9','MLargest10','NLargest1','NLargest2','NLargest3','NLargest4','NLargest5','NLargest6','NLargest7','NLargest8','NLargest9','NLargest10','Clash','Glycine','Proline','CisPro','dataset_pd'], axis=1, inplace=False)\n",
    "    #Becomes a list\n",
    "    BF_Prob.append(Prob_index) #List with probabilites for all instances\n",
    "    BF_Probtxt.append(Prob_index.to_string())\n",
    "    \n",
    "with open('Balanced probabilities.txt', 'w') as f:\n",
    "    for number, line in zip(range(BF), BF_Probtxt):\n",
    "        f.write(f\"Fold: {number}\\n\\n{line}\\n\\n\\n\")\n",
    "        \n",
    "with open('Balanced training data.txt', 'w') as f:\n",
    "    for number, fold in zip(range(BF), BF_data):\n",
    "        f.write(f\"Fold: {number}\\n\\n{fold}\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dead8029",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2049    0.672\n",
       "2       0.840\n",
       "2054    0.936\n",
       "8       0.768\n",
       "2056    0.844\n",
       "        ...  \n",
       "2004    0.696\n",
       "2017    0.800\n",
       "2019    0.812\n",
       "2036    0.812\n",
       "2039    0.744\n",
       "Length: 934, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Apply weighted vote scheme for a predictor that outputs confidence value between 0 and 1 for each class. \n",
    "def Weighted_Proba(BF_Prob, BF_list):\n",
    "\n",
    "    # Identify which instance appear in all folds, uding the nth fold (random number)\n",
    "    intersect_index = set(BF_Prob[0].index.values) #index of all 1782 instances in first fold\n",
    "    \n",
    "    for i in BF_list: #for all 5 folds\n",
    "        intersect_index = intersect_index.intersection(set(BF_Prob[i].index.values)) #intersection checks if instances are in all folds\n",
    "    intersect_index_list = list(intersect_index) #converts set to list, 945 items\n",
    "\n",
    "    with open('All Instances.txt', 'w') as f:\n",
    "        for line in intersect_index_list:\n",
    "            f.write(f\"{line}\\n\")\n",
    "            \n",
    "    BF_prob_list_PD =[]\n",
    "    BF_prob_list_SNP =[]\n",
    "    for i in BF_list: #for all 5 folds\n",
    "        BF_Prob_instance = BF_Prob[i].loc[intersect_index_list,:] #Returns each dataframe with the common instances\n",
    "        BF_prob_list_PD.append(BF_Prob_instance.iloc[:,1] - BF_Prob_instance.iloc[:,0]) #PD - SNP prob\n",
    "        BF_prob_list_SNP.append(BF_Prob_instance.iloc[:,0] - BF_Prob_instance.iloc[:,1]) #SNP - PD prob   \n",
    "    \n",
    "    SNP_Sum = 0\n",
    "    for i in BF_list:\n",
    "        SNP_Sum += BF_prob_list_SNP[i]\n",
    "    PD_Sum = 0\n",
    "    for i in BF_list:\n",
    "        PD_Sum += BF_prob_list_PD[i]\n",
    "        \n",
    "    S_out = abs((PD_Sum - SNP_Sum)/(len(BF_list) * 2))\n",
    "    return(S_out)\n",
    "\n",
    "Weighted_Proba(BF_Prob, BF_list=range(BF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8fe70fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "S_out_string = Weighted_Proba(BF_Prob, BF_list=range(BF)).to_string() #Write S_out to text file\n",
    "with open('S_out.txt', 'w') as f:\n",
    "    f.write(S_out_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05628e7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1071    0.94\n",
       "1052    0.92\n",
       "2834    0.89\n",
       "1878    0.08\n",
       "2603    0.95\n",
       "        ... \n",
       "2042    0.02\n",
       "2963    0.09\n",
       "1346    0.97\n",
       "3213    0.17\n",
       "2771    0.07\n",
       "Name: SNP, Length: 1782, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BF_Prob[0].iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a322d7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final vote\n",
    "\n",
    "PD = BF_Prob[0].iloc[:,1].to_numpy()\n",
    "SNP = BF_Prob[0].iloc[:,0].to_numpy()\n",
    "# if np.greater(PD,SNP):\n",
    "\n",
    "# PD_Count = 0\n",
    "# SNP_Count = 0\n",
    "# for i in range(len(BF_Prob)):\n",
    "#     if np.greater(PD,SNP):\n",
    "#         PD_Count += 1\n",
    "#     elif BF_Prob[i].iloc[:,0] > BF_Prob[i].iloc[:,1]:\n",
    "#         SNP_Count += 1\n",
    "#     else:\n",
    "#         pass\n",
    "\n",
    "        \n",
    "\n",
    "# PD_Count = 0\n",
    "# for i in Weighted_Proba(BF_Prob, BF_list=range(BF)):\n",
    "#     if i > 0.5:\n",
    "#         PD_Count += 1\n",
    "#     else:\n",
    "#         pass\n",
    "# print(PD_Count,\"samples predicted to be PD\")\n",
    "\n",
    "# SNP_Count = 0\n",
    "# for i in Weighted_Proba(BF_Prob, BF_list=range(BF)):\n",
    "#     if i < 0.5:\n",
    "#         SNP_Count += 1\n",
    "#     else:\n",
    "#         pass\n",
    "# print(SNP_Count,\"samples predicted to be SNP\")\n",
    "\n",
    "\n",
    "# #Evaluation of training after weighted vote\n",
    "# Classes_pred = RFC.predict(Input_test)\n",
    "# print(f\"Confusion Matrix:\\n {confusion_matrix(Classes_test, Classes_pred)}\")\n",
    "# print(f\"MCC:\\n {matthews_corrcoef(Classes_test, Classes_pred)}\")\n",
    "# print(\"F1:\\n\", f1_score(Classes_test, Classes_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb4af5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: retrive the probability from each tree for a single sample  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965f8777",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c426f23e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x25c76732ad0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # **Split data into training and test**\n",
    "# with open('SNPorPD.txt', 'w+') as f:\n",
    "#         data=f.read()\n",
    "#         f.write(str(y_test.to_string()))\n",
    "\n",
    "# # pipeline.fit(X, y) #applies list if transformers to give a fitted model\n",
    "\n",
    "plt.scatter(Classes_test, Output_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f620e35",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [17], line 8\u001b[0m\n\u001b[0;32m      1\u001b[0m gridsearch \u001b[38;5;241m=\u001b[39m GridSearchCV( \u001b[38;5;66;03m#validation\u001b[39;00m\n\u001b[0;32m      2\u001b[0m     estimator \u001b[38;5;241m=\u001b[39m LogisticRegression(solver\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msaga\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m      3\u001b[0m     param_grid \u001b[38;5;241m=\u001b[39m {}, \u001b[38;5;66;03m#dictionary of parameters to search through\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     cv \u001b[38;5;241m=\u001b[39m StratifiedKFold(),\n\u001b[0;32m      5\u001b[0m     n_jobs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;66;03m#how many processors to run in parallel\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     scoring \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      7\u001b[0m     verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m \n\u001b[1;32m----> 8\u001b[0m     )\u001b[38;5;241m.\u001b[39mfit(\u001b[43mX_train\u001b[49m, y_train)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "gridsearch = GridSearchCV( #validation\n",
    "    estimator = LogisticRegression(solver='saga'),\n",
    "    param_grid = {}, #dictionary of parameters to search through\n",
    "    cv = StratifiedKFold(),\n",
    "    n_jobs = 1, #how many processors to run in parallel\n",
    "    scoring = 'f1',\n",
    "    verbose = 3 \n",
    "    ).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15af356d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = clf.predict(X_test)\n",
    "# print(\"Training time:\", stop-start)\n",
    "# print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "# print(\"MCC:\\n\", matthews_corrcoef(y_test, y_pred))\n",
    "# print(\"F1:\\n\", f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1de8521",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 337.844,
   "position": {
    "height": "359.844px",
    "left": "1536px",
    "right": "20px",
    "top": "112px",
    "width": "354px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
