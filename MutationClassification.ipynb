{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fcba82d",
   "metadata": {},
   "source": [
    "### Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d94d2bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Example 2 is inbalanced data set; ~2200 in PD and ~1100 in SNP\\n    Goal is to predict if mutation is SNP or PD\\n    ImprovedBalancing branch\\n    \\n    Total samples: 3368\\n    2254 PD samples\\n    1111 SNP samples\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Example 2 is inbalanced data set; ~2200 in PD and ~1100 in SNP\n",
    "    Goal is to predict if mutation is SNP or PD\n",
    "    ImprovedBalancing branch\n",
    "    \n",
    "    Total samples: 3368\n",
    "    2254 PD samples\n",
    "    1111 SNP samples\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5737f62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\" Imports the required libraries and packages\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd  #Import for data manipulation in dataframes\n",
    "import numpy as np  #Array manipulation and calculates mean\n",
    "\n",
    "import random as rd\n",
    "\n",
    "from sklearn.metrics import(\n",
    "    matthews_corrcoef,  # CC for evaluation\n",
    "    f1_score,  #F1 score for evaluation\n",
    "    confusion_matrix,  #Creates the confusion matrix - stats on how accurate the test set output is\n",
    "    classification_report #Returns the F1 socre, precision, and recall of a prediction using a given model\n",
    "    )\n",
    "from sklearn.model_selection import(\n",
    "    train_test_split,  # Splits data frame into the training set and testing set\n",
    "    GridSearchCV,  # Cross validation to improve hyperparameters\n",
    "    StratifiedKFold\n",
    "        )\n",
    "from sklearn.ensemble import RandomForestClassifier #SK learn API for classificastion random forests\n",
    "from sklearn.tree import DecisionTreeClassifier #Single tree decisions \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier #allows for confidence scores to be predicted for each\n",
    "np.set_printoptions(threshold=np.inf) #full array printing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddcc865",
   "metadata": {},
   "source": [
    "### Clean dataset in pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "62413d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Clean_data(file):\n",
    "    \"\"\" Input:      file        The dataset to read\n",
    "\n",
    "        Returns:    Input       Dataframe with of input features for training\n",
    "                    Output      Dataframe of class labels for each instance in Input\n",
    "\n",
    "        Create, clean and convert dataset E2.csv to PD dataframe. Drops uneeded columns, removes blank spaces, \n",
    "        and applies \"One Hot Encoding\" to convert PD/SNP to 1/0\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_csv('E2.csv')\n",
    "\n",
    "    #Remove unrequired column, replace blank spaces, reset index to run from 0\n",
    "    df.drop(['pdbcode:chain:resnum:mutation'], axis=1, inplace=True)\n",
    "    df.replace(' ', '_', regex=True, inplace=True)\n",
    "    df.reset_index(drop=True, inplace = True)\n",
    "\n",
    "    Input = df.drop('dataset', axis =1).fillna('0') #Should remove the row \n",
    "    Output_encoded = pd.get_dummies(df, columns=['dataset']) #Encode the PD and SNP columns\n",
    "    Output = Output_encoded['dataset_pd'].copy().astype('int32') #PD = 1, SNP = 0\n",
    "\n",
    "    return Input, Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb451c9e",
   "metadata": {},
   "source": [
    "### Split into training and testing, generate RF (whole dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bbfacd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(Input, Output):\n",
    "    \"\"\" Input:      Input           Dataframe with of input features for training\n",
    "                    Output          Dataframe of class labels for each instance in Input\n",
    "\n",
    "        Returns:    Input_train     Features training data\n",
    "                    Input_test      Features test data\n",
    "                    Classes_train   Class label training data\n",
    "                    Classes_test    Class label test data\n",
    "\n",
    "        80% training and 20% testing split. Strartify ensures fixed poportion of labels are in both sets. \n",
    "        Random forest defined as RFC with 1000 trees, seed = 42. Outputs the training data to files.\n",
    "        \"\"\"\n",
    "\n",
    "    Input_train, Input_test, Classes_train, Classes_test = train_test_split(Input, Output, train_size = 0.8, random_state=42, stratify=Output) \n",
    "    RFC = RandomForestClassifier(random_state = 42, n_estimators = 1000, verbose = 1)\n",
    "    RFC.fit(Input_train, Classes_train)\n",
    "\n",
    "    with open('Training Data.txt', 'w') as file: #Writes class labels for all instances to text file\n",
    "        file.write(Input_train.to_string())\n",
    "    with open('Class labels.txt', 'w') as file: #Writes class labels for all instances to text file\n",
    "        file.write(Classes_train.to_string())\n",
    "    with open('Test Data.txt', 'w') as file: #Writes class labels for all instances to text file\n",
    "        file.write(Input_test.to_string())\n",
    "    with open('Test labels.txt', 'w') as file: #Writes class labels for all instances to text file\n",
    "        file.write(Classes_test.to_string())\n",
    "\n",
    "    return RFC, Input_test, Classes_test, Input_train, Classes_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e8b7f5",
   "metadata": {},
   "source": [
    "### Initial evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cf8d9857",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(RFC, Input_test, Classes_test):\n",
    "    \"\"\" Input:  Input_test      Features test data\n",
    "                Classes_test    Class label test data\n",
    "\n",
    "        Evaluates the training data. Random forest classifier makes prediction using the test features. True values \n",
    "        are the class labels testing data\n",
    "    \"\"\"\n",
    "\n",
    "    Output_pred = RFC.predict(Input_test) #Always perdict on the unseen test data, as train has been used by the estimastor\n",
    "    print(f\"Confusion Matrix:\\n {confusion_matrix(Classes_test, Output_pred)}\")\n",
    "    print(f\"{classification_report(Classes_test, Output_pred)}\\nMCC                {matthews_corrcoef(Classes_test, Output_pred)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a335a585",
   "metadata": {},
   "source": [
    "### Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6b6924e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_minority_class(classData):\n",
    "    \"\"\" Input:    classData  Array of class labels\n",
    "        Returns:  minClass   The label for the minority class\n",
    "                  minSize    The number of items in the minority class\n",
    "                  maxSize    The number of items in the majority class\n",
    "    Finds information about the inbalance in class sizes\n",
    "    \"\"\"\n",
    "    \n",
    "    Minority_count = 0\n",
    "    Majority_count = 0\n",
    "    for datum in classData:\n",
    "        if datum == 1:\n",
    "            Majority_count += 1\n",
    "        elif datum == 0:\n",
    "            Minority_count += 1\n",
    "\n",
    "    minClass = 0\n",
    "    minSize = Minority_count\n",
    "    maxSize = Majority_count\n",
    "    if Minority_count > Majority_count:\n",
    "        minClass = 1\n",
    "        minSize = Majority_count\n",
    "        maxSize = Minority_count\n",
    "\n",
    "    return minClass, minSize, maxSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6746be83",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Input:      maxSize     The number of items in the majority class\n",
    "                minSize     The number of items in the minority class\n",
    "                \n",
    "    Returns:    BF          Number of balancing folds\n",
    "    \n",
    "    Calculate the number of balancing folds needed using ratio of majority to minority class size. Double to ensure sufficient\n",
    "    majority class instances are sampled, then + 1 to make odd to allow weighted vote.\n",
    "\"\"\"\n",
    "def Balance_ratio(maxSize, minSize): \n",
    "    Divide = maxSize/minSize\n",
    "    BF = (2 * round(Divide)) + 1 #Double ratio to nearest integer\n",
    "    return BF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5d1241bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance(inData, classData, minClass, minSize):\n",
    "    \"\"\" Input:    inData          array of input data\n",
    "                  classData       array of classes assigned\n",
    "                  minorityClass   class label for the minority class\n",
    "                  minoritySize    size of the minority class\n",
    "                  \n",
    "         Returns: array of indexes that are of interest for a \n",
    "                  balanced dataset\n",
    "\n",
    "    Perform the actual balancing between SNPs and PDs\n",
    "    \"\"\"\n",
    "    \n",
    "    usedLines = [False] * len(inData) #Array of false for length of data\n",
    "    for i in range(len(inData)):\n",
    "        if classData[i] == minClass:\n",
    "            usedLines[i] = True\n",
    "            \n",
    "    usedCount = 0\n",
    "    while usedCount < minSize:\n",
    "        i = rd.randrange(len(inData))\n",
    "        if usedLines[i] == False:\n",
    "            usedCount += 1\n",
    "            usedLines[i] = True       \n",
    "\n",
    "    return usedLines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d5c54edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_data(inData, classData, usedLines):\n",
    "    \"\"\" Input:     inData      array of input training data\n",
    "                   classData   array of classes assigned to training data\n",
    "                   usedLines   array of line indexes to print\n",
    "                \n",
    "        Returns:   Input_balance  Array of balanced input training data\n",
    "                   Label_balance  Array of balanced classes assigned to training data\n",
    "\n",
    "    Create arrays for the input training data and its corresponding classes, as needed for predicting the probability.\n",
    "    The index [i] is the identifier between the two arrays\n",
    "    \"\"\"\n",
    "    Input_balance = []\n",
    "    Label_balance = []\n",
    "    for i in range(len(inData)):\n",
    "        if usedLines[i]:\n",
    "            Input_balance.append(inData[i])\n",
    "            Label_balance.append(classData[i])\n",
    "            \n",
    "    Input_balance = np.stack(Input_balance, axis =0)\n",
    "    Label_balance = np.stack(Label_balance, axis =0)\n",
    "    \n",
    "    return Input_balance, Label_balance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27419a33",
   "metadata": {},
   "source": [
    "### Balance for n folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "12239dc9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\" Input:      BF                Number of balancing folds needed\n",
    "                usedLines         Array of line indexes to print\n",
    "                Input_balance     Input_balance  Array of balanced input training data\n",
    "                Label_balance     Array of balanced classes assigned to training data\n",
    "\n",
    "    Returns:    Input_folds       List of 5 balanced arrays of training data\n",
    "                Output_folds      List of 5 balanced arrays of training data's labels\n",
    "\n",
    "    Performs the balance_data() function n number of balancing fold times. Returns lists for training data and labels\n",
    "    where each item is the output of balance_data()\n",
    "\"\"\"\n",
    "def Balance_Folds(BF, usedLines, Input_balance, Label_balance):\n",
    "    Input_folds = []\n",
    "    Output_folds = []\n",
    "    for fold in range(BF):\n",
    "        Input_folds.append(Input_balance)\n",
    "        Output_folds.append(Label_balance)\n",
    "        \n",
    "    return Input_folds, Output_folds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796af0e8",
   "metadata": {},
   "source": [
    "### Train RFC on balanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1decd7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BF_training(BF, Input_folds, Output_folds): \n",
    "    \"\"\" Input:      BF              Number of balancing folds\n",
    "                    Input_folds     List of 5 balanced arrays for training data\n",
    "                    Output_folds    List of 5 balanced arrays of training data's labels\n",
    "\n",
    "        Returns:    BF_RFC          List of RFC's trained on data in each balancing fold\n",
    "\n",
    "        Creates a model that returns probability predictions for each fold, using Balance_Fold() as input\n",
    "    \"\"\"    \n",
    "    BF_RFC = []\n",
    "    \n",
    "    for i in range(BF):\n",
    "        BF_RFC.append(RandomForestClassifier(random_state = 42, n_estimators = 1000, verbose = 1)) #Defines a Random Forest for each fold. 42 seeds, 1000 trees\n",
    "        BF_RFC[i].fit(Input_folds[i], Output_folds[i].ravel()) #Generates a random forest for each fold's training data        \n",
    "        \n",
    "    return BF_RFC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0dd278c",
   "metadata": {},
   "source": [
    "### Test RFC on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "acc41cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BFC_test(BF_RFC, Input_test):\n",
    "    \"\"\" Input:  BF_RFC          List of RFC's trained on data in each balancing fold\n",
    "                Input_test      20% unseen testing data split before the balancing folds\n",
    "                \n",
    "    Returns:    Prob_matrix      List of arrays. Each item is 2D matrix where the 1st dimension is each subset in balancing fold, \n",
    "                                 2nd dimension is predicted probability\n",
    "    \n",
    "    Tests the trained RFCs on the test set, then for every instance, outputs the predicted probability for each class\n",
    "    \"\"\"\n",
    "    Prob_matrix = [] #Empty list\n",
    "    Prob_matrixlist = []\n",
    "    for i in range(len(BF_RFC)): #step through item in\n",
    "        Prob_list = BF_RFC[i].predict_proba(Input_test.values)\n",
    "        Prob_matrix.append(Prob_list)\n",
    "        \n",
    "#         Output_pred = BF_RFC[i].predict(Input_test.values)\n",
    "#         print(f\"{matthews_corrcoef(Classes_test, Output_pred)}\")    \n",
    "              \n",
    "        \n",
    "    with open('Test probabilities.txt', 'w') as f:\n",
    "        for number, line in zip(range(BF), Prob_matrix ):\n",
    "            f.write(f\"Fold: {number}\\n\\n   SNP    PD\\n{line}\\n\\n\\n\")\n",
    "\n",
    "    return Prob_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4b8fdd",
   "metadata": {},
   "source": [
    "### Weighted voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "71033215",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Input:      Prob_matrix      List of arrays. 2D matrix where the 1st dimension is each subset in balancing fold, \n",
    "                                2nd dimension is predicted probability\n",
    "                BF              Number of balancing folds\n",
    "                \n",
    "    Returns:    Final_vote      Weighted vote classification\n",
    "    \n",
    "    Calculates the final weighted vote using confidence scores (Sc). Binary classification formula Sc = 2|S0 - 0.5|\n",
    "\"\"\"\n",
    "def Weighted_Vote(Prob_matrix, BF):\n",
    "    Sc_PD = [] #Empty list\n",
    "    Sc_SNP = [] #Empty list\n",
    "    for i in range(BF):\n",
    "        Sc_PD.append(2* (Prob_matrix[i][:,1] - 0.5)) #Confidence scores for PD, for each fold\n",
    "        Sc_SNP.append(2*(Prob_matrix[i][:,0] - 0.5)) #Confidence scores for SNP, for each fold\n",
    "    \n",
    "\n",
    "    Sum_PD = np.sum(Sc_PD, axis = 0) #Sum of all PD confidence scores. 1D Array\n",
    "    Sum_SNP = np.sum(Sc_SNP, axis = 0) #Sum of all SNP confidence scores. 1D Array     \n",
    "\n",
    "    Vote_arr = [] #Empty list\n",
    "    \n",
    "    for i in range(len(Classes_test)):\n",
    "        if Sum_PD[i] >= Sum_SNP[i]:\n",
    "            Vote_arr.append([1]) #Append PD classifications to list\n",
    "        elif Sum_SNP[i] > Sum_PD[i]:\n",
    "            Vote_arr.append([0]) #Append SNP classifications to list\n",
    "            \n",
    "    Final_vote = np.stack(Vote_arr) #Converts list of arrays to a 2D array, shape (674,1)\n",
    "    Final_vote = Final_vote.ravel() #Flattens 2D array to 1D array\n",
    "    \n",
    "    np.savetxt('Classifications.txt', Final_vote, \"%.0f\")\n",
    "    \n",
    "    return(Final_vote, Sum_PD, Sum_SNP) #Returns the final confidence scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18f5b78",
   "metadata": {},
   "source": [
    "### Final confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2ae1157a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Input:      Sum_PD      Sum of confidence score for PD predictions\n",
    "                Sum_SNP     Sum of confidence score for SNP predictions\n",
    "                \n",
    "    Returns:    S_out        Final confidence score\n",
    "    \n",
    "    Calculates the final confidence score\n",
    "\"\"\"\n",
    "def Final_score(Sum_PD, Sum_SNP, BF):\n",
    "    \n",
    "    S_Out = np.abs((Sum_PD - Sum_SNP) /(BF*2))\n",
    "    print(S_Out)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "92f36545",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def evalutation(Classes_test, Final_vote):\n",
    "    \"\"\" Input:      Classes_test       Class label test data\n",
    "                    Final_vote         Weighted vote classification\n",
    "\n",
    "        Returns:    Vote        Number of PDs and SNPs predicted after weighted vote\n",
    "\n",
    "        Evaluation metrics from RFC on test data with\n",
    "    \"\"\"\n",
    "    Output_pred = Final_vote\n",
    "\n",
    "    print(f\"Confusion Matrix:\\n {confusion_matrix(Classes_test, Output_pred)}\")\n",
    "    print(f\"{classification_report(Classes_test, Output_pred)}\\nMCC                {matthews_corrcoef(Classes_test, Output_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa67e232",
   "metadata": {},
   "source": [
    "### Main Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8b6b8f6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[145  78]\n",
      " [ 27 424]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.65      0.73       223\n",
      "           1       0.84      0.94      0.89       451\n",
      "\n",
      "    accuracy                           0.84       674\n",
      "   macro avg       0.84      0.80      0.81       674\n",
      "weighted avg       0.84      0.84      0.84       674\n",
      "\n",
      "MCC                0.6371468255225344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    3.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    3.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    3.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    3.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    3.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[181  42]\n",
      " [ 71 380]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.81      0.76       223\n",
      "           1       0.90      0.84      0.87       451\n",
      "\n",
      "    accuracy                           0.83       674\n",
      "   macro avg       0.81      0.83      0.82       674\n",
      "weighted avg       0.84      0.83      0.83       674\n",
      "\n",
      "MCC                0.6362319794773045\n",
      "[0.414 0.614 0.498 0.158 0.516 0.524 0.76  0.72  0.828 0.734 0.656 0.01\n",
      " 0.536 0.788 0.394 0.022 0.29  0.356 0.644 0.192 0.858 0.034 0.124 0.56\n",
      " 0.04  0.184 0.976 0.724 0.262 0.464 0.748 0.342 0.5   0.564 0.562 0.508\n",
      " 0.096 0.068 0.608 0.15  0.912 0.012 0.494 0.958 0.756 0.514 0.646 0.302\n",
      " 0.192 0.494 0.36  0.628 0.922 0.896 0.36  0.656 0.812 0.8   0.102 0.97\n",
      " 0.4   0.222 0.242 0.456 0.228 0.364 0.488 0.378 0.064 0.266 0.414 0.516\n",
      " 0.126 0.506 0.882 0.514 0.142 0.204 0.078 0.042 0.334 0.068 0.574 0.814\n",
      " 0.888 0.092 0.058 0.654 0.598 0.556 0.286 0.818 0.354 0.118 0.474 0.764\n",
      " 0.784 0.36  0.45  0.672 0.306 0.038 0.034 0.99  0.592 0.67  0.562 0.02\n",
      " 0.102 0.684 0.268 0.688 0.01  0.39  0.414 0.246 0.604 0.636 0.776 0.366\n",
      " 0.74  0.546 0.674 0.306 0.88  0.904 0.114 0.914 0.61  0.71  0.66  0.244\n",
      " 0.52  0.548 0.818 0.346 0.552 0.822 0.658 0.074 0.022 0.964 0.838 0.684\n",
      " 0.74  0.626 0.712 0.218 0.206 0.992 0.12  0.438 0.112 0.818 0.648 0.532\n",
      " 0.33  0.526 0.494 0.546 0.002 0.42  0.04  0.316 0.314 0.29  0.078 0.926\n",
      " 0.606 0.776 0.97  0.302 0.67  0.812 0.464 0.946 0.71  0.232 0.648 0.528\n",
      " 0.314 0.326 0.668 0.054 0.074 0.544 0.862 0.924 0.226 0.65  0.044 0.634\n",
      " 0.764 0.55  0.834 0.772 0.822 0.522 0.09  0.408 0.276 0.324 0.692 0.354\n",
      " 0.968 0.174 0.476 0.894 0.266 0.968 0.396 0.774 0.76  0.89  0.218 0.696\n",
      " 0.516 0.868 0.854 0.076 0.402 0.542 0.804 0.654 0.796 0.148 0.626 0.22\n",
      " 0.64  0.97  0.436 0.512 0.7   0.876 0.526 0.508 0.3   0.14  0.518 0.858\n",
      " 0.814 0.444 0.464 0.708 0.684 0.24  0.038 0.218 0.758 0.836 0.224 0.032\n",
      " 0.592 0.096 0.354 0.19  0.526 0.926 0.942 0.094 0.602 0.108 0.018 0.7\n",
      " 0.176 0.556 0.682 0.374 0.27  0.638 0.272 0.186 0.082 0.3   0.396 0.416\n",
      " 0.25  0.774 0.61  0.584 0.03  0.69  0.9   0.51  0.916 0.84  0.446 0.86\n",
      " 0.718 0.042 0.786 0.926 0.114 0.116 0.436 0.416 0.448 0.274 0.558 0.522\n",
      " 0.526 0.626 0.192 0.362 0.766 0.786 0.726 0.244 0.582 0.546 0.056 0.192\n",
      " 0.358 0.774 0.83  0.438 0.994 0.386 0.85  0.706 0.432 0.948 0.542 0.582\n",
      " 0.858 0.668 0.786 0.628 0.406 0.818 0.51  0.686 0.296 0.2   0.56  0.536\n",
      " 0.38  0.48  0.308 0.15  0.9   0.306 0.392 0.7   0.18  0.714 0.806 0.656\n",
      " 0.67  0.372 0.682 0.504 0.308 0.634 0.756 0.314 0.04  0.486 0.48  0.47\n",
      " 0.58  0.324 0.476 0.724 0.63  0.12  0.172 0.572 0.434 0.928 0.18  0.156\n",
      " 0.656 0.916 0.354 0.274 0.344 0.016 0.596 0.308 0.67  0.462 0.842 0.76\n",
      " 0.394 0.3   0.332 0.312 0.03  0.306 0.35  0.184 0.852 0.584 0.076 0.068\n",
      " 0.67  0.658 0.784 0.692 0.058 0.716 0.144 0.91  0.318 0.46  0.408 0.206\n",
      " 0.398 0.372 0.948 0.304 0.14  0.05  0.186 0.158 0.458 0.414 0.348 0.392\n",
      " 0.086 0.37  0.67  0.372 0.122 0.564 0.924 0.172 0.124 0.776 0.574 0.194\n",
      " 0.768 0.538 0.356 0.43  0.912 0.166 0.396 0.18  0.392 0.712 0.062 0.858\n",
      " 0.056 0.562 0.038 0.088 0.114 0.566 0.58  0.19  0.842 0.804 0.228 0.394\n",
      " 0.604 0.02  0.12  0.112 0.792 0.754 0.386 0.296 0.608 0.    0.768 0.772\n",
      " 0.636 0.19  0.386 0.848 0.728 0.594 0.672 0.666 0.17  0.194 0.868 0.678\n",
      " 0.96  0.19  0.858 0.684 0.226 0.378 0.01  0.228 0.178 0.56  0.45  0.806\n",
      " 0.172 0.242 0.382 0.356 0.258 0.104 0.188 0.52  0.634 0.358 0.614 0.726\n",
      " 0.808 0.652 0.458 0.694 0.23  0.574 0.956 0.228 0.54  0.202 0.278 0.744\n",
      " 0.538 0.476 0.408 0.602 0.25  0.036 0.94  0.668 0.088 0.344 0.162 0.256\n",
      " 0.802 0.014 0.326 0.646 0.166 0.742 0.696 0.514 0.324 0.134 0.128 0.286\n",
      " 0.504 0.862 0.62  0.892 0.304 0.012 0.948 0.304 0.654 0.59  0.126 0.54\n",
      " 0.494 0.766 0.2   0.406 0.984 0.056 0.06  0.35  0.89  0.116 0.484 0.258\n",
      " 0.76  0.608 0.202 0.396 0.248 0.592 0.506 0.046 0.424 0.024 0.966 0.138\n",
      " 0.958 0.33  0.418 0.486 0.572 0.454 0.876 0.174 0.616 0.252 0.472 0.8\n",
      " 0.134 0.64  0.698 0.24  0.758 0.5   0.174 0.24  0.538 0.196 0.436 0.394\n",
      " 0.612 0.7   0.69  0.642 0.048 0.336 0.012 0.112 0.946 0.448 0.924 0.074\n",
      " 0.116 0.666 0.844 0.856 0.746 0.124 0.874 0.924 0.258 0.18  0.39  0.384\n",
      " 0.91  0.316 0.886 0.99  0.816 0.486 0.53  0.846 0.184 0.506 0.536 0.14\n",
      " 0.228 0.632 0.578 0.292 0.474 0.104 0.1   0.036 0.582 0.872 0.184 0.046\n",
      " 0.412 0.554 0.74  0.582 0.93  0.684 0.236 0.664 0.7   0.418 0.606 0.09\n",
      " 0.508 0.186 0.16  0.07  0.3   0.334 0.35  0.744 0.362 0.304 0.954 0.604\n",
      " 0.458 0.166]\n"
     ]
    }
   ],
   "source": [
    "file = 'E2.csv'\n",
    "Input, Output = Clean_data(file)\n",
    "RFC, Input_test, Classes_test, Input_train, Classes_train = train(Input, Output)\n",
    "test(RFC,Input_test, Classes_test)\n",
    "\n",
    "inData    = pd.DataFrame(Input_train).to_numpy()\n",
    "classData = pd.DataFrame(Classes_train).to_numpy()\n",
    "\n",
    "minClass, minSize, maxSize   = find_minority_class(classData)\n",
    "BF                           = Balance_ratio(maxSize, minSize)\n",
    "usedLines                    = balance(inData, classData, minClass, minSize)\n",
    "\n",
    "Input_balance, Label_balance = balance_data(inData, classData, usedLines)\n",
    "Input_folds, Output_folds    = Balance_Folds(BF, usedLines, Input_balance, Label_balance)\n",
    "\n",
    "BF_RFC                       = BF_training(BF, Input_folds, Output_folds)\n",
    "Prob_matrix                  = BFC_test(BF_RFC, Input_test)\n",
    "Final_vote, Sum_PD, Sum_SNP  = Weighted_Vote(Prob_matrix, BF)\n",
    "\n",
    "evalutation(Classes_test, Final_vote)\n",
    "Final_score(Sum_PD, Sum_SNP, BF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5825d165",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 337.844,
   "position": {
    "height": "359.844px",
    "left": "1536px",
    "right": "20px",
    "top": "112px",
    "width": "354px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
