{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fcba82d",
   "metadata": {},
   "source": [
    "### Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d94d2bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Example 2 is inbalanced data set; ~2200 in PD and ~1100 in SNP\\n    Goal is to predict if mutation is SNP or PD\\n    CV branch\\n    \\n    Total samples: 3368\\n    2254 PD samples\\n    1111 SNP samples\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Example 2 is inbalanced data set; ~2200 in PD and ~1100 in SNP\n",
    "    Goal is to predict if mutation is SNP or PD\n",
    "    CV branch\n",
    "    \n",
    "    Total samples: 3368\n",
    "    2254 PD samples\n",
    "    1111 SNP samples\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5737f62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Imports the required libraries and packages\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd  #Import for data manipulation in dataframes\n",
    "import numpy as np  #Array manipulation and calculates mean\n",
    "\n",
    "import random as rd\n",
    "import time\n",
    "\n",
    "from sklearn.metrics import(\n",
    "    matthews_corrcoef,  # MCC for evaluation\n",
    "    balanced_accuracy_score, #hyperparameter evaluation\n",
    "    f1_score,  #hyperparameter evaluation\n",
    "    confusion_matrix,  # confusion matrix for classification evalutation\n",
    "    classification_report #Return the F1, precision, and recall of a prediction\n",
    "    )\n",
    "from sklearn.model_selection import(\n",
    "    train_test_split,  # Splits data frame into the training set and testing set\n",
    "    GridSearchCV,  # Cross validation to improve hyperparameters\n",
    "    RandomizedSearchCV,\n",
    "    StratifiedKFold, # K-fold CV\n",
    "    GroupKFold\n",
    "        )\n",
    "from sklearn.ensemble import RandomForestClassifier #SK learn API for classificastion random forests\n",
    "from sklearn.tree import DecisionTreeClassifier #Single tree decisions \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier #allows for confidence scores to be predicted for each\n",
    "np.set_printoptions(threshold=np.inf, precision=3) #full array printing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddcc865",
   "metadata": {},
   "source": [
    "### Clean dataset in pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62413d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Clean_data(file):\n",
    "    \"\"\" Input:      file        The dataset to read\n",
    "\n",
    "        Returns:    Output      Cleaned dataframe with numeric values for class\n",
    "\n",
    "        Create, clean and convert dataset E2.csv to PD dataframe. Sorts alphabetically to order proteins, removes blank spaces\n",
    "        and applies \"One Hot Encoding\" to convert classes (PD/SNP) to 1/0\n",
    "    \"\"\"\n",
    "    df = pd.read_csv('E2.csv')\n",
    "\n",
    "    #Remove unrequired column, replace blank spaces, reset index to run from 0\n",
    "    df.dropna(inplace = True) #drop rows with missing values\n",
    "    df.replace(' ', '_', regex=True, inplace=True)\n",
    "    df.reset_index(drop=True, inplace = True)\n",
    "\n",
    "#     Input = df.drop('dataset', axis =1)\n",
    "    Output_encoded = pd.get_dummies(df, columns=['dataset']) #Encode the PD and SNP columns\n",
    "    Output = Output_encoded.drop(['dataset_snp'],axis = 1)\n",
    "#     Output = Output_encoded['dataset_pd'].copy().astype('int32') #PD = 1, SNP = 0\n",
    "\n",
    "    return Output #Datset in alphabetical order, NaNs removed and encoded PD label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfaeb64c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pdbcode:chain:resnum:mutation</th>\n",
       "      <th>Binding</th>\n",
       "      <th>SProtFT0</th>\n",
       "      <th>SProtFT1</th>\n",
       "      <th>SProtFT2</th>\n",
       "      <th>SProtFT3</th>\n",
       "      <th>SProtFT4</th>\n",
       "      <th>SProtFT5</th>\n",
       "      <th>SProtFT6</th>\n",
       "      <th>SProtFT7</th>\n",
       "      <th>...</th>\n",
       "      <th>NLargest6</th>\n",
       "      <th>NLargest7</th>\n",
       "      <th>NLargest8</th>\n",
       "      <th>NLargest9</th>\n",
       "      <th>NLargest10</th>\n",
       "      <th>Clash</th>\n",
       "      <th>Glycine</th>\n",
       "      <th>Proline</th>\n",
       "      <th>CisPro</th>\n",
       "      <th>dataset_pd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3odq:B:90:K</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>35.332</td>\n",
       "      <td>33.811</td>\n",
       "      <td>30.525</td>\n",
       "      <td>28.448</td>\n",
       "      <td>23.301</td>\n",
       "      <td>-8.83</td>\n",
       "      <td>-100.0000</td>\n",
       "      <td>-100.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3thc:A:214:Y</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>152.367</td>\n",
       "      <td>142.055</td>\n",
       "      <td>119.325</td>\n",
       "      <td>110.986</td>\n",
       "      <td>110.768</td>\n",
       "      <td>-11.19</td>\n",
       "      <td>-100.0000</td>\n",
       "      <td>-100.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2ary:A:103:A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>74.267</td>\n",
       "      <td>69.595</td>\n",
       "      <td>67.078</td>\n",
       "      <td>62.108</td>\n",
       "      <td>61.438</td>\n",
       "      <td>-2.03</td>\n",
       "      <td>-100.0000</td>\n",
       "      <td>-100.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2r3v:A:301:T</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>162.474</td>\n",
       "      <td>130.995</td>\n",
       "      <td>114.245</td>\n",
       "      <td>113.635</td>\n",
       "      <td>87.611</td>\n",
       "      <td>1.32</td>\n",
       "      <td>-100.0000</td>\n",
       "      <td>-100.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1bhg:A:408:S</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>188.020</td>\n",
       "      <td>176.892</td>\n",
       "      <td>175.881</td>\n",
       "      <td>160.863</td>\n",
       "      <td>160.839</td>\n",
       "      <td>-2.93</td>\n",
       "      <td>-100.0000</td>\n",
       "      <td>-100.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3360</th>\n",
       "      <td>3cot:A:261:C</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>103.081</td>\n",
       "      <td>85.249</td>\n",
       "      <td>83.669</td>\n",
       "      <td>77.663</td>\n",
       "      <td>73.123</td>\n",
       "      <td>-4.57</td>\n",
       "      <td>-100.0000</td>\n",
       "      <td>-100.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3361</th>\n",
       "      <td>2l0w:A:47:V</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>53.941</td>\n",
       "      <td>42.229</td>\n",
       "      <td>27.331</td>\n",
       "      <td>25.610</td>\n",
       "      <td>25.432</td>\n",
       "      <td>-5.44</td>\n",
       "      <td>2.4896</td>\n",
       "      <td>-100.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3362</th>\n",
       "      <td>2l9n:A:126:T</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>73.001</td>\n",
       "      <td>59.724</td>\n",
       "      <td>56.923</td>\n",
       "      <td>50.393</td>\n",
       "      <td>47.249</td>\n",
       "      <td>-4.98</td>\n",
       "      <td>-100.0000</td>\n",
       "      <td>-100.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3363</th>\n",
       "      <td>2xwt:C:252:P</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>62.633</td>\n",
       "      <td>51.638</td>\n",
       "      <td>51.579</td>\n",
       "      <td>50.647</td>\n",
       "      <td>49.074</td>\n",
       "      <td>41.29</td>\n",
       "      <td>-100.0000</td>\n",
       "      <td>3.2714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3364</th>\n",
       "      <td>3b63:B:177:C</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>75.434</td>\n",
       "      <td>62.945</td>\n",
       "      <td>56.809</td>\n",
       "      <td>55.505</td>\n",
       "      <td>54.530</td>\n",
       "      <td>-2.66</td>\n",
       "      <td>-100.0000</td>\n",
       "      <td>-100.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3365 rows Ã— 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pdbcode:chain:resnum:mutation  Binding  SProtFT0  SProtFT1  SProtFT2  \\\n",
       "0                      3odq:B:90:K      0.0       0.0       0.0       0.0   \n",
       "1                     3thc:A:214:Y      0.0       0.0       0.0       0.0   \n",
       "2                     2ary:A:103:A      0.0       0.0       0.0       0.0   \n",
       "3                     2r3v:A:301:T      0.0       0.0       0.0       0.0   \n",
       "4                     1bhg:A:408:S      0.0       0.0       0.0       0.0   \n",
       "...                            ...      ...       ...       ...       ...   \n",
       "3360                  3cot:A:261:C      0.0       0.0       0.0       0.0   \n",
       "3361                   2l0w:A:47:V      0.0       0.0       0.0       0.0   \n",
       "3362                  2l9n:A:126:T      0.0       0.0       0.0       0.0   \n",
       "3363                  2xwt:C:252:P      0.0       0.0       0.0       0.0   \n",
       "3364                  3b63:B:177:C      0.0       0.0       0.0       0.0   \n",
       "\n",
       "      SProtFT3  SProtFT4  SProtFT5  SProtFT6  SProtFT7  ...  NLargest6  \\\n",
       "0          0.0       0.0       0.0       0.0       0.0  ...     35.332   \n",
       "1          0.0       0.0       0.0       0.0       0.0  ...    152.367   \n",
       "2          0.0       0.0       0.0       0.0       0.0  ...     74.267   \n",
       "3          0.0       0.0       0.0       0.0       0.0  ...    162.474   \n",
       "4          0.0       0.0       0.0       0.0       0.0  ...    188.020   \n",
       "...        ...       ...       ...       ...       ...  ...        ...   \n",
       "3360       0.0       0.0       0.0       0.0       0.0  ...    103.081   \n",
       "3361       0.0       0.0       0.0       0.0       0.0  ...     53.941   \n",
       "3362       0.0       0.0       0.0       0.0       0.0  ...     73.001   \n",
       "3363       0.0       0.0       0.0       0.0       0.0  ...     62.633   \n",
       "3364       0.0       0.0       0.0       0.0       0.0  ...     75.434   \n",
       "\n",
       "      NLargest7  NLargest8  NLargest9  NLargest10  Clash   Glycine   Proline  \\\n",
       "0        33.811     30.525     28.448      23.301  -8.83 -100.0000 -100.0000   \n",
       "1       142.055    119.325    110.986     110.768 -11.19 -100.0000 -100.0000   \n",
       "2        69.595     67.078     62.108      61.438  -2.03 -100.0000 -100.0000   \n",
       "3       130.995    114.245    113.635      87.611   1.32 -100.0000 -100.0000   \n",
       "4       176.892    175.881    160.863     160.839  -2.93 -100.0000 -100.0000   \n",
       "...         ...        ...        ...         ...    ...       ...       ...   \n",
       "3360     85.249     83.669     77.663      73.123  -4.57 -100.0000 -100.0000   \n",
       "3361     42.229     27.331     25.610      25.432  -5.44    2.4896 -100.0000   \n",
       "3362     59.724     56.923     50.393      47.249  -4.98 -100.0000 -100.0000   \n",
       "3363     51.638     51.579     50.647      49.074  41.29 -100.0000    3.2714   \n",
       "3364     62.945     56.809     55.505      54.530  -2.66 -100.0000 -100.0000   \n",
       "\n",
       "      CisPro  dataset_pd  \n",
       "0        0.0           1  \n",
       "1        0.0           1  \n",
       "2        0.0           0  \n",
       "3        0.0           1  \n",
       "4        0.0           1  \n",
       "...      ...         ...  \n",
       "3360     0.0           1  \n",
       "3361     0.0           1  \n",
       "3362     0.0           1  \n",
       "3363     0.0           1  \n",
       "3364     0.0           1  \n",
       "\n",
       "[3365 rows x 49 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Output = Clean_data(file = 'E2.csv')\n",
    "Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb451c9e",
   "metadata": {},
   "source": [
    "### Split dataset into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bbfacd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(Output):\n",
    "    \"\"\"      \n",
    "        Input:      Output          Cleaned dataframe\n",
    "\n",
    "        Returns:    Training_Set     Training data\n",
    "                    Testing_Set      Testing data\n",
    "\n",
    "        80% training and 20% testing split. Outputs the data to files. Splits are randomly shuffled\n",
    "        \"\"\"\n",
    "    Training_Set, Testing_Set = train_test_split(Output,train_size = 0.8)\n",
    "    \n",
    "    with open('Training dataset.txt', 'w') as file: #Writes training features to text file\n",
    "        file.write(Training_Set.to_string())\n",
    "    with open('Testing dataset.txt', 'w') as file: #Writes training class labels to text file\n",
    "        file.write(Testing_Set.to_string())\n",
    "\n",
    "\n",
    "    return Training_Set, Testing_Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f8c71a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "Training_Set, Testing_Set = train(Output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e8b7f5",
   "metadata": {},
   "source": [
    "### Initial evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "cf8d9857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test(Initial_RFC, Input_test, Classes_test):\n",
    "#     \"\"\" Input:  Input_test      Features test data\n",
    "#                 Classes_test    Class label test data\n",
    "\n",
    "#         Evaluates the training data before balancing. Random forest classifier makes prediction using the test features. True values \n",
    "#         are the class labels testing data\n",
    "#     \"\"\"\n",
    "\n",
    "#     Output_pred = Initial_RFC.predict(Input_test) #Always perdict on the unseen test data, as train has been used by the estimastor\n",
    "#     print(f\"              **Initial Evaluation**\\n\")\n",
    "#     print(f\"Confusion Matrix:\\n {confusion_matrix(Classes_test, Output_pred)}\")\n",
    "#     print(f\"{classification_report(Classes_test, Output_pred)}\\nMCC                {matthews_corrcoef(Classes_test, Output_pred)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5004d774",
   "metadata": {},
   "source": [
    "### Group K-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "503e943b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "841 unique proteins\n"
     ]
    }
   ],
   "source": [
    "Group_df = Training_Set\n",
    "Group_df.sort_values(by=['pdbcode:chain:resnum:mutation'], inplace = True) #Alphabetically order PDB identifier column\n",
    "Group_df.dropna(inplace = True) #Remove rows with missing values\n",
    "\n",
    "PDB_codes = [] #Empty list that will contain only the PDB code\n",
    "for i in range(len(Group_df)): \n",
    "    PDB_codes.append(Group_df.iloc[i][0].partition(':')[0]) #Obtain just the 'pdbcode' from 'pdbcode:chain:resnum:mutation'\n",
    "\n",
    "Group_df.drop(['pdbcode:chain:resnum:mutation'], axis=1, inplace=True) #Remove 'pdbcode:chain:resnum:mutation' column\n",
    "Group_df.insert(0, 'PDB code', PDB_codes) #Insert PDB codes as first column\n",
    "\n",
    "\n",
    "#Groups proteins by PDB code#\n",
    "\n",
    "PDB_codes_count = 0\n",
    "PDB_codes_list = [] #Empty list that will contain the protein groups as items\n",
    "for i in range(len(Group_df)-1):\n",
    "    First = Group_df.iloc[i][0] #PDB code of row i\n",
    "    Second = Group_df.iloc[i + 1][0] #PDB code of row i+1 \n",
    "\n",
    "    if First == Second:\n",
    "        PDB_codes_count += 1 #increase count\n",
    "    else:\n",
    "        PDB_codes_list.append(np.array(Group_df.iloc[(i - PDB_codes_count): i + 1, 0:].values)) #List of samples as arrays, ordered\n",
    "        PDB_codes_count = 0 #reset count\n",
    "      \n",
    "\n",
    "print(f\"{Group_df['PDB code'].nunique() -1} unique proteins\")\n",
    "# df.to_csv('order.csv', index = False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e99690b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PDB code  Binding  SProtFT0  SProtFT1  SProtFT2  SProtFT3  SProtFT4  \\\n",
      "2400     13gs      0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "671      13gs      0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "1009     1a02      0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "2334     1a22      0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "3240     1a22      0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "...       ...      ...       ...       ...       ...       ...       ...   \n",
      "1707     6pax      0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "2970     6pax      0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "2126     6pax      0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "2972     6pax      0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "1975     6rlx      1.0       0.0       0.0       0.0       0.0       0.0   \n",
      "\n",
      "      SProtFT5  SProtFT6  SProtFT7  ...  NLargest6  NLargest7  NLargest8  \\\n",
      "2400       0.0       0.0       0.0  ...     72.924     72.765     71.665   \n",
      "671        0.0       0.0       0.0  ...     72.924     72.765     71.665   \n",
      "1009       0.0       0.0       0.0  ...     58.939     56.680     52.867   \n",
      "2334       0.0       0.0       0.0  ...     69.638     64.705     60.273   \n",
      "3240       0.0       0.0       0.0  ...     69.638     64.705     60.273   \n",
      "...        ...       ...       ...  ...        ...        ...        ...   \n",
      "1707       0.0       0.0       0.0  ...     18.348     17.344     16.832   \n",
      "2970       0.0       0.0       0.0  ...     18.348     17.344     16.832   \n",
      "2126       0.0       0.0       0.0  ...     18.348     17.344     16.832   \n",
      "2972       0.0       0.0       0.0  ...     18.348     17.344     16.832   \n",
      "1975       0.0       0.0       0.0  ...      3.420      3.250      0.000   \n",
      "\n",
      "      NLargest9  NLargest10    Clash  Glycine   Proline  CisPro  dataset_pd  \n",
      "2400     70.664      64.469    -4.19   -100.0 -100.0000     0.0           0  \n",
      "671      70.664      64.469    -0.29   -100.0 -100.0000     0.0           0  \n",
      "1009     49.065      44.336    -5.72   -100.0 -100.0000     0.0           0  \n",
      "2334     60.189      54.902    -4.87   -100.0 -100.0000     0.0           1  \n",
      "3240     60.189      54.902    -7.57   -100.0 -100.0000     0.0           1  \n",
      "...         ...         ...      ...      ...       ...     ...         ...  \n",
      "1707     16.270      15.453   746.57   -100.0    2.5114     0.0           1  \n",
      "2970     16.270      15.453    -7.94   -100.0 -100.0000     0.0           1  \n",
      "2126     16.270      15.453   -10.50   -100.0 -100.0000     0.0           1  \n",
      "2972     16.270      15.453  3551.52   -100.0    2.4384     0.0           1  \n",
      "1975      0.000       0.000    -5.02   -100.0 -100.0000     0.0           0  \n",
      "\n",
      "[2692 rows x 49 columns]\n",
      "     PDB code  Binding  SProtFT0  SProtFT1  SProtFT2  SProtFT3  SProtFT4  \\\n",
      "2400     13gs      0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "671      13gs      0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "1009     1a02      0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "2334     1a22      0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "3240     1a22      0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "...       ...      ...       ...       ...       ...       ...       ...   \n",
      "1707     6pax      0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "2970     6pax      0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "2126     6pax      0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "2972     6pax      0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "1975     6rlx      1.0       0.0       0.0       0.0       0.0       0.0   \n",
      "\n",
      "      SProtFT5  SProtFT6  SProtFT7  ...  NLargest6  NLargest7  NLargest8  \\\n",
      "2400       0.0       0.0       0.0  ...     72.924     72.765     71.665   \n",
      "671        0.0       0.0       0.0  ...     72.924     72.765     71.665   \n",
      "1009       0.0       0.0       0.0  ...     58.939     56.680     52.867   \n",
      "2334       0.0       0.0       0.0  ...     69.638     64.705     60.273   \n",
      "3240       0.0       0.0       0.0  ...     69.638     64.705     60.273   \n",
      "...        ...       ...       ...  ...        ...        ...        ...   \n",
      "1707       0.0       0.0       0.0  ...     18.348     17.344     16.832   \n",
      "2970       0.0       0.0       0.0  ...     18.348     17.344     16.832   \n",
      "2126       0.0       0.0       0.0  ...     18.348     17.344     16.832   \n",
      "2972       0.0       0.0       0.0  ...     18.348     17.344     16.832   \n",
      "1975       0.0       0.0       0.0  ...      3.420      3.250      0.000   \n",
      "\n",
      "      NLargest9  NLargest10    Clash  Glycine   Proline  CisPro  dataset_pd  \n",
      "2400     70.664      64.469    -4.19   -100.0 -100.0000     0.0           0  \n",
      "671      70.664      64.469    -0.29   -100.0 -100.0000     0.0           0  \n",
      "1009     49.065      44.336    -5.72   -100.0 -100.0000     0.0           0  \n",
      "2334     60.189      54.902    -4.87   -100.0 -100.0000     0.0           1  \n",
      "3240     60.189      54.902    -7.57   -100.0 -100.0000     0.0           1  \n",
      "...         ...         ...      ...      ...       ...     ...         ...  \n",
      "1707     16.270      15.453   746.57   -100.0    2.5114     0.0           1  \n",
      "2970     16.270      15.453    -7.94   -100.0 -100.0000     0.0           1  \n",
      "2126     16.270      15.453   -10.50   -100.0 -100.0000     0.0           1  \n",
      "2972     16.270      15.453  3551.52   -100.0    2.4384     0.0           1  \n",
      "1975      0.000       0.000    -5.02   -100.0 -100.0000     0.0           0  \n",
      "\n",
      "[2692 rows x 49 columns]\n"
     ]
    }
   ],
   "source": [
    "print(f\"{Group_df}\\n{Group_df}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5bcadb2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['13gs', 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "        0.0, 0.0, 0.0, -18.417, 9.216, 0.431920922, 20.0, 0.0, 0.19, 0.0,\n",
       "        0.0, 0.0, 196.165, 150.631, 115.221, 110.327, 82.948, 72.924,\n",
       "        72.765, 71.665, 70.664, 64.469, 196.165, 150.631, 115.221,\n",
       "        98.902, 82.948, 72.924, 72.765, 71.665, 70.664, 64.469, -4.19,\n",
       "        -100.0, -100.0, 0.0, 0],\n",
       "       ['13gs', 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "        0.0, 0.0, 0.0, 0.0, 80.419, 0.769317406, 20.0, -0.29, 0.0, 0.0,\n",
       "        0.0, 38.925, 157.24, 146.405, 113.634, 112.582, 84.237, 81.872,\n",
       "        71.952, 63.934, 61.222, 59.101, 196.165, 150.631, 115.221,\n",
       "        98.902, 82.948, 72.924, 72.765, 71.665, 70.664, 64.469, -0.29,\n",
       "        -100.0, -100.0, 0.0, 0]], dtype=object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PDB_codes_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "17453a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Input_CV = df.drop('dataset_pd', axis =1)\n",
    "Output_CV = df['dataset_pd'].copy().astype('int32')\n",
    "groups = df['PDB code']\n",
    "\n",
    "# Input_train, Input_test, Classes_train, Classes_test = train_test_split(Input_CV, Output_CV, train_size = 0.8, stratify=Output_CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "15fcb813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GroupKFold(n_splits=5)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [2153, 2153, 2692]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [381], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(group_kfold)\n\u001b[0;32m      5\u001b[0m GroupKFold(n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (train_index, test_index) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(group_kfold\u001b[38;5;241m.\u001b[39msplit(Input_train, Classes_train, groups)):\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFold \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Train: index=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, group=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgroups[train_index]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:330\u001b[0m, in \u001b[0;36m_BaseKFold.split\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msplit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, groups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    307\u001b[0m     \u001b[38;5;124;03m\"\"\"Generate indices to split data into training and test set.\u001b[39;00m\n\u001b[0;32m    308\u001b[0m \n\u001b[0;32m    309\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    328\u001b[0m \u001b[38;5;124;03m        The testing set indices for that split.\u001b[39;00m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 330\u001b[0m     X, y, groups \u001b[38;5;241m=\u001b[39m \u001b[43mindexable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    331\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(X)\n\u001b[0;32m    332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits \u001b[38;5;241m>\u001b[39m n_samples:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:433\u001b[0m, in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    414\u001b[0m \u001b[38;5;124;03m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[0;32m    415\u001b[0m \n\u001b[0;32m    416\u001b[0m \u001b[38;5;124;03mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    429\u001b[0m \u001b[38;5;124;03m    sparse matrix, or dataframe) or `None`.\u001b[39;00m\n\u001b[0;32m    430\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    432\u001b[0m result \u001b[38;5;241m=\u001b[39m [_make_indexable(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m iterables]\n\u001b[1;32m--> 433\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:387\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    385\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 387\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    388\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    389\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    390\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [2153, 2153, 2692]"
     ]
    }
   ],
   "source": [
    "group_kfold = GroupKFold(n_splits=5)\n",
    "group_kfold.get_n_splits(Input_train, Classes_train, groups)\n",
    "print(group_kfold)\n",
    "\n",
    "GroupKFold(n_splits=5)\n",
    "for i, (train_index, test_index) in enumerate(group_kfold.split(Input_train, Classes_train, groups)):\n",
    "    \n",
    "    print(f\"Fold {i}:\")\n",
    "    print(f\"  Train: index={train_index}, group={groups[train_index]}\")\n",
    "    print(f\"  Test:  index={test_index}, group={groups[test_index]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a335a585",
   "metadata": {},
   "source": [
    "### Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6924e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_minority_class(classData):\n",
    "    \"\"\" Input:    classData  Array of class labels\n",
    "        Returns:  minClass   The label for the minority class\n",
    "                  minSize    The number of items in the minority class\n",
    "                  maxSize    The number of items in the majority class\n",
    "\n",
    "        Finds information about the inbalance in class sizes\n",
    "    \"\"\"\n",
    "    \n",
    "    Minority_count = 0\n",
    "    Majority_count = 0\n",
    "    for datum in classData:\n",
    "        if datum == 1:\n",
    "            Majority_count += 1\n",
    "        elif datum == 0:\n",
    "            Minority_count += 1\n",
    "\n",
    "    minClass = 0\n",
    "    minSize = Minority_count\n",
    "    maxSize = Majority_count\n",
    "    if Minority_count > Majority_count:\n",
    "        minClass = 1\n",
    "        minSize = Majority_count\n",
    "        maxSize = Minority_count\n",
    "\n",
    "    return minClass, minSize, maxSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6746be83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Balance_ratio(maxSize, minSize): \n",
    "    \"\"\" Input:      maxSize     The number of items in the majority class\n",
    "                    minSize     The number of items in the minority class\n",
    "\n",
    "        Returns:    BF          Number of balancing folds\n",
    "\n",
    "        Calculate the number of balancing folds needed using ratio of majority to minority class size. Double to ensure sufficient\n",
    "        majority class instances are sampled, then + 1 to make odd to allow weighted vote.\n",
    "    \"\"\"\n",
    "    Divide = maxSize/minSize\n",
    "    BF = (2 * round(Divide)) + 1 #Double ratio to nearest integer\n",
    "    return BF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1241bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance(inData, classData, minClass, minSize):\n",
    "    \"\"\" Input:    inData          array of input data\n",
    "                  classData       array of classes assigned\n",
    "                  minorityClass   class label for the minority class\n",
    "                  minoritySize    size of the minority class\n",
    "\n",
    "        Returns: array of indexes that are of interest for a balanced dataset\n",
    "\n",
    "        Perform the actual balancing between SNPs and PDs\n",
    "    \"\"\"\n",
    "    usedLines = [False] * len(inData) #Array of false for length of data\n",
    "    for i in range(len(inData)):\n",
    "        if classData[i] == minClass:\n",
    "            usedLines[i] = True\n",
    "            \n",
    "    usedCount = 0\n",
    "    while usedCount < minSize:\n",
    "        i = rd.randrange(len(inData))\n",
    "        if usedLines[i] == False:\n",
    "            usedCount += 1\n",
    "            usedLines[i] = True       \n",
    "\n",
    "    return usedLines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c54edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_data(inData, classData, usedLines):\n",
    "    \"\"\"     Input:     inData      array of input training data\n",
    "                       classData   array of classes assigned to training data\n",
    "                       usedLines   array of line indexes to print\n",
    "\n",
    "            Returns:   Input_balance  Array of balanced input training data\n",
    "                       Label_balance  Array of balanced classes assigned to training data\n",
    "        Create arrays for the input training data and classes, as needed for predicting the probability.\n",
    "        The index [i] is the identifier between the two arrays\n",
    "    \"\"\"\n",
    "    Input_balance = []\n",
    "    Label_balance = []\n",
    "    for i in range(len(inData)):\n",
    "        if usedLines[i]:\n",
    "            Input_balance.append(inData[i])\n",
    "            Label_balance.append(classData[i])\n",
    "            \n",
    "    Input_balance = np.stack(Input_balance, axis =0)\n",
    "    Label_balance = np.stack(Label_balance, axis =0)\n",
    "    \n",
    "    return Input_balance, Label_balance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27419a33",
   "metadata": {},
   "source": [
    "### Balance for n folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12239dc9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def Balance_Folds(BF, usedLines, Input_balance, Label_balance):\n",
    "    \"\"\" Input:      BF                Number of balancing folds needed\n",
    "                    usedLines         Array of line indexes to print\n",
    "                    Input_balance     Input_balance  Array of balanced input training data\n",
    "                    Label_balance     Array of balanced classes assigned to training data\n",
    "\n",
    "        Returns:    Input_folds       List of 5 balanced arrays of training data\n",
    "                    Output_folds      List of 5 balanced arrays of training data's labels\n",
    "\n",
    "        Perform the balance_data() function n number of balancing fold times. Return lists for training data and labels\n",
    "        where each item is the output of balance_data()\n",
    "    \"\"\"\n",
    "    Input_folds = []\n",
    "    Output_folds = []\n",
    "    for fold in range(BF):\n",
    "        Input_folds.append(Input_balance)\n",
    "        Output_folds.append(Label_balance)\n",
    "\n",
    "\n",
    "    with open('Balanced training data.txt', 'w') as f:\n",
    "        for number, fold in zip(range(BF), Input_folds):\n",
    "            f.write(f\"Fold: {number}\\n\\n{fold}\\n\\n\\n\")\n",
    "        \n",
    "    return Input_folds, Output_folds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cd1aaa",
   "metadata": {},
   "source": [
    "### RFC hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0840d9dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " def Hyperparameter(BF, Input_folds, Output_folds):\n",
    "    \"\"\" Input:      BF                Number of balancing folds needed\n",
    "                    Input_folds       List of 5 balanced arrays of training data\n",
    "                    Output_folds      List of 5 balanced arrays of training data's labels\n",
    "\n",
    "        Returns:    BF_RFC_HP         List of optimized hyperparameters for each RFC\n",
    "\n",
    "        Perform RandomSearchCV on each RFC to optimize number of trees, max depth and max samples\n",
    "    \"\"\"  \n",
    "    estimator = RandomForestClassifier()\n",
    "    param_grid = {\n",
    "                'n_estimators':np.arange(50,500,50),\n",
    "                'max_depth': np.arange(2, 10, 2),\n",
    "                'max_samples': np.arange(0.2, 1.2, 0.2)\n",
    "                  }\n",
    "    BF_RFC_HP = []\n",
    "\n",
    "    for i in range(BF):\n",
    "        HPtuning = RandomizedSearchCV(\n",
    "            estimator,\n",
    "            param_grid, \n",
    "            scoring = 'balanced_accuracy',\n",
    "            cv = 10,\n",
    "            n_jobs = 6, #how many cores to run in parallel\n",
    "            verbose = 2\n",
    "            ).fit(Input_folds[i], Output_folds[i].ravel())\n",
    "        BF_RFC_HP.append(HPtuning.best_params_)\n",
    "    \n",
    "    return(BF_RFC_HP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796af0e8",
   "metadata": {},
   "source": [
    "### Train RFC on balanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1decd7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BF_training(BF, Input_folds, Output_folds, BF_RFC_HP): \n",
    "    \"\"\" Input:      BF              Number of balancing folds\n",
    "                    Input_folds     List of 5 balanced arrays for training data\n",
    "                    Output_folds    List of 5 balanced arrays of training data's labels\n",
    "\n",
    "        Returns:    BF_RFC          List of RFC's trained on data in each balancing fold\n",
    "\n",
    "        Create a model that returns probability predictions for each fold, using Balance_Fold() as input\n",
    "    \"\"\"    \n",
    "    BF_RFC = []\n",
    "    \n",
    "    for i in range(BF):\n",
    "        BF_RFC.append(RandomForestClassifier(\n",
    "                                             verbose = 1\n",
    "                                            )) #Generates a RF for each fold \n",
    "        BF_RFC[i].fit(Input_folds[i], Output_folds[i].ravel()) #Fits the RFC to balanced training data    \n",
    "        \n",
    "    return BF_RFC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0dd278c",
   "metadata": {},
   "source": [
    "#### Test RFC on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc41cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BFC_test(BF_RFC, Input_test):\n",
    "    \"\"\" Input:  BF_RFC          List of RFC's trained on data in each balancing fold\n",
    "                Input_test      20% unseen testing data split before the balancing folds\n",
    "                \n",
    "        Returns:Prob_matrix     List of arrays. Each item is 2D matrix where the 1st dimension is each subset in balancing fold, \n",
    "                                2nd dimension is predicted probability\n",
    "    \n",
    "        Test the trained RFCs on the test set, then for every instance, outputs the predicted probability for each class\n",
    "    \"\"\"\n",
    "    Prob_matrix = [] #Empty list\n",
    "    Prob_matrixlist = []\n",
    "    for i in range(len(BF_RFC)):\n",
    "        Prob_list = BF_RFC[i].predict_proba(Input_test.values)\n",
    "        Prob_matrix.append(Prob_list)   \n",
    "        \n",
    "    with open('Test probabilities.txt', 'w') as f:\n",
    "        for number, line in zip(range(BF), Prob_matrix ):\n",
    "            f.write(f\"Fold: {number}\\n\\n   SNP    PD\\n{line}\\n\\n\\n\")\n",
    "\n",
    "    return Prob_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4b8fdd",
   "metadata": {},
   "source": [
    "### Weighted voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71033215",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Weighted_Vote(Prob_matrix, BF):\n",
    "    \"\"\" Input:      Prob_matrix     List of arrays. 2D matrix where the 1st dimension is each subset in balancing fold, \n",
    "                                    2nd dimension is predicted probability\n",
    "                    BF              Number of balancing folds\n",
    "\n",
    "        Returns:    Final_vote      Weighted vote classification\n",
    "\n",
    "        Calculate the final weighted vote using confidence scores (Sc). Binary classification formula Sc = 2|S0 - 0.5|\n",
    "    \"\"\"\n",
    "    Sc_PD = [] #Empty list\n",
    "    Sc_SNP = [] #Empty list\n",
    "    for i in range(BF):\n",
    "        Sc_PD.append(2* (Prob_matrix[i][:,1] - 0.5)) #Confidence scores for PD, for each fold\n",
    "        Sc_SNP.append(2*(Prob_matrix[i][:,0] - 0.5)) #Confidence scores for SNP, for each fold\n",
    "    \n",
    "\n",
    "    Sum_PD = np.sum(Sc_PD, axis = 0) #Sum of all PD confidence scores. 1D Array\n",
    "    Sum_SNP = np.sum(Sc_SNP, axis = 0) #Sum of all SNP confidence scores. 1D Array     \n",
    "\n",
    "    Vote_arr = [] #Empty list\n",
    "    \n",
    "    for i in range(len(Classes_test)):\n",
    "        if Sum_PD[i] >= Sum_SNP[i]:\n",
    "            Vote_arr.append([1]) #Append PD classifications to list\n",
    "        elif Sum_SNP[i] > Sum_PD[i]:\n",
    "            Vote_arr.append([0]) #Append SNP classifications to list\n",
    "            \n",
    "    Final_vote = np.stack(Vote_arr) #Converts list of arrays to a 2D array, shape (674,1)\n",
    "    Final_vote = Final_vote.ravel() #Flattens 2D array to 1D array\n",
    "        \n",
    "    return(Final_vote, Sum_PD, Sum_SNP) #Returns the final confidence scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18f5b78",
   "metadata": {},
   "source": [
    "### Final confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae1157a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Final_score(Sum_PD, Sum_SNP, BF):\n",
    "    \"\"\" Input:      Sum_PD      Sum of confidence score for PD predictions\n",
    "                    Sum_SNP     Sum of confidence score for SNP predictions\n",
    "\n",
    "        Returns:    S_out        Final confidence score\n",
    "\n",
    "        Calculate the final confidence score\n",
    "    \"\"\"\n",
    "    \n",
    "    S_Out = np.abs((Sum_PD - Sum_SNP) /(BF*2))\n",
    "    np.savetxt('S_out.txt', S_Out, \"%.3f\")\n",
    "    \n",
    "    return S_Out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f36545",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def evalutation(Classes_test, Final_vote, S_Out):\n",
    "    \"\"\" Input:      Classes_test       Class label test data\n",
    "                    Final_vote         Weighted vote classification\n",
    "\n",
    "        Evaluation metrics from RFC on test data with\n",
    "    \"\"\"\n",
    "    Output_pred = Final_vote\n",
    "    print(f\"              ***Final Evaluation***\\n\")\n",
    "    print(f\"Confusion Matrix:\\n {confusion_matrix(Classes_test, Output_pred)}\")\n",
    "    print(f\"{classification_report(Classes_test, Output_pred)}\\nMCC                {matthews_corrcoef(Classes_test, Output_pred)}\")\n",
    "    \n",
    "    print(f\"See file 'Classification.txt' for final classifications and confidence scores\")\n",
    "    np.savetxt('Classification.txt',\n",
    "           np.column_stack([Final_vote, S_Out]),\n",
    "           fmt = [\"%.0f\",\"%.3f\"],\n",
    "           delimiter =\"      \",\n",
    "           header = \"Final classifications and confidence scores\\n\\n\"\n",
    "          )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa67e232",
   "metadata": {},
   "source": [
    "### Main Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6b8f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file                         = 'E2.csv'\n",
    "Input, Output                = Clean_data(file)\n",
    "RFC, Input_test, Classes_test, Input_train, Classes_train = train(Input, Output)\n",
    "test(RFC,Input_test, Classes_test)\n",
    "\n",
    "inData                       = pd.DataFrame(Input_train).to_numpy()\n",
    "classData                    = pd.DataFrame(Classes_train).to_numpy()\n",
    "\n",
    "minClass, minSize, maxSize   = find_minority_class(classData)\n",
    "BF                           = Balance_ratio(maxSize, minSize)\n",
    "usedLines                    = balance(inData, classData, minClass, minSize)\n",
    "\n",
    "Input_balance, Label_balance = balance_data(inData, classData, usedLines)\n",
    "Input_folds, Output_folds    = Balance_Folds(BF, usedLines, Input_balance, Label_balance)\n",
    "\n",
    "BF_RFC_HP                    = Hyperparameter(BF, Input_folds, Output_folds)\n",
    "BF_RFC                       = BF_training(BF, Input_folds, Output_folds, BF_RFC_HP)\n",
    "Prob_matrix                  = BFC_test(BF_RFC, Input_test)\n",
    "\n",
    "Final_vote, Sum_PD, Sum_SNP  = Weighted_Vote(Prob_matrix, BF)\n",
    "S_Out                        = Final_score(Sum_PD, Sum_SNP, BF)\n",
    "\n",
    "evalutation(Classes_test, Final_vote,S_Out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab48735",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 337.844,
   "position": {
    "height": "40px",
    "left": "1536px",
    "right": "20px",
    "top": "112px",
    "width": "354px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
