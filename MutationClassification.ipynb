{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fcba82d",
   "metadata": {},
   "source": [
    "### Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "5d94d2bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Example 2 is inbalanced data set; ~2200 in PD and ~1100 in SNP\\n    Goal is to predict if mutation is SNP or PD\\n    CV branch\\n    \\n    Total samples: 3368\\n    2254 PD samples\\n    1111 SNP samples\\n'"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Example 2 is inbalanced data set; ~2200 in PD and ~1100 in SNP\n",
    "    Goal is to predict if mutation is SNP or PD\n",
    "    CV branch\n",
    "    \n",
    "    Total samples: 3368\n",
    "    2254 PD samples\n",
    "    1111 SNP samples\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "5737f62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Imports the required libraries and packages\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd  #Import for data manipulation in dataframes\n",
    "import numpy as np  #Array manipulation and calculates mean\n",
    "\n",
    "import random as rd\n",
    "import time\n",
    "\n",
    "from sklearn.metrics import(\n",
    "    matthews_corrcoef,  # MCC for evaluation\n",
    "    balanced_accuracy_score, #hyperparameter evaluation\n",
    "    f1_score,  #hyperparameter evaluation\n",
    "    confusion_matrix,  # confusion matrix for classification evalutation\n",
    "    classification_report #Return the F1, precision, and recall of a prediction\n",
    "    )\n",
    "from sklearn.model_selection import(\n",
    "    train_test_split,  # Splits data frame into the training set and testing set\n",
    "    GridSearchCV,  # Cross validation to improve hyperparameters\n",
    "    RandomizedSearchCV,\n",
    "    StratifiedKFold, # K-fold CV\n",
    "    GroupKFold\n",
    "        )\n",
    "from sklearn.ensemble import RandomForestClassifier #SK learn API for classificastion random forests\n",
    "from sklearn.tree import DecisionTreeClassifier #Single tree decisions \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier #allows for confidence scores to be predicted for each\n",
    "np.set_printoptions(threshold=np.inf, precision=3) #full array printing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddcc865",
   "metadata": {},
   "source": [
    "### Clean dataset in pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "62413d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Clean_data(file):\n",
    "    \"\"\" Input:      file        The dataset to read\n",
    "\n",
    "        Returns:    Input       Dataframe with of input features for training\n",
    "                    Output      Dataframe of class labels for each instance in Input\n",
    "\n",
    "        Create, clean and convert dataset E2.csv to PD dataframe. Sorts alphabetically to order proteins, removes blank spaces\n",
    "        and applies \"One Hot Encoding\" to convert classes (PD/SNP) to 1/0\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_csv('E2.csv')\n",
    "\n",
    "    #Create ordered PDB column for K-fold validation boundries\n",
    "    df.sort_values(by=['pdbcode:chain:resnum:mutation'], inplace = True) #Order column by PDB codes alphabetically\n",
    "    \n",
    "#     df.drop(['pdbcode:chain:resnum:mutation'], axis=1, inplace=True) #Remove 'pdbcode:chain:resnum:mutation' column\n",
    "\n",
    "    #Remove unrequired column, replace blank spaces, reset index to run from 0\n",
    "    df.dropna(inplace = True) #drop rows with missing values\n",
    "    df.replace(' ', '_', regex=True, inplace=True)\n",
    "    df.reset_index(drop=True, inplace = True)\n",
    "\n",
    "    Input = df.drop('dataset', axis =1)\n",
    "    Output_encoded = pd.get_dummies(df, columns=['dataset']) #Encode the PD and SNP columns\n",
    "    Output = Output_encoded.drop(['dataset_snp'],axis = 1)\n",
    "#     Output = Output_encoded['dataset_pd'].copy().astype('int32') #PD = 1, SNP = 0\n",
    "\n",
    "    return Output #Datset in alphabetical order, NaNs removed and encoded PD label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "cfaeb64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Output = Clean_data(file = 'E2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb451c9e",
   "metadata": {},
   "source": [
    "### Split dataset into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "bbfacd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(Output):\n",
    "    \"\"\"      \n",
    "                    Output          Cleaned dataframe\n",
    "\n",
    "        Returns:    Testing_Set     Training data\n",
    "                    Validation_Set  Testing data\n",
    "\n",
    "        80% training and 20% testing split. Strartify ensures fixed poportion of labels are in both sets. \n",
    "        Outputs the data to files.\n",
    "        \"\"\"\n",
    "    Training_Set, Validation_Set = train_test_split(Output,train_size = 0.8)\n",
    "#     with open('Training Data.txt', 'w') as file: #Writes training features to text file\n",
    "#         file.write(Input_train.to_string())\n",
    "#     with open('Class labels.txt', 'w') as file: #Writes training class labels to text file\n",
    "#         file.write(Classes_train.to_string())\n",
    "#     with open('Test Data.txt', 'w') as file: #Writes testing features to text file\n",
    "#         file.write(Input_test.to_string())\n",
    "#     with open('Test labels.txt', 'w') as file: #Writes testing class labels to text file\n",
    "#         file.write(Classes_test.to_string())\n",
    "\n",
    "    return Training_Set, Validation_Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "f8c71a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "Training_Set, Validation_Set = train(Output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "ebe73f20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pdbcode:chain:resnum:mutation</th>\n",
       "      <th>Binding</th>\n",
       "      <th>SProtFT0</th>\n",
       "      <th>SProtFT1</th>\n",
       "      <th>SProtFT2</th>\n",
       "      <th>SProtFT3</th>\n",
       "      <th>SProtFT4</th>\n",
       "      <th>SProtFT5</th>\n",
       "      <th>SProtFT6</th>\n",
       "      <th>SProtFT7</th>\n",
       "      <th>...</th>\n",
       "      <th>NLargest6</th>\n",
       "      <th>NLargest7</th>\n",
       "      <th>NLargest8</th>\n",
       "      <th>NLargest9</th>\n",
       "      <th>NLargest10</th>\n",
       "      <th>Clash</th>\n",
       "      <th>Glycine</th>\n",
       "      <th>Proline</th>\n",
       "      <th>CisPro</th>\n",
       "      <th>dataset_pd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1773</th>\n",
       "      <td>2q4r:A:139:K</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>105.077</td>\n",
       "      <td>93.135</td>\n",
       "      <td>89.569</td>\n",
       "      <td>73.005</td>\n",
       "      <td>64.813</td>\n",
       "      <td>-4.94</td>\n",
       "      <td>-100.0000</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>1ifr:A:520:S</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>46.981</td>\n",
       "      <td>42.136</td>\n",
       "      <td>34.982</td>\n",
       "      <td>33.769</td>\n",
       "      <td>33.623</td>\n",
       "      <td>-3.54</td>\n",
       "      <td>-100.0000</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>1fb1:A:224:R</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>49.608</td>\n",
       "      <td>44.322</td>\n",
       "      <td>36.724</td>\n",
       "      <td>32.934</td>\n",
       "      <td>27.455</td>\n",
       "      <td>-6.48</td>\n",
       "      <td>-100.0000</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1817</th>\n",
       "      <td>2uxw:A:283:A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>166.748</td>\n",
       "      <td>138.660</td>\n",
       "      <td>135.198</td>\n",
       "      <td>127.073</td>\n",
       "      <td>99.783</td>\n",
       "      <td>-3.30</td>\n",
       "      <td>-100.0000</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2877</th>\n",
       "      <td>3odq:B:104:S</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>35.332</td>\n",
       "      <td>33.811</td>\n",
       "      <td>30.525</td>\n",
       "      <td>28.448</td>\n",
       "      <td>23.301</td>\n",
       "      <td>-1.94</td>\n",
       "      <td>-100.0000</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1641</th>\n",
       "      <td>2nz2:A:277:T</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>96.469</td>\n",
       "      <td>92.958</td>\n",
       "      <td>92.200</td>\n",
       "      <td>79.049</td>\n",
       "      <td>67.323</td>\n",
       "      <td>-2.28</td>\n",
       "      <td>-100.0000</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1152</th>\n",
       "      <td>2aij:X:224:W</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>63.267</td>\n",
       "      <td>61.317</td>\n",
       "      <td>60.754</td>\n",
       "      <td>54.731</td>\n",
       "      <td>52.559</td>\n",
       "      <td>-13.06</td>\n",
       "      <td>-100.0000</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>2xsx:A:374:E</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>105.432</td>\n",
       "      <td>103.922</td>\n",
       "      <td>103.614</td>\n",
       "      <td>98.976</td>\n",
       "      <td>92.988</td>\n",
       "      <td>58.84</td>\n",
       "      <td>3.0018</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>1hdr:A:65:R</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>59.881</td>\n",
       "      <td>47.153</td>\n",
       "      <td>47.103</td>\n",
       "      <td>46.007</td>\n",
       "      <td>40.790</td>\n",
       "      <td>-7.85</td>\n",
       "      <td>-100.0000</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>2xiq:A:95:R</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>155.635</td>\n",
       "      <td>117.314</td>\n",
       "      <td>116.603</td>\n",
       "      <td>115.474</td>\n",
       "      <td>107.125</td>\n",
       "      <td>22.93</td>\n",
       "      <td>-100.0000</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2692 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pdbcode:chain:resnum:mutation  Binding  SProtFT0  SProtFT1  SProtFT2  \\\n",
       "1773                  2q4r:A:139:K      0.0       0.0       0.0       0.0   \n",
       "549                   1ifr:A:520:S      0.0       0.0       0.0       0.0   \n",
       "356                   1fb1:A:224:R      1.0       0.0       0.0       0.0   \n",
       "1817                  2uxw:A:283:A      0.0       0.0       0.0       0.0   \n",
       "2877                  3odq:B:104:S      0.0       0.0       0.0       0.0   \n",
       "...                            ...      ...       ...       ...       ...   \n",
       "1641                  2nz2:A:277:T      0.0       0.0       0.0       0.0   \n",
       "1152                  2aij:X:224:W      0.0       0.0       0.0       0.0   \n",
       "2022                  2xsx:A:374:E      0.0       0.0       0.0       0.0   \n",
       "487                    1hdr:A:65:R      0.0       0.0       0.0       0.0   \n",
       "1995                   2xiq:A:95:R      0.0       0.0       0.0       0.0   \n",
       "\n",
       "      SProtFT3  SProtFT4  SProtFT5  SProtFT6  SProtFT7  ...  NLargest6  \\\n",
       "1773       0.0       0.0       0.0       0.0       0.0  ...    105.077   \n",
       "549        0.0       0.0       0.0       0.0       0.0  ...     46.981   \n",
       "356        0.0       0.0       0.0       0.0       0.0  ...     49.608   \n",
       "1817       0.0       0.0       0.0       0.0       0.0  ...    166.748   \n",
       "2877       0.0       0.0       0.0       0.0       0.0  ...     35.332   \n",
       "...        ...       ...       ...       ...       ...  ...        ...   \n",
       "1641       0.0       0.0       0.0       0.0       0.0  ...     96.469   \n",
       "1152       0.0       0.0       0.0       0.0       0.0  ...     63.267   \n",
       "2022       0.0       0.0       0.0       0.0       0.0  ...    105.432   \n",
       "487        0.0       0.0       0.0       0.0       0.0  ...     59.881   \n",
       "1995       0.0       0.0       0.0       0.0       0.0  ...    155.635   \n",
       "\n",
       "      NLargest7  NLargest8  NLargest9  NLargest10  Clash   Glycine  Proline  \\\n",
       "1773     93.135     89.569     73.005      64.813  -4.94 -100.0000   -100.0   \n",
       "549      42.136     34.982     33.769      33.623  -3.54 -100.0000   -100.0   \n",
       "356      44.322     36.724     32.934      27.455  -6.48 -100.0000   -100.0   \n",
       "1817    138.660    135.198    127.073      99.783  -3.30 -100.0000   -100.0   \n",
       "2877     33.811     30.525     28.448      23.301  -1.94 -100.0000   -100.0   \n",
       "...         ...        ...        ...         ...    ...       ...      ...   \n",
       "1641     92.958     92.200     79.049      67.323  -2.28 -100.0000   -100.0   \n",
       "1152     61.317     60.754     54.731      52.559 -13.06 -100.0000   -100.0   \n",
       "2022    103.922    103.614     98.976      92.988  58.84    3.0018   -100.0   \n",
       "487      47.153     47.103     46.007      40.790  -7.85 -100.0000   -100.0   \n",
       "1995    117.314    116.603    115.474     107.125  22.93 -100.0000   -100.0   \n",
       "\n",
       "      CisPro  dataset_pd  \n",
       "1773     0.0           1  \n",
       "549      0.0           1  \n",
       "356      0.0           1  \n",
       "1817     0.0           1  \n",
       "2877     0.0           1  \n",
       "...      ...         ...  \n",
       "1641     0.0           1  \n",
       "1152     0.0           1  \n",
       "2022     0.0           1  \n",
       "487      0.0           1  \n",
       "1995     0.0           1  \n",
       "\n",
       "[2692 rows x 49 columns]"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Training_Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e8b7f5",
   "metadata": {},
   "source": [
    "### Initial evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "cf8d9857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test(Initial_RFC, Input_test, Classes_test):\n",
    "#     \"\"\" Input:  Input_test      Features test data\n",
    "#                 Classes_test    Class label test data\n",
    "\n",
    "#         Evaluates the training data before balancing. Random forest classifier makes prediction using the test features. True values \n",
    "#         are the class labels testing data\n",
    "#     \"\"\"\n",
    "\n",
    "#     Output_pred = Initial_RFC.predict(Input_test) #Always perdict on the unseen test data, as train has been used by the estimastor\n",
    "#     print(f\"              **Initial Evaluation**\\n\")\n",
    "#     print(f\"Confusion Matrix:\\n {confusion_matrix(Classes_test, Output_pred)}\")\n",
    "#     print(f\"{classification_report(Classes_test, Output_pred)}\\nMCC                {matthews_corrcoef(Classes_test, Output_pred)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5506fbc1",
   "metadata": {},
   "source": [
    "### Manual K-fold splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "503e943b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "851 unique proteins\n"
     ]
    }
   ],
   "source": [
    "df = Training_Set\n",
    "df.sort_values(by=['pdbcode:chain:resnum:mutation'], inplace = True) #Order column by PDB codes alphabetically\n",
    "df.dropna(inplace = True) #drop rows with missing values\n",
    "\n",
    "boundry = [] #Empty list\n",
    "for i in range(len(df)):\n",
    "    boundry.append(df.iloc[i][0].partition(':')[0]) #Obtain just the PDB code from the 'pdbcode:chain:resnum:mutation' entry\n",
    "\n",
    "df.drop(['pdbcode:chain:resnum:mutation'], axis=1, inplace=True) #Remove 'pdbcode:chain:resnum:mutation' column\n",
    "df.insert(0, 'PDB code', boundry) #Insert PDB codes as first column\n",
    "\n",
    "\n",
    "#Groups proteins by PDB code#\n",
    "\n",
    "# boundry_count = 0\n",
    "# count = 0\n",
    "# df_list = [] #list of unique protein groups\n",
    "# for i in range(len(df)-1):\n",
    "#     First = df.iloc[i][0] #PDB code of row\n",
    "#     Second = df.iloc[i + 1][0] #PDB code of row n+1 \n",
    "\n",
    "#     if First == Second:\n",
    "#         boundry_count += 1 #increase count\n",
    "#     else: #if PDB code in row n is not same as row n+1\n",
    "#         df_list.append(np.array(df.iloc[(i - boundry_count): i + 1, 0:].values)) #List of samples as arrays, ordered\n",
    "#         boundry_count = 0\n",
    "      \n",
    "\n",
    "print(f\"{df['PDB code'].nunique() -1} unique proteins\")\n",
    "# df.to_csv('order.csv', index = False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "17453a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Input_CV = df.drop('dataset_pd', axis =1)\n",
    "Output_CV = df['dataset_pd'].copy().astype('int32')\n",
    "groups = df['PDB code']\n",
    "\n",
    "# Input_train, Input_test, Classes_train, Classes_test = train_test_split(Input_CV, Output_CV, train_size = 0.8, stratify=Output_CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "15fcb813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GroupKFold(n_splits=5)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [2153, 2153, 2692]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [381], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(group_kfold)\n\u001b[0;32m      5\u001b[0m GroupKFold(n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (train_index, test_index) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(group_kfold\u001b[38;5;241m.\u001b[39msplit(Input_train, Classes_train, groups)):\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFold \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Train: index=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, group=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgroups[train_index]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:330\u001b[0m, in \u001b[0;36m_BaseKFold.split\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msplit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, groups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    307\u001b[0m     \u001b[38;5;124;03m\"\"\"Generate indices to split data into training and test set.\u001b[39;00m\n\u001b[0;32m    308\u001b[0m \n\u001b[0;32m    309\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    328\u001b[0m \u001b[38;5;124;03m        The testing set indices for that split.\u001b[39;00m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 330\u001b[0m     X, y, groups \u001b[38;5;241m=\u001b[39m \u001b[43mindexable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    331\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(X)\n\u001b[0;32m    332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits \u001b[38;5;241m>\u001b[39m n_samples:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:433\u001b[0m, in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    414\u001b[0m \u001b[38;5;124;03m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[0;32m    415\u001b[0m \n\u001b[0;32m    416\u001b[0m \u001b[38;5;124;03mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    429\u001b[0m \u001b[38;5;124;03m    sparse matrix, or dataframe) or `None`.\u001b[39;00m\n\u001b[0;32m    430\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    432\u001b[0m result \u001b[38;5;241m=\u001b[39m [_make_indexable(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m iterables]\n\u001b[1;32m--> 433\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:387\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    385\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 387\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    388\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    389\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    390\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [2153, 2153, 2692]"
     ]
    }
   ],
   "source": [
    "group_kfold = GroupKFold(n_splits=5)\n",
    "group_kfold.get_n_splits(Input_train, Classes_train, groups)\n",
    "print(group_kfold)\n",
    "\n",
    "GroupKFold(n_splits=5)\n",
    "for i, (train_index, test_index) in enumerate(group_kfold.split(Input_train, Classes_train, groups)):\n",
    "    \n",
    "    print(f\"Fold {i}:\")\n",
    "    print(f\"  Train: index={train_index}, group={groups[train_index]}\")\n",
    "    print(f\"  Test:  index={test_index}, group={groups[test_index]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a335a585",
   "metadata": {},
   "source": [
    "### Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6924e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_minority_class(classData):\n",
    "    \"\"\" Input:    classData  Array of class labels\n",
    "        Returns:  minClass   The label for the minority class\n",
    "                  minSize    The number of items in the minority class\n",
    "                  maxSize    The number of items in the majority class\n",
    "\n",
    "        Finds information about the inbalance in class sizes\n",
    "    \"\"\"\n",
    "    \n",
    "    Minority_count = 0\n",
    "    Majority_count = 0\n",
    "    for datum in classData:\n",
    "        if datum == 1:\n",
    "            Majority_count += 1\n",
    "        elif datum == 0:\n",
    "            Minority_count += 1\n",
    "\n",
    "    minClass = 0\n",
    "    minSize = Minority_count\n",
    "    maxSize = Majority_count\n",
    "    if Minority_count > Majority_count:\n",
    "        minClass = 1\n",
    "        minSize = Majority_count\n",
    "        maxSize = Minority_count\n",
    "\n",
    "    return minClass, minSize, maxSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6746be83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Balance_ratio(maxSize, minSize): \n",
    "    \"\"\" Input:      maxSize     The number of items in the majority class\n",
    "                    minSize     The number of items in the minority class\n",
    "\n",
    "        Returns:    BF          Number of balancing folds\n",
    "\n",
    "        Calculate the number of balancing folds needed using ratio of majority to minority class size. Double to ensure sufficient\n",
    "        majority class instances are sampled, then + 1 to make odd to allow weighted vote.\n",
    "    \"\"\"\n",
    "    Divide = maxSize/minSize\n",
    "    BF = (2 * round(Divide)) + 1 #Double ratio to nearest integer\n",
    "    return BF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1241bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance(inData, classData, minClass, minSize):\n",
    "    \"\"\" Input:    inData          array of input data\n",
    "                  classData       array of classes assigned\n",
    "                  minorityClass   class label for the minority class\n",
    "                  minoritySize    size of the minority class\n",
    "\n",
    "        Returns: array of indexes that are of interest for a balanced dataset\n",
    "\n",
    "        Perform the actual balancing between SNPs and PDs\n",
    "    \"\"\"\n",
    "    usedLines = [False] * len(inData) #Array of false for length of data\n",
    "    for i in range(len(inData)):\n",
    "        if classData[i] == minClass:\n",
    "            usedLines[i] = True\n",
    "            \n",
    "    usedCount = 0\n",
    "    while usedCount < minSize:\n",
    "        i = rd.randrange(len(inData))\n",
    "        if usedLines[i] == False:\n",
    "            usedCount += 1\n",
    "            usedLines[i] = True       \n",
    "\n",
    "    return usedLines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c54edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_data(inData, classData, usedLines):\n",
    "    \"\"\"     Input:     inData      array of input training data\n",
    "                       classData   array of classes assigned to training data\n",
    "                       usedLines   array of line indexes to print\n",
    "\n",
    "            Returns:   Input_balance  Array of balanced input training data\n",
    "                       Label_balance  Array of balanced classes assigned to training data\n",
    "        Create arrays for the input training data and classes, as needed for predicting the probability.\n",
    "        The index [i] is the identifier between the two arrays\n",
    "    \"\"\"\n",
    "    Input_balance = []\n",
    "    Label_balance = []\n",
    "    for i in range(len(inData)):\n",
    "        if usedLines[i]:\n",
    "            Input_balance.append(inData[i])\n",
    "            Label_balance.append(classData[i])\n",
    "            \n",
    "    Input_balance = np.stack(Input_balance, axis =0)\n",
    "    Label_balance = np.stack(Label_balance, axis =0)\n",
    "    \n",
    "    return Input_balance, Label_balance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27419a33",
   "metadata": {},
   "source": [
    "### Balance for n folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12239dc9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def Balance_Folds(BF, usedLines, Input_balance, Label_balance):\n",
    "    \"\"\" Input:      BF                Number of balancing folds needed\n",
    "                    usedLines         Array of line indexes to print\n",
    "                    Input_balance     Input_balance  Array of balanced input training data\n",
    "                    Label_balance     Array of balanced classes assigned to training data\n",
    "\n",
    "        Returns:    Input_folds       List of 5 balanced arrays of training data\n",
    "                    Output_folds      List of 5 balanced arrays of training data's labels\n",
    "\n",
    "        Perform the balance_data() function n number of balancing fold times. Return lists for training data and labels\n",
    "        where each item is the output of balance_data()\n",
    "    \"\"\"\n",
    "    Input_folds = []\n",
    "    Output_folds = []\n",
    "    for fold in range(BF):\n",
    "        Input_folds.append(Input_balance)\n",
    "        Output_folds.append(Label_balance)\n",
    "\n",
    "\n",
    "    with open('Balanced training data.txt', 'w') as f:\n",
    "        for number, fold in zip(range(BF), Input_folds):\n",
    "            f.write(f\"Fold: {number}\\n\\n{fold}\\n\\n\\n\")\n",
    "        \n",
    "    return Input_folds, Output_folds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cd1aaa",
   "metadata": {},
   "source": [
    "### RFC hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0840d9dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " def Hyperparameter(BF, Input_folds, Output_folds):\n",
    "    \"\"\" Input:      BF                Number of balancing folds needed\n",
    "                    Input_folds       List of 5 balanced arrays of training data\n",
    "                    Output_folds      List of 5 balanced arrays of training data's labels\n",
    "\n",
    "        Returns:    BF_RFC_HP         List of optimized hyperparameters for each RFC\n",
    "\n",
    "        Perform RandomSearchCV on each RFC to optimize number of trees, max depth and max samples\n",
    "    \"\"\"  \n",
    "    estimator = RandomForestClassifier()\n",
    "    param_grid = {\n",
    "                'n_estimators':np.arange(50,500,50),\n",
    "                'max_depth': np.arange(2, 10, 2),\n",
    "                'max_samples': np.arange(0.2, 1.2, 0.2)\n",
    "                  }\n",
    "    BF_RFC_HP = []\n",
    "\n",
    "    for i in range(BF):\n",
    "        HPtuning = RandomizedSearchCV(\n",
    "            estimator,\n",
    "            param_grid, \n",
    "            scoring = 'balanced_accuracy',\n",
    "            cv = 10,\n",
    "            n_jobs = 6, #how many cores to run in parallel\n",
    "            verbose = 2\n",
    "            ).fit(Input_folds[i], Output_folds[i].ravel())\n",
    "        BF_RFC_HP.append(HPtuning.best_params_)\n",
    "    \n",
    "    return(BF_RFC_HP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796af0e8",
   "metadata": {},
   "source": [
    "### Train RFC on balanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1decd7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BF_training(BF, Input_folds, Output_folds, BF_RFC_HP): \n",
    "    \"\"\" Input:      BF              Number of balancing folds\n",
    "                    Input_folds     List of 5 balanced arrays for training data\n",
    "                    Output_folds    List of 5 balanced arrays of training data's labels\n",
    "\n",
    "        Returns:    BF_RFC          List of RFC's trained on data in each balancing fold\n",
    "\n",
    "        Create a model that returns probability predictions for each fold, using Balance_Fold() as input\n",
    "    \"\"\"    \n",
    "    BF_RFC = []\n",
    "    \n",
    "    for i in range(BF):\n",
    "        BF_RFC.append(RandomForestClassifier(\n",
    "                                             verbose = 1\n",
    "                                            )) #Generates a RF for each fold \n",
    "        BF_RFC[i].fit(Input_folds[i], Output_folds[i].ravel()) #Fits the RFC to balanced training data    \n",
    "        \n",
    "    return BF_RFC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0dd278c",
   "metadata": {},
   "source": [
    "#### Test RFC on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc41cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BFC_test(BF_RFC, Input_test):\n",
    "    \"\"\" Input:  BF_RFC          List of RFC's trained on data in each balancing fold\n",
    "                Input_test      20% unseen testing data split before the balancing folds\n",
    "                \n",
    "        Returns:Prob_matrix     List of arrays. Each item is 2D matrix where the 1st dimension is each subset in balancing fold, \n",
    "                                2nd dimension is predicted probability\n",
    "    \n",
    "        Test the trained RFCs on the test set, then for every instance, outputs the predicted probability for each class\n",
    "    \"\"\"\n",
    "    Prob_matrix = [] #Empty list\n",
    "    Prob_matrixlist = []\n",
    "    for i in range(len(BF_RFC)):\n",
    "        Prob_list = BF_RFC[i].predict_proba(Input_test.values)\n",
    "        Prob_matrix.append(Prob_list)   \n",
    "        \n",
    "    with open('Test probabilities.txt', 'w') as f:\n",
    "        for number, line in zip(range(BF), Prob_matrix ):\n",
    "            f.write(f\"Fold: {number}\\n\\n   SNP    PD\\n{line}\\n\\n\\n\")\n",
    "\n",
    "    return Prob_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4b8fdd",
   "metadata": {},
   "source": [
    "### Weighted voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71033215",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Weighted_Vote(Prob_matrix, BF):\n",
    "    \"\"\" Input:      Prob_matrix     List of arrays. 2D matrix where the 1st dimension is each subset in balancing fold, \n",
    "                                    2nd dimension is predicted probability\n",
    "                    BF              Number of balancing folds\n",
    "\n",
    "        Returns:    Final_vote      Weighted vote classification\n",
    "\n",
    "        Calculate the final weighted vote using confidence scores (Sc). Binary classification formula Sc = 2|S0 - 0.5|\n",
    "    \"\"\"\n",
    "    Sc_PD = [] #Empty list\n",
    "    Sc_SNP = [] #Empty list\n",
    "    for i in range(BF):\n",
    "        Sc_PD.append(2* (Prob_matrix[i][:,1] - 0.5)) #Confidence scores for PD, for each fold\n",
    "        Sc_SNP.append(2*(Prob_matrix[i][:,0] - 0.5)) #Confidence scores for SNP, for each fold\n",
    "    \n",
    "\n",
    "    Sum_PD = np.sum(Sc_PD, axis = 0) #Sum of all PD confidence scores. 1D Array\n",
    "    Sum_SNP = np.sum(Sc_SNP, axis = 0) #Sum of all SNP confidence scores. 1D Array     \n",
    "\n",
    "    Vote_arr = [] #Empty list\n",
    "    \n",
    "    for i in range(len(Classes_test)):\n",
    "        if Sum_PD[i] >= Sum_SNP[i]:\n",
    "            Vote_arr.append([1]) #Append PD classifications to list\n",
    "        elif Sum_SNP[i] > Sum_PD[i]:\n",
    "            Vote_arr.append([0]) #Append SNP classifications to list\n",
    "            \n",
    "    Final_vote = np.stack(Vote_arr) #Converts list of arrays to a 2D array, shape (674,1)\n",
    "    Final_vote = Final_vote.ravel() #Flattens 2D array to 1D array\n",
    "        \n",
    "    return(Final_vote, Sum_PD, Sum_SNP) #Returns the final confidence scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18f5b78",
   "metadata": {},
   "source": [
    "### Final confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae1157a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Final_score(Sum_PD, Sum_SNP, BF):\n",
    "    \"\"\" Input:      Sum_PD      Sum of confidence score for PD predictions\n",
    "                    Sum_SNP     Sum of confidence score for SNP predictions\n",
    "\n",
    "        Returns:    S_out        Final confidence score\n",
    "\n",
    "        Calculate the final confidence score\n",
    "    \"\"\"\n",
    "    \n",
    "    S_Out = np.abs((Sum_PD - Sum_SNP) /(BF*2))\n",
    "    np.savetxt('S_out.txt', S_Out, \"%.3f\")\n",
    "    \n",
    "    return S_Out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f36545",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def evalutation(Classes_test, Final_vote, S_Out):\n",
    "    \"\"\" Input:      Classes_test       Class label test data\n",
    "                    Final_vote         Weighted vote classification\n",
    "\n",
    "        Evaluation metrics from RFC on test data with\n",
    "    \"\"\"\n",
    "    Output_pred = Final_vote\n",
    "    print(f\"              ***Final Evaluation***\\n\")\n",
    "    print(f\"Confusion Matrix:\\n {confusion_matrix(Classes_test, Output_pred)}\")\n",
    "    print(f\"{classification_report(Classes_test, Output_pred)}\\nMCC                {matthews_corrcoef(Classes_test, Output_pred)}\")\n",
    "    \n",
    "    print(f\"See file 'Classification.txt' for final classifications and confidence scores\")\n",
    "    np.savetxt('Classification.txt',\n",
    "           np.column_stack([Final_vote, S_Out]),\n",
    "           fmt = [\"%.0f\",\"%.3f\"],\n",
    "           delimiter =\"      \",\n",
    "           header = \"Final classifications and confidence scores\\n\\n\"\n",
    "          )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa67e232",
   "metadata": {},
   "source": [
    "### Main Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6b8f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file                         = 'E2.csv'\n",
    "Input, Output                = Clean_data(file)\n",
    "RFC, Input_test, Classes_test, Input_train, Classes_train = train(Input, Output)\n",
    "test(RFC,Input_test, Classes_test)\n",
    "\n",
    "inData                       = pd.DataFrame(Input_train).to_numpy()\n",
    "classData                    = pd.DataFrame(Classes_train).to_numpy()\n",
    "\n",
    "minClass, minSize, maxSize   = find_minority_class(classData)\n",
    "BF                           = Balance_ratio(maxSize, minSize)\n",
    "usedLines                    = balance(inData, classData, minClass, minSize)\n",
    "\n",
    "Input_balance, Label_balance = balance_data(inData, classData, usedLines)\n",
    "Input_folds, Output_folds    = Balance_Folds(BF, usedLines, Input_balance, Label_balance)\n",
    "\n",
    "BF_RFC_HP                    = Hyperparameter(BF, Input_folds, Output_folds)\n",
    "BF_RFC                       = BF_training(BF, Input_folds, Output_folds, BF_RFC_HP)\n",
    "Prob_matrix                  = BFC_test(BF_RFC, Input_test)\n",
    "\n",
    "Final_vote, Sum_PD, Sum_SNP  = Weighted_Vote(Prob_matrix, BF)\n",
    "S_Out                        = Final_score(Sum_PD, Sum_SNP, BF)\n",
    "\n",
    "evalutation(Classes_test, Final_vote,S_Out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab48735",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 337.844,
   "position": {
    "height": "40px",
    "left": "1536px",
    "right": "20px",
    "top": "112px",
    "width": "354px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
