{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fcba82d",
   "metadata": {},
   "source": [
    "### Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d94d2bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Example 2 is inbalanced data set; ~2200 in PD and ~1100 in SNP\\n    Goal is to predict if mutation is SNP or PD\\n    ImprovedBalancing branch\\n    \\n    Total samples: 3368\\n    2254 PD samples\\n    1111 SNP samples\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Example 2 is inbalanced data set; ~2200 in PD and ~1100 in SNP\n",
    "    Goal is to predict if mutation is SNP or PD\n",
    "    ImprovedBalancing branch\n",
    "    \n",
    "    Total samples: 3368\n",
    "    2254 PD samples\n",
    "    1111 SNP samples\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5737f62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\" Imports the required libraries and packages\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd  #Import for data manipulation in dataframes\n",
    "import numpy as np  #Array manipulation and calculates mean\n",
    "\n",
    "import random as rd\n",
    "\n",
    "from sklearn.metrics import(\n",
    "    matthews_corrcoef,  # CC for evaluation\n",
    "    f1_score,  #F1 score for evaluation\n",
    "    confusion_matrix,  #Creates the confusion matrix - stats on how accurate the test set output is\n",
    "    classification_report #Returns the F1 socre, precision, and recall of a prediction using a given model\n",
    "    )\n",
    "from sklearn.model_selection import(\n",
    "    train_test_split,  # Splits data frame into the training set and testing set\n",
    "    GridSearchCV,  # Cross validation to improve hyperparameters\n",
    "    StratifiedKFold\n",
    "        )\n",
    "from sklearn.ensemble import RandomForestClassifier #SK learn API for classificastion random forests\n",
    "from sklearn.tree import DecisionTreeClassifier #Single tree decisions \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier #allows for confidence scores to be predicted for each\n",
    "\n",
    "np.set_printoptions(threshold=np.inf) #full array printing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddcc865",
   "metadata": {},
   "source": [
    "### Clean dataset in pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "62413d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Clean_data():\n",
    "    \"\"\" Input:      file        The dataset to read\n",
    "\n",
    "        Returns:    Input       Dataframe with of input features for training\n",
    "                    Output      Dataframe of class labels for each instance in Input\n",
    "\n",
    "        Create, clean and convert dataset E2.csv to PD dataframe. Drops uneeded columns, removes blank spaces, \n",
    "        and applies \"One Hot Encoding\" to convert PD/SNP to 1/0\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_csv('E2.csv')\n",
    "\n",
    "    #Remove unrequired column, replace blank spaces, reset index to run from 0\n",
    "    df.drop(['pdbcode:chain:resnum:mutation'], axis=1, inplace=True)\n",
    "    df.replace(' ', '_', regex=True, inplace=True)\n",
    "    df.reset_index(drop=True, inplace = True)\n",
    "\n",
    "    Input = df.drop('dataset', axis =1).fillna('0') #Should remove the row \n",
    "    Output_encoded = pd.get_dummies(df, columns=['dataset']) #Encode the PD and SNP columns\n",
    "    Output = Output_encoded['dataset_pd'].copy().astype('int32') #PD = 1, SNP = 0\n",
    "\n",
    "    return Input, Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb451c9e",
   "metadata": {},
   "source": [
    "### Split into training and testing, generate RF (whole dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bbfacd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(Input, Output):\n",
    "    \"\"\" Input:      Input           Dataframe with of input features for training\n",
    "                    Output          Dataframe of class labels for each instance in Input\n",
    "\n",
    "        Returns:    Input_train     Features training data\n",
    "                    Input_test      Features test data\n",
    "                    Classes_train   Class label training data\n",
    "                    Classes_test    Class label test data\n",
    "\n",
    "        80% training and 20% testing split. Strartify ensures fixed poportion of labels are in both sets. \n",
    "        Random forest defined as RFC with 1000 trees, seed = 42. Outputs the training data to files.\n",
    "        \"\"\"\n",
    "\n",
    "    Input_train, Input_test, Classes_train, Classes_test = train_test_split(Input, Output, train_size = 0.8, random_state=42, stratify=Output) \n",
    "    RFC = RandomForestClassifier(random_state = 42, n_estimators = 1000, verbose = 1)\n",
    "    RFC.fit(Input_train, Classes_train)\n",
    "\n",
    "    with open('Training Data.txt', 'w') as file: #Writes class labels for all instances to text file\n",
    "        file.write(Input_train.to_string())\n",
    "    with open('Class labels.txt', 'w') as file: #Writes class labels for all instances to text file\n",
    "        file.write(Classes_train.to_string())\n",
    "    with open('Test Data.txt', 'w') as file: #Writes class labels for all instances to text file\n",
    "        file.write(Input_test.to_string())\n",
    "    with open('Test labels.txt', 'w') as file: #Writes class labels for all instances to text file\n",
    "        file.write(Classes_test.to_string())\n",
    "\n",
    "    return RFC, Input_test, Classes_test, Input_train, Classes_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e8b7f5",
   "metadata": {},
   "source": [
    "### Initial evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cf8d9857",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(RFC, Input_test, Classes_test):\n",
    "    \"\"\" Input:  Input_test      Features test data\n",
    "                Classes_test    Class label test data\n",
    "\n",
    "        Evaluates the training data. Random forest classifier makes prediction using the test features. True values \n",
    "        are the class labels testing data\n",
    "    \"\"\"\n",
    "\n",
    "    Output_pred = RFC.predict(Input_test) #Always perdict on the unseen test data, as train has been used by the estimastor\n",
    "    print(f\"Confusion Matrix:\\n {confusion_matrix(Classes_test, Output_pred)}\")\n",
    "    print(f\"{classification_report(Classes_test, Output_pred)}\\nMCC                {matthews_corrcoef(Classes_test, Output_pred)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c10ad630",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    4.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[145  78]\n",
      " [ 27 424]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.65      0.73       223\n",
      "           1       0.84      0.94      0.89       451\n",
      "\n",
      "    accuracy                           0.84       674\n",
      "   macro avg       0.84      0.80      0.81       674\n",
      "weighted avg       0.84      0.84      0.84       674\n",
      "\n",
      "MCC                0.6371468255225344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "Input, Output = Clean_data()\n",
    "RFC, Input_test, Classes_test, Input_train, Classes_train = train(Input, Output)\n",
    "test(RFC,Input_test, Classes_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1344ddd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223 SNP samples\n",
      "451 PD samples\n"
     ]
    }
   ],
   "source": [
    "a = 0\n",
    "b = 0\n",
    "for i in Classes_test:\n",
    "    if i == 0:\n",
    "        a = a + 1\n",
    "    if i == 1:\n",
    "        b = b + 1\n",
    "print(f\"{a} SNP samples\")\n",
    "print(f\"{b} PD samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a335a585",
   "metadata": {},
   "source": [
    "### Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6b6924e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_minority_class(classData):\n",
    "    \"\"\" Input:    classData  Array of class labels\n",
    "        Returns:  minClass   The label for the minority class\n",
    "                  minSize    The number of items in the minority class\n",
    "                  maxSize    The number of items in the majority class\n",
    "    Finds information about the inbalance in class sizes\n",
    "    \"\"\"\n",
    "    \n",
    "    Minority_count = 0\n",
    "    Majority_count = 0\n",
    "    for datum in classData:\n",
    "        if datum == 1:\n",
    "            Majority_count += 1\n",
    "        elif datum == 0:\n",
    "            Minority_count += 1\n",
    "\n",
    "    minClass = 0\n",
    "    minSize = Minority_count\n",
    "    maxSize = Majority_count\n",
    "    if Minority_count > Majority_count:\n",
    "        minClass = 1\n",
    "        minSize = Majority_count\n",
    "        maxSize = Minority_count\n",
    "\n",
    "    return minClass, minSize, maxSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6746be83",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Input:      maxSize     The number of items in the majority class\n",
    "                minSize     The number of items in the minority class\n",
    "                \n",
    "    Returns:    BF          Number of balancing folds\n",
    "    \n",
    "    Calculate the number of balancing folds needed using ratio of majority to minority class size. Double to ensure sufficient\n",
    "    majority class instances are sampled, then + 1 to make odd to allow weighted vote.\n",
    "\"\"\"\n",
    "def Balance_ratio(maxSize, minSize): \n",
    "    Divide = maxSize/minSize\n",
    "    BF = (2 * round(Divide)) + 1 #Double ratio to nearest integer\n",
    "    return BF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5d1241bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance(inData, classData, minClass, minSize):\n",
    "    \"\"\" Input:    inData          array of input data\n",
    "                  classData       array of classes assigned\n",
    "                  minorityClass   class label for the minority class\n",
    "                  minoritySize    size of the minority class\n",
    "                  \n",
    "         Returns: array of indexes that are of interest for a \n",
    "                  balanced dataset\n",
    "\n",
    "    Perform the actual balancing between SNPs and PDs\n",
    "    \"\"\"\n",
    "    \n",
    "    usedLines = [False] * len(inData) #Array of false for length of data\n",
    "    for i in range(len(inData)):\n",
    "        if classData[i] == minClass:\n",
    "            usedLines[i] = True\n",
    "            \n",
    "    usedCount = 0\n",
    "    while usedCount < minSize:\n",
    "        i = rd.randrange(len(inData))\n",
    "        if usedLines[i] == False:\n",
    "            usedCount += 1\n",
    "            usedLines[i] = True       \n",
    "\n",
    "    return usedLines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d5c54edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_data(inData, classData, usedLines):\n",
    "    \"\"\" Input:     inData      array of input training data\n",
    "                   classData   array of classes assigned to training data\n",
    "                   usedLines   array of line indexes to print\n",
    "                \n",
    "        Returns:   Input_balance  Array of balanced input training data\n",
    "                   Label_balance  Array of balanced classes assigned to training data\n",
    "\n",
    "    Create arrays for the input training data and its corresponding classes, as needed for predicting the probability.\n",
    "    The index [i] is the identifier between the two arrays\n",
    "    \"\"\"\n",
    "    Input_balance = []\n",
    "    Label_balance = []\n",
    "    for i in range(len(inData)):\n",
    "        if usedLines[i]:\n",
    "            Input_balance.append(inData[i])\n",
    "            Label_balance.append(classData[i])\n",
    "            \n",
    "    Input_balance = np.stack(Input_balance, axis =0)\n",
    "    Label_balance = np.stack(Label_balance, axis =0)\n",
    "    \n",
    "    return Input_balance, Label_balance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27419a33",
   "metadata": {},
   "source": [
    "### Balance for n folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "12239dc9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\" Input:      BF                Number of balancing folds needed\n",
    "                usedLines         Array of line indexes to print\n",
    "                Input_balance     Input_balance  Array of balanced input training data\n",
    "                Label_balance     Array of balanced classes assigned to training data\n",
    "\n",
    "    Returns:    Input_folds       List of 5 balanced arrays of training data\n",
    "                Output_folds      List of 5 balanced arrays of training data's labels\n",
    "\n",
    "    Performs the balance_data() function n number of balancing fold times. Returns lists for training data and labels\n",
    "    where each item is the output of balance_data()\n",
    "\"\"\"\n",
    "def Balance_Folds(BF, usedLines, Input_balance, Label_balance):\n",
    "    Input_folds = []\n",
    "    Output_folds = []\n",
    "    for fold in range(BF):\n",
    "        Input_folds.append(Input_balance)\n",
    "        Output_folds.append(Label_balance)\n",
    "        \n",
    "    return Input_folds, Output_folds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796af0e8",
   "metadata": {},
   "source": [
    "### Train RFC on balanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1decd7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BF_training(BF, Input_folds, Output_folds): \n",
    "    \"\"\" Input:      BF              Number of balancing folds\n",
    "                    Input_folds     List of 5 balanced arrays for training data\n",
    "                    Output_folds    List of 5 balanced arrays of training data's labels\n",
    "\n",
    "        Returns:    BF_RFC          List of RFC's trained on data in each balancing fold\n",
    "\n",
    "        Creates a model that returns probability predictions for each fold, using Balance_Fold() as input\n",
    "    \"\"\"    \n",
    "    BF_RFC = []\n",
    "    \n",
    "    for i in range(BF):\n",
    "        BF_RFC.append(RandomForestClassifier(random_state = 42, n_estimators = 1000, verbose = 1)) #Defines a Random Forest for each fold. 42 seeds, 1000 trees\n",
    "        BF_RFC[i].fit(Input_folds[i], Output_folds[i].ravel()) #Generates a random forest for each fold's training data        \n",
    "        \n",
    "    return BF_RFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "acc41cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BFC_test(BF_RFC, Input_test):\n",
    "    \"\"\" Input:  BF_RFC          List of RFC's trained on data in each balancing fold\n",
    "                Input_test      20% unseen testing data split before the balancing folds\n",
    "                \n",
    "    Returns:    Prob_matrix      List of arrays. Each item is 2D matrix where the 1st dimension is each subset in balancing fold, \n",
    "                                 2nd dimension is predicted probability\n",
    "    \n",
    "    Tests the trained RFCs on the test set, then for every instance, outputs the predicted probability for each class\n",
    "    \"\"\"\n",
    "    Prob_matrix = [] #Empty list\n",
    "    Prob_matrixlist = []\n",
    "    for i in range(len(BF_RFC)): #step through item in\n",
    "        Prob_list = BF_RFC[i].predict_proba(Input_test.values)\n",
    "        Prob_matrix.append(Prob_list)\n",
    "        \n",
    "        Output_pred = BF_RFC[i].predict(Input_test.values)\n",
    "        print(f\"{matthews_corrcoef(Classes_test, Output_pred)}\")    \n",
    "              \n",
    "        \n",
    "    with open('Test probabilities.txt', 'w') as f:\n",
    "        for number, line in zip(range(BF), Prob_matrix ):\n",
    "            f.write(f\"Fold: {number}\\n\\n   SNP    PD\\n{line}\\n\\n\\n\")\n",
    "\n",
    "    return Prob_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4b8fdd",
   "metadata": {},
   "source": [
    "### Weighted voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "71033215",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Input:      Prob_matrix      List of arrays. 2D matrix where the 1st dimension is each subset in balancing fold, \n",
    "                                2nd dimension is predicted probability\n",
    "                BF              Number of balancing folds\n",
    "                \n",
    "    Returns:    S_Out           Confidence score for each predictor\n",
    "    \n",
    "    Calculates the final weighted vote using confidence scores (Sc). Binary classification formula Sc = 2|S0 - 0.5|\n",
    "\"\"\"\n",
    "def Weighted_Vote(Prob_matrix, BF):\n",
    "    Sc_PD = [] #list of arrays\n",
    "    Sc_SNP = [] #list of arrays\n",
    "    for i in range(BF):\n",
    "        Sc_PD.append(2* (Prob_matrix[i][:,1] - 0.5)) #Confidence scores for PD\n",
    "        Sc_SNP.append(2*(Prob_matrix[i][:,0] - 0.5)) #Confidence scores for SNP\n",
    "\n",
    "    Sum_PD = np.sum(Sc_PD, axis = 0)\n",
    "    Sum_SNP = np.sum(Sc_SNP, axis = 0)\n",
    "           \n",
    "    PD_Count = 0\n",
    "    SNP_Count = 0\n",
    "    \n",
    "    for i in range(len(Prob_matrix[0])):\n",
    "        if Sum_PD[i] >= Sum_SNP[i]:\n",
    "            PD_Count += 1\n",
    "        else:\n",
    "            SNP_Count += 1\n",
    "            \n",
    "#     np.savetxt('S_out.txt', S_Out, \"%.3f\")\n",
    "    \n",
    "    return(PD_Count, SNP_Count) #Returns the final confidence scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "b262743c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(415, 259)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PD_Count, SNP_Count = Weighted_Vote(Prob_matrix, BF)\n",
    "PD_Count, SNP_Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f7156ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Input:      S_Out       Confidence score for each predictor\n",
    "                \n",
    "    Returns:    Vote        Number of PDs and SNPs predicted after weighted vote\n",
    "    \n",
    "    Calculates the final confidence score\n",
    "\"\"\"\n",
    "def Final_vote(S_Out):\n",
    "    \n",
    "    SNP_Count = 0\n",
    "    PD_Count = 0\n",
    "    FinalClass = []\n",
    "    for i in range(len(S_Out)):\n",
    "        if S_Out[i] >= 0.5:\n",
    "            PD_Count += 1\n",
    "            FinalClass.append(round(S_Out[i]))\n",
    "        elif S_Out[i] < 0.5:\n",
    "            SNP_Count += 1\n",
    "            FinalClass.append(round(S_Out[i]))\n",
    "    \n",
    "    return FinalClass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "9ce6740d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    3.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    3.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    3.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    3.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    3.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6372799342204151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6372799342204151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6372799342204151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6372799342204151\n",
      "0.6372799342204151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "# file = 'E2.csv'\n",
    "# Input, Output = Clean_data(file)\n",
    "\n",
    "inData    = pd.DataFrame(Input_train).to_numpy()\n",
    "classData = pd.DataFrame(Classes_train).to_numpy()\n",
    "\n",
    "minClass, minSize, maxSize   = find_minority_class(classData)\n",
    "BF                           = Balance_ratio(maxSize, minSize)\n",
    "usedLines                    = balance(inData, classData, minClass, minSize)\n",
    "\n",
    "Input_balance, Label_balance = balance_data(inData, classData, usedLines)\n",
    "Input_folds, Output_folds    = Balance_Folds(BF, usedLines, Input_balance, Label_balance)\n",
    "\n",
    "BF_RFC                       = BF_training(BF, Input_folds, Output_folds)\n",
    "Prob_matrix                  = BFC_test(BF_RFC, Input_test)\n",
    "\n",
    "# S_Out                        = Score(Prob_matrix, BF)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "84ee4d17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.804, 0.842, 0.189, 0.36 , 0.86 , 0.873, 0.857, 0.093, 0.068,\n",
       "       0.869, 0.802, 0.39 , 0.774, 0.185, 0.728, 0.455, 0.605, 0.297,\n",
       "       0.81 , 0.647, 0.909, 0.527, 0.503, 0.796, 0.468, 0.681, 0.989,\n",
       "       0.884, 0.652, 0.647, 0.9  , 0.671, 0.592, 0.905, 0.83 , 0.773,\n",
       "       0.484, 0.548, 0.835, 0.661, 0.034, 0.734, 0.249, 0.954, 0.886,\n",
       "       0.667, 0.792, 0.623, 0.491, 0.824, 0.746, 0.226, 0.962, 0.924,\n",
       "       0.69 , 0.843, 0.914, 0.094, 0.528, 0.976, 0.672, 0.396, 0.616,\n",
       "       0.837, 0.379, 0.488, 0.573, 0.427, 0.503, 0.793, 0.85 , 0.217,\n",
       "       0.543, 0.725, 0.055, 0.753, 0.648, 0.626, 0.336, 0.402, 0.763,\n",
       "       0.341, 0.812, 0.831, 0.922, 0.39 , 0.485, 0.8  , 0.233, 0.82 ,\n",
       "       0.601, 0.947, 0.359, 0.583, 0.71 , 0.804, 0.933, 0.303, 0.266,\n",
       "       0.861, 0.38 , 0.539, 0.696, 0.992, 0.158, 0.192, 0.771, 0.561,\n",
       "       0.652, 0.23 , 0.329, 0.166, 0.475, 0.191, 0.303, 0.523, 0.819,\n",
       "       0.708, 0.071, 0.644, 0.125, 0.248, 0.151, 0.329, 0.054, 0.969,\n",
       "       0.429, 0.921, 0.156, 0.884, 0.841, 0.376, 0.274, 0.789, 0.932,\n",
       "       0.444, 0.219, 0.928, 0.841, 0.732, 0.438, 0.977, 0.899, 0.874,\n",
       "       0.1  , 0.821, 0.125, 0.579, 0.461, 0.971, 0.527, 0.558, 0.519,\n",
       "       0.175, 0.14 , 0.843, 0.388, 0.648, 0.281, 0.835, 0.384, 0.287,\n",
       "       0.623, 0.616, 0.709, 0.681, 0.484, 0.956, 0.836, 0.895, 0.974,\n",
       "       0.649, 0.717, 0.867, 0.569, 0.922, 0.887, 0.455, 0.914, 0.863,\n",
       "       0.417, 0.656, 0.858, 0.407, 0.539, 0.874, 0.864, 0.958, 0.38 ,\n",
       "       0.85 , 0.332, 0.165, 0.211, 0.723, 0.092, 0.126, 0.924, 0.762,\n",
       "       0.449, 0.254, 0.706, 0.76 , 0.183, 0.667, 0.964, 0.476, 0.793,\n",
       "       0.828, 0.618, 0.993, 0.758, 0.058, 0.907, 0.917, 0.654, 0.938,\n",
       "       0.279, 0.936, 0.926, 0.461, 0.864, 0.182, 0.912, 0.765, 0.899,\n",
       "       0.383, 0.762, 0.529, 0.837, 0.97 , 0.771, 0.147, 0.073, 0.932,\n",
       "       0.215, 0.868, 0.34 , 0.498, 0.78 , 0.875, 0.106, 0.691, 0.301,\n",
       "       0.121, 0.628, 0.736, 0.408, 0.292, 0.89 , 0.833, 0.664, 0.444,\n",
       "       0.882, 0.457, 0.328, 0.591, 0.27 , 0.96 , 0.967, 0.507, 0.843,\n",
       "       0.622, 0.598, 0.87 , 0.609, 0.803, 0.598, 0.33 , 0.615, 0.238,\n",
       "       0.399, 0.407, 0.429, 0.661, 0.621, 0.315, 0.34 , 0.861, 0.827,\n",
       "       0.227, 0.392, 0.752, 0.945, 0.211, 0.933, 0.886, 0.721, 0.967,\n",
       "       0.117, 0.443, 0.94 , 0.972, 0.504, 0.646, 0.651, 0.666, 0.697,\n",
       "       0.362, 0.773, 0.482, 0.792, 0.892, 0.519, 0.302, 0.899, 0.886,\n",
       "       0.76 , 0.368, 0.801, 0.76 , 0.462, 0.644, 0.451, 0.857, 0.876,\n",
       "       0.7  , 0.986, 0.228, 0.893, 0.817, 0.791, 0.976, 0.762, 0.288,\n",
       "       0.939, 0.812, 0.114, 0.824, 0.427, 0.935, 0.688, 0.243, 0.225,\n",
       "       0.397, 0.723, 0.585, 0.301, 0.256, 0.389, 0.574, 0.067, 0.432,\n",
       "       0.297, 0.893, 0.711, 0.815, 0.065, 0.826, 0.177, 0.856, 0.155,\n",
       "       0.811, 0.358, 0.636, 0.172, 0.726, 0.353, 0.331, 0.866, 0.822,\n",
       "       0.816, 0.67 , 0.867, 0.736, 0.869, 0.447, 0.575, 0.755, 0.302,\n",
       "       0.921, 0.435, 0.518, 0.116, 0.935, 0.304, 0.607, 0.391, 0.608,\n",
       "       0.209, 0.307, 0.157, 0.327, 0.887, 0.87 , 0.823, 0.644, 0.24 ,\n",
       "       0.285, 0.537, 0.674, 0.298, 0.664, 0.957, 0.159, 0.458, 0.615,\n",
       "       0.74 , 0.201, 0.08 , 0.845, 0.427, 0.161, 0.473, 0.927, 0.749,\n",
       "       0.745, 0.6  , 0.378, 0.342, 0.368, 0.964, 0.506, 0.404, 0.509,\n",
       "       0.586, 0.295, 0.76 , 0.43 , 0.411, 0.746, 0.435, 0.698, 0.808,\n",
       "       0.676, 0.69 , 0.686, 0.963, 0.372, 0.502, 0.911, 0.712, 0.537,\n",
       "       0.933, 0.252, 0.289, 0.675, 0.969, 0.347, 0.238, 0.502, 0.65 ,\n",
       "       0.92 , 0.643, 0.954, 0.498, 0.121, 0.482, 0.565, 0.763, 0.707,\n",
       "       0.184, 0.451, 0.089, 0.92 , 0.453, 0.203, 0.179, 0.513, 0.694,\n",
       "       0.521, 0.109, 0.885, 0.322, 0.366, 0.795, 0.462, 0.119, 0.934,\n",
       "       0.115, 0.587, 0.358, 0.714, 0.868, 0.739, 0.101, 0.8  , 0.387,\n",
       "       0.305, 0.982, 0.165, 0.979, 0.452, 0.918, 0.727, 0.298, 0.294,\n",
       "       0.508, 0.443, 0.356, 0.275, 0.254, 0.922, 0.447, 0.644, 0.337,\n",
       "       0.276, 0.647, 0.621, 0.791, 0.39 , 0.815, 0.811, 0.899, 0.17 ,\n",
       "       0.85 , 0.887, 0.273, 0.164, 0.662, 0.159, 0.986, 0.603, 0.759,\n",
       "       0.567, 0.373, 0.893, 0.875, 0.741, 0.188, 0.861, 0.372, 0.456,\n",
       "       0.966, 0.138, 0.457, 0.289, 0.416, 0.756, 0.827, 0.684, 0.642,\n",
       "       0.156, 0.438, 0.105, 0.879, 0.145, 0.273, 0.533, 0.615, 0.504,\n",
       "       0.803, 0.949, 0.783, 0.042, 0.678, 0.338, 0.974, 0.652, 0.175,\n",
       "       0.812, 0.543, 0.264, 0.61 , 0.897, 0.372, 0.835, 0.993, 0.74 ,\n",
       "       0.583, 0.811, 0.936, 0.57 , 0.77 , 0.449, 0.889, 0.186, 0.451,\n",
       "       0.756, 0.68 , 0.894, 0.262, 0.524, 0.26 , 0.626, 0.989, 0.63 ,\n",
       "       0.95 , 0.636, 0.287, 0.224, 0.817, 0.698, 0.126, 0.435, 0.186,\n",
       "       0.503, 0.666, 0.888, 0.393, 0.143, 0.778, 0.583, 0.09 , 0.19 ,\n",
       "       0.625, 0.778, 0.251, 0.459, 0.775, 0.786, 0.831, 0.906, 0.847,\n",
       "       0.906, 0.287, 0.688, 0.503, 0.631, 0.955, 0.201, 0.956, 0.555,\n",
       "       0.432, 0.904, 0.907, 0.114, 0.127, 0.376, 0.964, 0.958, 0.629,\n",
       "       0.721, 0.157, 0.783, 0.943, 0.674, 0.912, 0.978, 0.927, 0.515,\n",
       "       0.618, 0.023, 0.642, 0.759, 0.266, 0.374, 0.618, 0.725, 0.174,\n",
       "       0.617, 0.27 , 0.444, 0.513, 0.524, 0.747, 0.045, 0.403, 0.585,\n",
       "       0.233, 0.796, 0.868, 0.774, 0.956, 0.852, 0.593, 0.873, 0.131,\n",
       "       0.602, 0.529, 0.44 , 0.131, 0.444, 0.434, 0.447, 0.631, 0.202,\n",
       "       0.621, 0.904, 0.756, 0.306, 0.939, 0.786, 0.184, 0.561])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Prob_matrix[0][:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f36545",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Final_vote(S_Out)) #Always perdict on the unseen test data, as train has been used by the estimastor\n",
    "Output_pred = Final_vote(S_Out)\n",
    "\n",
    "print(f\"Confusion Matrix:\\n {confusion_matrix(Classes_test, Output_pred)}\")\n",
    "print(f\"{classification_report(Classes_test, Output_pred)}\\nMCC                {matthews_corrcoef(Classes_test, Output_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9a01ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 337.844,
   "position": {
    "height": "359.844px",
    "left": "1536px",
    "right": "20px",
    "top": "112px",
    "width": "354px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
